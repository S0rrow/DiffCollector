diff --git a/addons/hive-bridge/src/test/java/org/apache/atlas/hive/hook/HiveHookIT.java b/addons/hive-bridge/src/test/java/org/apache/atlas/hive/hook/HiveHookIT.java
index 2f0c71ffd..f7290eec4 100755
--- a/addons/hive-bridge/src/test/java/org/apache/atlas/hive/hook/HiveHookIT.java
+++ b/addons/hive-bridge/src/test/java/org/apache/atlas/hive/hook/HiveHookIT.java
@@ -22,19 +22,16 @@ import com.google.common.base.Joiner;
 import com.google.common.collect.ImmutableList;
 import org.apache.atlas.ApplicationProperties;
 import org.apache.atlas.AtlasClient;
-import org.apache.atlas.fs.model.FSDataTypes;
 import org.apache.atlas.hive.bridge.HiveMetaStoreBridge;
 import org.apache.atlas.hive.model.HiveDataModelGenerator;
 import org.apache.atlas.hive.model.HiveDataTypes;
 import org.apache.atlas.typesystem.Referenceable;
 import org.apache.atlas.typesystem.Struct;
-import org.apache.atlas.typesystem.persistence.Id;
 import org.apache.atlas.utils.ParamChecker;
 import org.apache.commons.configuration.Configuration;
 import org.apache.commons.lang.RandomStringUtils;
 import org.apache.commons.lang.StringEscapeUtils;
 import org.apache.commons.lang.StringUtils;
-import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.metastore.TableType;
 import org.apache.hadoop.hive.ql.Driver;
@@ -64,9 +61,6 @@ public class HiveHookIT {
     private Driver driver;
     private AtlasClient dgiCLient;
     private SessionState ss;
-    
-    private static final String INPUTS = AtlasClient.PROCESS_ATTRIBUTE_INPUTS;
-    private static final String OUTPUTS = AtlasClient.PROCESS_ATTRIBUTE_OUTPUTS;
 
     private enum QUERY_TYPE {
         GREMLIN,
@@ -87,11 +81,9 @@ public class HiveHookIT {
         SessionState.setCurrentSessionState(ss);
 
         Configuration configuration = ApplicationProperties.get();
-        dgiCLient = new AtlasClient(configuration.getString(HiveMetaStoreBridge.ATLAS_ENDPOINT, DGI_URL));
-
         HiveMetaStoreBridge hiveMetaStoreBridge = new HiveMetaStoreBridge(conf, configuration);
         hiveMetaStoreBridge.registerHiveDataModel();
-
+        dgiCLient = new AtlasClient(configuration.getString(HiveMetaStoreBridge.ATLAS_ENDPOINT, DGI_URL));
     }
 
     private void runCommand(String cmd) throws Exception {
@@ -153,15 +145,10 @@ public class HiveHookIT {
         return tableName;
     }
 
-    private String createTable(boolean isExternal, boolean isPartitioned, boolean isTemporary) throws Exception {
+    private String createTable(boolean isPartitioned, boolean isTemporary) throws Exception {
         String tableName = tableName();
-
-        String location = "";
-        if (isExternal) {
-            location = " location '" +  createTestDFSPath("someTestPath") + "'";
-        }
-        runCommand("create " + (isExternal ? " EXTERNAL " : "") + (isTemporary ? "TEMPORARY " : "") + "table " + tableName + "(id int, name string) comment 'table comment' " + (isPartitioned ?
-            " partitioned by(dt string)" : "") + location);
+        runCommand("create " + (isTemporary ? "TEMPORARY " : "") + "table " + tableName + "(id int, name string) comment 'table comment' " + (isPartitioned ?
+            " partitioned by(dt string)" : ""));
         return tableName;
     }
 
@@ -195,37 +182,6 @@ public class HiveHookIT {
         assertDatabaseIsRegistered(DEFAULT_DB);
     }
 
-    @Test
-    public void testCreateExternalTable() throws Exception {
-        String tableName = tableName();
-        String dbName = createDatabase();
-        String colName = columnName();
-
-        String pFile = createTestDFSPath("parentPath");
-        final String query = String.format("create EXTERNAL table %s.%s( %s, %s) location '%s'", dbName , tableName , colName + " int", "name string",  pFile);
-        runCommand(query);
-        String tableId = assertTableIsRegistered(dbName, tableName);
-
-        Referenceable processReference = validateProcess(query, 1, 1);
-        validateHDFSPaths(processReference, pFile, INPUTS);
-        validateOutputTables(processReference, tableId);
-    }
-
-    private void validateOutputTables(Referenceable processReference, String... expectedTableGuids) throws Exception {
-       validateTables(processReference, OUTPUTS, expectedTableGuids);
-    }
-
-    private void validateInputTables(Referenceable processReference, String... expectedTableGuids) throws Exception {
-        validateTables(processReference, INPUTS, expectedTableGuids);
-    }
-
-    private void validateTables(Referenceable processReference, String attrName, String... expectedTableGuids) throws Exception {
-        List<Id> tableRef = (List<Id>) processReference.get(attrName);
-        for(int i = 0; i < expectedTableGuids.length; i++) {
-            Assert.assertEquals(tableRef.get(i)._getId(), expectedTableGuids[i]);
-        }
-    }
-
     private String assertColumnIsRegistered(String colName) throws Exception {
         LOG.debug("Searching for column {}", colName.toLowerCase());
         String query =
@@ -309,16 +265,9 @@ public class HiveHookIT {
         Assert.assertEquals(vertices.length(), 0);
     }
 
-    private String createTestDFSPath(String path) throws Exception {
-        return "pfile://" + mkdir(path);
-    }
-
-    private String createTestDFSFile(String path) throws Exception {
-        return "pfile://" + file(path);
-    }
 
     @Test
-    public void testLoadLocalPath() throws Exception {
+    public void testLoadData() throws Exception {
         String tableName = createTable(false);
 
         String loadFile = file("load");
@@ -329,69 +278,19 @@ public class HiveHookIT {
     }
 
     @Test
-    public void testLoadLocalPathIntoPartition() throws Exception {
+    public void testLoadDataIntoPartition() throws Exception {
         String tableName = createTable(true);
 
         String loadFile = file("load");
         String query = "load data local inpath 'file://" + loadFile + "' into table " + tableName +  " partition(dt = '2015-01-01')";
         runCommand(query);
 
-        validateProcess(query, 0, 1);
-    }
-
-    @Test
-    public void testLoadDFSPath() throws Exception {
-        String tableName = createTable(true, true, false);
-
-        String tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-
-        String loadFile = createTestDFSFile("loadDFSFile");
-        String query = "load data inpath '" + loadFile + "' into table " + tableName + " partition(dt = '2015-01-01')";
-        runCommand(query);
-
-        Referenceable processReference = validateProcess(query, 1, 1);
-
-        validateHDFSPaths(processReference, loadFile, INPUTS);
-
-        validateOutputTables(processReference, tableId);
-    }
-
-    private Referenceable validateProcess(String query, int numInputs, int numOutputs) throws Exception {
-        String processId = assertProcessIsRegistered(query);
-        Referenceable process = dgiCLient.getEntity(processId);
-        if (numInputs == 0) {
-            Assert.assertNull(process.get(INPUTS));
-        } else {
-            Assert.assertEquals(((List<Referenceable>) process.get(INPUTS)).size(), numInputs);
-        }
-
-        if (numOutputs == 0) {
-            Assert.assertNull(process.get(OUTPUTS));
-        } else {
-            Assert.assertEquals(((List<Id>) process.get(OUTPUTS)).size(), numOutputs);
-        }
-
-        return process;
-    }
-
-    private Referenceable validateProcess(String query, String[] inputs, String[] outputs) throws Exception {
         String processId = assertProcessIsRegistered(query);
         Referenceable process = dgiCLient.getEntity(processId);
-        if (inputs == null) {
-            Assert.assertNull(process.get(INPUTS));
-        } else {
-            Assert.assertEquals(((List<Referenceable>) process.get(INPUTS)).size(), inputs.length);
-            validateInputTables(process, inputs);
-        }
+        Assert.assertNull(process.get("inputs"));
 
-        if (outputs == null) {
-            Assert.assertNull(process.get(OUTPUTS));
-        } else {
-            Assert.assertEquals(((List<Id>) process.get(OUTPUTS)).size(), outputs.length);
-            validateOutputTables(process, outputs);
-        }
-
-        return process;
+        System.out.println(" Ref Ops : " + process.get("outputs"));
+        Assert.assertEquals(((List<Referenceable>) process.get("outputs")).size(), 1);
     }
 
     @Test
@@ -402,11 +301,13 @@ public class HiveHookIT {
                 "insert into " + insertTableName + " select id, name from " + tableName;
 
         runCommand(query);
+        String processId = assertProcessIsRegistered(query);
+        Referenceable process = dgiCLient.getEntity(processId);
+        Assert.assertEquals(((List<Referenceable>) process.get("inputs")).size(), 1);
+        Assert.assertEquals(((List<Referenceable>) process.get("outputs")).size(), 1);
 
-        String inputTableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-        String opTableId = assertTableIsRegistered(DEFAULT_DB, insertTableName);
-
-        validateProcess(query, new String[] {inputTableId}, new String[] {opTableId});
+        assertTableIsRegistered(DEFAULT_DB, tableName);
+        assertTableIsRegistered(DEFAULT_DB, insertTableName);
     }
 
     @Test
@@ -417,7 +318,10 @@ public class HiveHookIT {
             "insert overwrite LOCAL DIRECTORY '" + randomLocalPath.getAbsolutePath() + "' select id, name from " + tableName;
 
         runCommand(query);
-        validateProcess(query, 1, 0);
+        String processId = assertProcessIsRegistered(query);
+        Referenceable process = dgiCLient.getEntity(processId);
+        Assert.assertEquals(((List<Referenceable>) process.get("inputs")).size(), 1);
+        Assert.assertNull(process.get("outputs"));
 
         assertTableIsRegistered(DEFAULT_DB, tableName);
     }
@@ -425,32 +329,34 @@ public class HiveHookIT {
     @Test
     public void testInsertIntoDFSDir() throws Exception {
         String tableName = createTable();
-        String pFile = createTestDFSPath("somedfspath");
+        String pFile = "pfile://" + mkdir("somedfspath");
         String query =
             "insert overwrite DIRECTORY '" + pFile  + "' select id, name from " + tableName;
 
         runCommand(query);
-        Referenceable processReference = validateProcess(query, 1, 1);
-        validateHDFSPaths(processReference, pFile, OUTPUTS);
-
-        String tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
+        String processId = assertProcessIsRegistered(query);
+        Referenceable process = dgiCLient.getEntity(processId);
+        Assert.assertEquals(((List<Referenceable>) process.get("inputs")).size(), 1);
+        Assert.assertNull(process.get("outputs"));
 
-        validateInputTables(processReference, tableId);
+        assertTableIsRegistered(DEFAULT_DB, tableName);
     }
 
     @Test
     public void testInsertIntoTempTable() throws Exception {
         String tableName = createTable();
-        String insertTableName = createTable(false, false, true);
+        String insertTableName = createTable(false, true);
         String query =
             "insert into " + insertTableName + " select id, name from " + tableName;
 
         runCommand(query);
-        validateProcess(query, 1, 1);
+        String processId = assertProcessIsRegistered(query);
+        Referenceable process = dgiCLient.getEntity(processId);
+        Assert.assertEquals(((List<Referenceable>) process.get("inputs")).size(), 1);
+        Assert.assertEquals(((List<Referenceable>) process.get("outputs")).size(), 1);
 
-        String ipTableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-        String opTableId = assertTableIsRegistered(DEFAULT_DB, insertTableName);
-        validateProcess(query, new String[] {ipTableId}, new String[] {opTableId});
+        assertTableIsRegistered(DEFAULT_DB, tableName);
+        assertTableIsRegistered(DEFAULT_DB, insertTableName);
     }
 
     @Test
@@ -461,11 +367,10 @@ public class HiveHookIT {
             "insert into " + insertTableName + " partition(dt = '2015-01-01') select id, name from " + tableName
                 + " where dt = '2015-01-01'";
         runCommand(query);
-        validateProcess(query, 1, 1);
-
-        String ipTableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-        String opTableId = assertTableIsRegistered(DEFAULT_DB, insertTableName);
-        validateProcess(query, new String[] {ipTableId}, new String[] {opTableId});
+        String processId = assertProcessIsRegistered(query);
+        Referenceable process = dgiCLient.getEntity(processId);
+        Assert.assertEquals(((List<Referenceable>) process.get("inputs")).size(), 1);
+        Assert.assertEquals(((List<Referenceable>) process.get("outputs")).size(), 1);
     }
 
     private String random() {
@@ -487,58 +392,19 @@ public class HiveHookIT {
     }
 
     @Test
-    public void testExportImportUnPartitionedTable() throws Exception {
+    public void testExportImport() throws Exception {
         String tableName = createTable(false);
 
-        String tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-
         String filename = "pfile://" + mkdir("export");
         String query = "export table " + tableName + " to \"" + filename + "\"";
         runCommand(query);
-        Referenceable processReference = validateProcess(query, 1, 1);
-        validateHDFSPaths(processReference, filename, OUTPUTS);
-        validateInputTables(processReference, tableId);
+        assertProcessIsRegistered(query);
 
-        //Import
         tableName = createTable(false);
-        tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-
-        query = "import table " + tableName + " from '" + filename + "'";
-        runCommand(query);
-        processReference = validateProcess(query, 1, 1);
-        validateHDFSPaths(processReference, filename, INPUTS);
-
-        validateOutputTables(processReference, tableId);
-    }
-
-    @Test
-    public void testExportImportPartitionedTable() throws Exception {
-        String tableName = createTable(true);
-        String tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-
-        //Add a partition
-        String partFile = "pfile://" + mkdir("partition");
-        String query = "alter table " + tableName + " add partition (dt='2015-01-01') location '" + partFile + "'";
-        runCommand(query);
-
-        String filename = "pfile://" + mkdir("export");
-        query = "export table " + tableName + " to \"" + filename + "\"";
-        runCommand(query);
-        Referenceable processReference = validateProcess(query, 1, 1);
-        validateHDFSPaths(processReference, filename, OUTPUTS);
-
-        validateInputTables(processReference, tableId);
-
-        //Import
-        tableName = createTable(true);
-        tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
 
         query = "import table " + tableName + " from '" + filename + "'";
         runCommand(query);
-        processReference = validateProcess(query, 1, 1);
-        validateHDFSPaths(processReference, filename, INPUTS);
-
-        validateOutputTables(processReference, tableId);
+        assertProcessIsRegistered(query);
     }
 
     @Test
@@ -680,41 +546,6 @@ public class HiveHookIT {
         Assert.assertEquals(columns.get(0).get(HiveDataModelGenerator.NAME), "id");
     }
 
-    @Test()
-    public void testTruncateTable() throws Exception {
-        String tableName = createTable(false);
-        String query = String.format("truncate table %s", tableName);
-        runCommand(query);
-
-        String tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-        validateProcess(query, 0, 1);
-
-        //Check lineage
-        String datasetName = HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName);
-        JSONObject response = dgiCLient.getInputGraph(datasetName);
-        JSONObject vertices = response.getJSONObject("values").getJSONObject("vertices");
-        //Below should be assertTrue - Fix https://issues.apache.org/jira/browse/ATLAS-653
-        Assert.assertFalse(vertices.has(tableId));
-    }
-
-    @Test
-    public void testAlterTablePartitionColumnType() throws Exception {
-        String tableName = createTable(true, true, false);
-        final String newType = "int";
-        String query = String.format("ALTER TABLE %s PARTITION COLUMN (dt %s)", tableName, newType);
-        runCommand(query);
-
-        final String tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-        final String dtColId = assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), "dt"));
-        Referenceable table = dgiCLient.getEntity(tableId);
-        Referenceable column = dgiCLient.getEntity(dtColId);
-        Assert.assertEquals(column.get("type"), newType);
-
-        final List<Referenceable> partitionKeys = (List<Referenceable>) table.get("partitionKeys");
-        Assert.assertEquals(partitionKeys.size(), 1);
-        Assert.assertEquals(partitionKeys.get(0).getId()._getId(), dtColId);
-    }
-
     @Test
     public void testAlterViewRename() throws Exception {
         String tableName = createTable();
@@ -732,9 +563,8 @@ public class HiveHookIT {
 
     @Test
     public void testAlterTableLocation() throws Exception {
-        //Its an external table, so the HDFS location should also be registered as an entity
-        String tableName = createTable(true, true, false);
-        final String testPath = createTestDFSPath("testBaseDir");
+        String tableName = createTable();
+        final String testPath = "file://" + System.getProperty("java.io.tmpdir", "/tmp") + File.pathSeparator + "testPath";
         String query = "alter table " + tableName + " set location '" + testPath + "'";
         runCommand(query);
 
@@ -743,38 +573,6 @@ public class HiveHookIT {
         Referenceable tableRef = dgiCLient.getEntity(tableId);
         Referenceable sdRef = (Referenceable)tableRef.get(HiveDataModelGenerator.STORAGE_DESC);
         Assert.assertEquals(sdRef.get("location"), testPath);
-
-        Referenceable processReference = validateProcess(query, 1, 1);
-        validateHDFSPaths(processReference, testPath, INPUTS);
-
-        validateOutputTables(processReference, tableId);
-
-    }
-
-    private String validateHDFSPaths(Referenceable processReference, String testPath, String attributeName) throws Exception {
-        List<Id> hdfsPathRefs = (List<Id>) processReference.get(attributeName);
-
-        final String testPathNormed = normalize(new Path(testPath).toString());
-        String hdfsPathId = assertHDFSPathIsRegistered(testPathNormed);
-        Assert.assertEquals(hdfsPathRefs.get(0)._getId(), hdfsPathId);
-
-        Referenceable hdfsPathRef = dgiCLient.getEntity(hdfsPathId);
-        Assert.assertEquals(hdfsPathRef.get("path"), testPathNormed);
-        Assert.assertEquals(hdfsPathRef.get("name"), testPathNormed);
-//        Assert.assertEquals(hdfsPathRef.get("name"), new Path(testPath).getName());
-        Assert.assertEquals(hdfsPathRef.get(AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME), testPathNormed);
-
-        return hdfsPathRef.getId()._getId();
-    }
-
-
-    private String assertHDFSPathIsRegistered(String path) throws Exception {
-        final String typeName = FSDataTypes.HDFS_PATH().toString();
-        final String parentTypeName = FSDataTypes.FS_PATH().toString();
-        String gremlinQuery =
-            String.format("g.V.has('__typeName', '%s').has('%s.path', \"%s\").toList()", typeName, parentTypeName,
-                normalize(path));
-        return assertEntityIsRegistered(gremlinQuery);
     }
 
     @Test
@@ -865,114 +663,7 @@ public class HiveHookIT {
 
         //Add another property
         runSerdePropsQuery(tableName, expectedProps);
-    }
-
-    @Test
-    public void testDropTable() throws Exception {
-        //Test Deletion of tables and its corrresponding columns
-        String tableName = createTable(true, true, false);
 
-        assertTableIsRegistered(DEFAULT_DB, tableName);
-        assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), "id"));
-        assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), "name"));
-
-        final String query = String.format("drop table %s ", tableName);
-        runCommand(query);
-        assertColumnIsNotRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), "id"));
-        assertColumnIsNotRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), "name"));
-        assertTableIsNotRegistered(DEFAULT_DB, tableName);
-    }
-
-    @Test
-    public void testDropDatabaseWithCascade() throws Exception {
-        //Test Deletion of database and its corresponding tables
-        String dbName = "db" + random();
-        runCommand("create database " + dbName + " WITH DBPROPERTIES ('p1'='v1')");
-
-        final int numTables = 10;
-        String[] tableNames = new String[numTables];
-        for(int i = 0; i < numTables; i++) {
-            tableNames[i] = createTable(true, true, false);
-        }
-
-        final String query = String.format("drop database %s cascade", dbName);
-        runCommand(query);
-
-        //Verify columns are not registered for one of the tables
-        assertColumnIsNotRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, dbName, tableNames[0]), "id"));
-        assertColumnIsNotRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, dbName, tableNames[0]), "name"));
-
-        for(int i = 0; i < numTables; i++) {
-            assertTableIsNotRegistered(dbName, tableNames[i]);
-        }
-        assertDBIsNotRegistered(dbName);
-    }
-
-    @Test
-    public void testDropDatabaseWithoutCascade() throws Exception {
-        //Test Deletion of database and its corresponding tables
-        String dbName = "db" + random();
-        runCommand("create database " + dbName + " WITH DBPROPERTIES ('p1'='v1')");
-
-        final int numTables = 10;
-        String[] tableNames = new String[numTables];
-        for(int i = 0; i < numTables; i++) {
-            tableNames[i] = createTable(true, true, false);
-            String query = String.format("drop table %s", tableNames[i]);
-            runCommand(query);
-            assertTableIsNotRegistered(dbName, tableNames[i]);
-        }
-
-        final String query = String.format("drop database %s", dbName);
-        runCommand(query);
-
-        assertDBIsNotRegistered(dbName);
-    }
-
-    @Test
-    public void testDropNonExistingDB() throws Exception {
-        //Test Deletion of a non existing DB
-        final String dbName = "nonexistingdb";
-        assertDBIsNotRegistered(dbName);
-        final String query = String.format("drop database if exists %s cascade", dbName);
-        runCommand(query);
-
-        //Should have no effect
-        assertDBIsNotRegistered(dbName);
-        assertProcessIsNotRegistered(query);
-    }
-
-    @Test
-    public void testDropNonExistingTable() throws Exception {
-        //Test Deletion of a non existing table
-        final String tableName = "nonexistingtable";
-        assertTableIsNotRegistered(DEFAULT_DB, tableName);
-        final String query = String.format("drop table if exists %s", tableName);
-        runCommand(query);
-
-        //Should have no effect
-        assertTableIsNotRegistered(DEFAULT_DB, tableName);
-        assertProcessIsNotRegistered(query);
-    }
-
-    @Test
-    public void testDropView() throws Exception {
-        //Test Deletion of tables and its corrresponding columns
-        String tableName = createTable(true, true, false);
-        String viewName = tableName();
-        String query = "create view " + viewName + " as select * from " + tableName;
-        runCommand(query);
-
-        assertTableIsRegistered(DEFAULT_DB, viewName);
-        assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, viewName), "id"));
-        assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, viewName), "name"));
-
-        query = String.format("drop view %s ", viewName);
-
-        runCommand(query);
-        assertColumnIsNotRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, viewName), "id"));
-        assertColumnIsNotRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, viewName), "name"));
-        assertTableIsNotRegistered(DEFAULT_DB, viewName);
     }
 
     private void runSerdePropsQuery(String tableName, Map<String, String> expectedProps) throws Exception {
@@ -1153,14 +844,6 @@ public class HiveHookIT {
         assertEntityIsNotRegistered(QUERY_TYPE.DSL, query);
     }
 
-    private void assertDBIsNotRegistered(String dbName) throws Exception {
-        LOG.debug("Searching for database {}.{}", dbName);
-        String query = String.format(
-            "%s as d where name = '%s' and clusterName = '%s'" + " select d",
-            HiveDataTypes.HIVE_DB.getName(), dbName.toLowerCase(), CLUSTER_NAME);
-        assertEntityIsNotRegistered(QUERY_TYPE.DSL, query);
-    }
-
     private String assertTableIsRegistered(String dbName, String tableName) throws Exception {
         LOG.debug("Searching for table {}.{}", dbName, tableName);
         String query = String.format(