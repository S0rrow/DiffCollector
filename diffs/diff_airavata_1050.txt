diff --git a/modules/gfac/gfac-monitor/src/main/java/org/apache/airavata/gfac/monitor/impl/pull/qstat/HPCPullMonitor.java b/modules/gfac/gfac-monitor/src/main/java/org/apache/airavata/gfac/monitor/impl/pull/qstat/HPCPullMonitor.java
index e165bfd5b..15c638090 100644
--- a/modules/gfac/gfac-monitor/src/main/java/org/apache/airavata/gfac/monitor/impl/pull/qstat/HPCPullMonitor.java
+++ b/modules/gfac/gfac-monitor/src/main/java/org/apache/airavata/gfac/monitor/impl/pull/qstat/HPCPullMonitor.java
@@ -28,8 +28,6 @@ import org.apache.airavata.common.utils.ServerSettings;
 import org.apache.airavata.commons.gfac.type.HostDescription;
 import org.apache.airavata.gfac.core.cpi.GFac;
 import org.apache.airavata.gfac.core.monitor.MonitorID;
-import org.apache.airavata.gfac.core.utils.GFacThreadPoolExecutor;
-import org.apache.airavata.gfac.core.utils.OutHandlerWorker;
 import org.apache.airavata.gfac.monitor.HostMonitorData;
 import org.apache.airavata.gfac.monitor.UserMonitorData;
 import org.apache.airavata.gfac.monitor.core.PullMonitor;
@@ -113,12 +111,12 @@ public class HPCPullMonitor extends PullMonitor {
         this.startPulling = true;
         while (this.startPulling && !ServerSettings.isStopAllThreads()) {
             try {
-                // After finishing one iteration of the full queue this thread sleeps 1 second
-                synchronized (this.queue) {
-                    if (this.queue.size() > 0) {
+                if (this.queue.size() > 0) {
+                    synchronized (this.queue) {
                         startPulling();
+                    }
                 }
-            }
+                // After finishing one iteration of the full queue this thread sleeps 1 second
                 Thread.sleep(10000);
             } catch (Exception e) {
                 // we catch all the exceptions here because no matter what happens we do not stop running this
@@ -232,24 +230,34 @@ public class HPCPullMonitor extends PullMonitor {
                         }
                         jobStatus = new JobStatusChangeRequestEvent();
                         iMonitorID.setStatus(jobStatuses.get(iMonitorID.getJobID()+","+iMonitorID.getJobName()));    //IMPORTANT this is not a simple setter we have a logic
+                        JobIdentifier jobIdentity = new JobIdentifier(iMonitorID.getJobID(), iMonitorID.getTaskID(), iMonitorID.getWorkflowNodeID(), iMonitorID.getExperimentID());
+                        jobStatus.setJobIdentity(jobIdentity);
+                        jobStatus.setState(iMonitorID.getStatus());
+                        // we have this JobStatus class to handle amqp monitoring
+
+                        publisher.publish(jobStatus);
+                        logger.debugId(jobStatus.getJobIdentity().getJobId(), "Published job status change request, " +
+                                        "experiment {} , task {}", jobStatus.getJobIdentity().getExperimentId(),
+                                jobStatus.getJobIdentity().getTaskId());
+                        // if the job is completed we do not have to put the job to the queue again
+                        iMonitorID.setLastMonitored(new Timestamp((new Date()).getTime()));
 
                         if (iMonitorID.getFailedCount() > FAILED_COUNT) {
                             iMonitorID.setLastMonitored(new Timestamp((new Date()).getTime()));
                             String outputDir = iMonitorID.getJobExecutionContext().getApplicationContext()
                                     .getApplicationDeploymentDescription().getType().getOutputDataDirectory();
-                            List<String> stdOut = null;
-                            try {
-                                stdOut = connection.getCluster().listDirectory(outputDir); // check the outputs directory
-                            } catch (SSHApiException e) {
-                                if (e.getMessage().contains("No such file or directory")) {
-                                    // this is because while we run output handler something failed and during exception
-                                    // we store all the jobs in the monitor queue again
-                                    logger.error("We know this  job is already attempted to run out-handlers");
-                                    CommonUtils.removeMonitorFromQueue(queue, iMonitorID);
+                            List<String> stdOut = connection.getCluster().listDirectory(outputDir); // check the outputs directory
+                            if (stdOut.size() > 0) { // have to be careful with this
+                                for(int i=0;i<stdOut.size();i++) {
+                                    logger.info("--------------------------------------------------------------------------------------------");
+                                    logger.info("--------------------------------------------------------------------------------------------");
+                                    logger.info("--------------------------------------------------------------------------------------------");
+                                    logger.info("--------------------------------------------------------------------------------------------");
+                                    logger.info("--------------------------------------------------------------------------------------------");
+                                    logger.info("--------------------------------------------------------------------------------------------");
+                                    logger.info("--------------------------------------------------------------------------------------------");
+                                    logger.info(stdOut.get(i));
                                 }
-                            }
-                            if (stdOut != null && stdOut.size() > 0 && !stdOut.get(0).isEmpty()) { // have to be careful with this
-                                iMonitorID.setStatus(JobState.COMPLETE);
                                 completedJobs.put(iMonitorID.getJobName(), iMonitorID);
                                 logger.errorId(iMonitorID.getJobID(), "Job monitoring failed {} times, removed job {} from " +
                                                 "monitor queue. Experiment {} , task {}", iMonitorID.getFailedCount(),
@@ -263,21 +271,6 @@ public class HPCPullMonitor extends PullMonitor {
                             // if the job is complete we remove it from the Map, if any of these maps
                             // get empty this userMonitorData will get delete from the queue
                         }
-                        JobIdentifier jobIdentity = new JobIdentifier(iMonitorID.getJobID(),
-                                iMonitorID.getTaskID(),
-                                iMonitorID.getWorkflowNodeID(),
-                                iMonitorID.getExperimentID(),
-                                iMonitorID.getJobExecutionContext().getGatewayID());
-                        jobStatus.setJobIdentity(jobIdentity);
-                        jobStatus.setState(iMonitorID.getStatus());
-                        // we have this JobStatus class to handle amqp monitoring
-
-                        publisher.publish(jobStatus);
-                        logger.debugId(jobStatus.getJobIdentity().getJobId(), "Published job status change request, " +
-                                        "experiment {} , task {}", jobStatus.getJobIdentity().getExperimentId(),
-                                jobStatus.getJobIdentity().getTaskId());
-                        // if the job is completed we do not have to put the job to the queue again
-                        iMonitorID.setLastMonitored(new Timestamp((new Date()).getTime()));
                     }
                 } else {
                     logger.debug("Qstat Monitor doesn't handle non-gsissh hosts , host {}", iHostMonitorData.getHost()
@@ -295,8 +288,8 @@ public class HPCPullMonitor extends PullMonitor {
             for (String jobName: keys) {
                 MonitorID completedJob = completedJobs.get(jobName);
                 CommonUtils.removeMonitorFromQueue(queue, completedJob);
-                    gfac.invokeOutFlowHandlers(completedJob.getJobExecutionContext());
-//                  GFacThreadPoolExecutor.getFixedThreadPool().submit(new OutHandlerWorker(gfac, completedJob, publisher));
+                gfac.invokeOutFlowHandlers(completedJob.getJobExecutionContext());
+//                GFacThreadPoolExecutor.getCachedThreadPool().submit(new OutHandlerWorker(gfac, completedJob, publisher));
                 if (zk == null) {
                     zk = completedJob.getJobExecutionContext().getZk();
                 }
@@ -326,13 +319,12 @@ public class HPCPullMonitor extends PullMonitor {
             if (e.getMessage().contains("Unknown Job Id Error")) {
                 // in this case job is finished or may be the given job ID is wrong
                 jobStatus.setState(JobState.UNKNOWN);
-                JobIdentifier jobIdentifier = new JobIdentifier("UNKNOWN", "UNKNOWN", "UNKNOWN", "UNKNOWN", "UNKNOWN");
+                JobIdentifier jobIdentifier = new JobIdentifier("UNKNOWN", "UNKNOWN", "UNKNOWN", "UNKNOWN");
                 if (currentMonitorID != null){
                     jobIdentifier.setExperimentId(currentMonitorID.getExperimentID());
                     jobIdentifier.setTaskId(currentMonitorID.getTaskID());
                     jobIdentifier.setWorkflowNodeId(currentMonitorID.getWorkflowNodeID());
                     jobIdentifier.setJobId(currentMonitorID.getJobID());
-                    jobIdentifier.setGatewayId(currentMonitorID.getJobExecutionContext().getGatewayID());
                 }
                 jobStatus.setJobIdentity(jobIdentifier);
                 publisher.publish(jobStatus);