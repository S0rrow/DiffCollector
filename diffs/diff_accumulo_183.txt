diff --git a/test/src/test/java/org/apache/accumulo/test/functional/ExamplesIT.java b/test/src/test/java/org/apache/accumulo/test/functional/ExamplesIT.java
index 6ac0cd399b..48300fbe7d 100644
--- a/test/src/test/java/org/apache/accumulo/test/functional/ExamplesIT.java
+++ b/test/src/test/java/org/apache/accumulo/test/functional/ExamplesIT.java
@@ -20,18 +20,12 @@ import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertTrue;
 
 import java.io.File;
-import java.io.IOException;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.List;
 import java.util.Map.Entry;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
 
 import org.apache.accumulo.core.cli.BatchWriterOpts;
-import org.apache.accumulo.core.client.AccumuloException;
-import org.apache.accumulo.core.client.AccumuloSecurityException;
-import org.apache.accumulo.core.client.BatchScanner;
 import org.apache.accumulo.core.client.BatchWriter;
 import org.apache.accumulo.core.client.BatchWriterConfig;
 import org.apache.accumulo.core.client.Connector;
@@ -52,8 +46,6 @@ import org.apache.accumulo.examples.simple.client.RandomBatchWriter;
 import org.apache.accumulo.examples.simple.client.ReadWriteExample;
 import org.apache.accumulo.examples.simple.client.RowOperations;
 import org.apache.accumulo.examples.simple.client.SequentialBatchWriter;
-import org.apache.accumulo.examples.simple.client.TraceDumpExample;
-import org.apache.accumulo.examples.simple.client.TracingExample;
 import org.apache.accumulo.examples.simple.constraints.MaxMutationSize;
 import org.apache.accumulo.examples.simple.dirlist.Ingest;
 import org.apache.accumulo.examples.simple.dirlist.QueryUtil;
@@ -72,111 +64,59 @@ import org.apache.accumulo.examples.simple.shard.ContinuousQuery;
 import org.apache.accumulo.examples.simple.shard.Index;
 import org.apache.accumulo.examples.simple.shard.Query;
 import org.apache.accumulo.examples.simple.shard.Reverse;
+import org.apache.accumulo.minicluster.MiniAccumuloCluster.LogWriter;
 import org.apache.accumulo.minicluster.MemoryUnit;
-import org.apache.accumulo.minicluster.impl.MiniAccumuloClusterImpl;
-import org.apache.accumulo.minicluster.impl.MiniAccumuloClusterImpl.LogWriter;
-import org.apache.accumulo.minicluster.impl.MiniAccumuloConfigImpl;
+import org.apache.accumulo.minicluster.MiniAccumuloConfig;
 import org.apache.accumulo.server.util.Admin;
 import org.apache.accumulo.test.TestIngest;
-import org.apache.accumulo.tracer.TraceServer;
+import org.apache.accumulo.test.VerifyIngest;
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.io.Text;
-import org.junit.AfterClass;
-import org.junit.BeforeClass;
 import org.junit.Test;
 
-public class ExamplesIT extends AbstractMacIT {
+public class ExamplesIT extends MacTest {
+  
   BatchWriterOpts bwOpts = new BatchWriterOpts();
-
-  static Connector c;
-  static String instance;
-  static String keepers;
-  static String user = "root";
-  static String passwd;
-  String visibility = "A|B";
-  static String auths = "A,B";
-  BatchWriterConfig bwc = new BatchWriterConfig();
-  BatchWriter bw;
-  IteratorSetting is;
-  static String dir;
-  static FileSystem fs;
-  private static MiniAccumuloClusterImpl cluster;
-
-  @BeforeClass
-  public static void before() throws Exception {
-    MiniAccumuloConfigImpl cfg = new MiniAccumuloConfigImpl(createTestDir(ExamplesIT.class.getName()), AbstractMacIT.ROOT_PASSWORD);
-    cfg.setNativeLibPaths(NativeMapIT.nativeMapLocation().getAbsolutePath());
-    cfg.setDefaultMemory(cfg.getDefaultMemory() * 2, MemoryUnit.BYTE);
-
-    cfg.setProperty(Property.TSERV_NATIVEMAP_ENABLED, Boolean.TRUE.toString());
-    configureForEnvironment(cfg, ExamplesIT.class, createSharedTestDir(ExamplesIT.class.getName() + "-ssl"));
-    cluster = new MiniAccumuloClusterImpl(cfg);
-    cluster.start();
-
-    passwd = AbstractMacIT.ROOT_PASSWORD;
-    c = cluster.getConnector("root", ROOT_PASSWORD);
-    fs = FileSystem.get(CachedConfiguration.getInstance());
-    instance = c.getInstance().getInstanceName();
-    keepers = c.getInstance().getZooKeepers();
-    dir = cluster.getConfig().getDir().getAbsolutePath();
-
-    c.securityOperations().changeUserAuthorizations(user, new Authorizations(auths.split(",")));
-  }
-
-  @Override
-  public Connector getConnector() throws AccumuloException, AccumuloSecurityException {
-    return cluster.getConnector("root", ROOT_PASSWORD);
-  }
-
+  
   @Override
-  public String rootPath() {
-    return cluster.getConfig().getDir().getAbsolutePath();
-  }
-
-  @Test(timeout = 15 * 1000)
-  public void testTrace() throws Exception {
-    Process trace = exec(TraceServer.class);
-    while (!c.tableOperations().exists("trace"))
-      UtilWaitThread.sleep(500);
-    Process p = goodExec(TracingExample.class, "-i", instance, "-z", keepers, "-u", user, "-p", passwd, "-C", "-D", "-c");
-    for (LogWriter writer : cluster.getLogWriters()) {
-      writer.flush();
-    }
-    String result = FunctionalTestUtils.readAll(cluster, TracingExample.class, p);
-    Pattern pattern = Pattern.compile("TraceID: ([0-9a-f]+)");
-    Matcher matcher = pattern.matcher(result);
-    int count = 0;
-    while (matcher.find()) {
-      p = goodExec(TraceDumpExample.class, "-i", instance, "-z", keepers, "-u", user, "-p", passwd, "--traceid", matcher.group(1));
-      count++;
-    }
-    assertTrue(count > 0);
-    result = FunctionalTestUtils.readAll(cluster, TraceDumpExample.class, p);
-    assertTrue(result.contains("myHost@myApp"));
-    trace.destroy();
-  }
-
-  private Process exec(Class<TraceServer> class1) throws IOException {
-    return cluster.exec(class1);
+  public void configure(MiniAccumuloConfig cfg) {
+    cfg.setDefaultMemory(cfg.getDefaultMemory() * 2, MemoryUnit.BYTE);
   }
-
-  @Test(timeout = 45 * 1000)
-  public void testDirList() throws Exception {
-    goodExec(Ingest.class, "-i", instance, "-z", keepers, "-u", user, "-p", passwd, "--dirTable", "dirTable", "--indexTable", "indexTable", "--dataTable",
-        "dataTable", "--vis", visibility, "--chunkSize", 10000 + "", cluster.getConfig().getDir().getAbsolutePath());
-    Process p = goodExec(QueryUtil.class, "-i", instance, "-z", keepers, "-p", passwd, "-u", user, "-t", "indexTable", "--auths", auths, "--search", "--path",
-        "accumulo-site.xml");
-    for (LogWriter writer : cluster.getLogWriters()) {
+  
+  @Test(timeout=5*60*1000)
+  public void test() throws Exception {
+    Connector c = getConnector();
+    String instance = c.getInstance().getInstanceName();
+    String keepers = c.getInstance().getZooKeepers();
+    String user = "root";
+    String passwd = MacTest.PASSWORD;
+    String visibility = "A|B";
+    String auths = "A,B";
+    BatchWriterConfig bwc = new BatchWriterConfig();
+    BatchWriter bw;
+    IteratorSetting is;
+    String dir = cluster.getConfig().getDir().getAbsolutePath();
+    FileSystem fs = FileSystem.get(CachedConfiguration.getInstance());
+    
+    
+    log.info("testing dirlist example (a little)");
+    c.securityOperations().changeUserAuthorizations(user, new Authorizations(auths.split(",")));
+    assertEquals(0, cluster.exec(Ingest.class, "-i", instance, "-z", keepers, "-u", user, "-p", passwd, 
+        "--dirTable", "dirTable", "--indexTable", "indexTable", "--dataTable", "dataTable",
+        "--vis", visibility, "--chunkSize", 10000 + "", cluster.getConfig().getDir().getAbsolutePath()).waitFor());
+    Process p = cluster.exec(QueryUtil.class, "-i", instance, "-z", keepers, "-p", passwd, "-u", user,
+        "-t", "indexTable", "--auths", auths, "--search", "--path", "accumulo-site.xml");
+    assertEquals(0, p.waitFor());
+    for(LogWriter writer : cluster.getLogWriters()) {
       writer.flush();
     }
     String result = FunctionalTestUtils.readAll(cluster, QueryUtil.class, p);
     System.out.println("result " + result);
     assertTrue(result.contains("accumulo-site.xml"));
-  }
 
-  @Test(timeout = 5 * 1000)
-  public void testAgeoffFilter() throws Exception {
+  
+    log.info("Testing ageoff filtering");
     c.tableOperations().create("filtertest");
     is = new IteratorSetting(10, AgeOffFilter.class);
     AgeOffFilter.setTTL(is, 1000L);
@@ -187,46 +127,37 @@ public class ExamplesIT extends AbstractMacIT {
     bw.addMutation(m);
     UtilWaitThread.sleep(1000);
     int count = 0;
-    for (@SuppressWarnings("unused")
-    Entry<Key,Value> line : c.createScanner("filtertest", Authorizations.EMPTY))
+    for (@SuppressWarnings("unused") Entry<Key,Value> line : c.createScanner("filtertest", Authorizations.EMPTY))
       count++;
     assertEquals(0, count);
-  }
-
-  @Test(timeout = 20 * 1000)
-  public void testBloomFilters() throws Exception {
+    
+    
+    log.info("Testing bloom filters are fast for missing data");
     c.tableOperations().create("bloom_test");
     c.tableOperations().setProperty("bloom_test", Property.TABLE_BLOOM_ENABLED.getKey(), "true");
-    goodExec(RandomBatchWriter.class, "--seed", "7", "-i", instance, "-z", keepers, "-u", user, "-p", passwd, "--num", "100000", "--min", "0", "--max",
-        "1000000000", "--size", "50", "--batchMemory", "2M", "--batchLatency", "60s", "--batchThreads", "3", "-t", "bloom_test");
+    assertEquals(0, cluster.exec(RandomBatchWriter.class, "--seed", "7", "-i", instance, "-z",
+        keepers, "-u", user, "-p", MacTest.PASSWORD, "--num", "100000", "--min", "0", "--max", "1000000000", "--size", "50",
+        "--batchMemmory", "2M", "--batchLatency", "60s", "--batchThreads", "3", "-t", "bloom_test").waitFor());
     c.tableOperations().flush("bloom_test", null, null, true);
-    long diff = 0, diff2 = 0;
-    // try the speed test a couple times in case the system is loaded with other tests
-    for (int i = 0; i < 2; i++) {
-      long now = System.currentTimeMillis();
-      goodExec(RandomBatchScanner.class, "--seed", "7", "-i", instance, "-z", keepers, "-u", user, "-p", passwd, "--num", "10000", "--min", "0", "--max",
-          "1000000000", "--size", "50", "--scanThreads", "4", "-t", "bloom_test");
-      diff = System.currentTimeMillis() - now;
-      now = System.currentTimeMillis();
-      expectExec(1, RandomBatchScanner.class, "--seed", "8", "-i", instance, "-z", keepers, "-u", user, "-p", passwd, "--num", "10000", "--min", "0", "--max",
-          "1000000000", "--size", "50", "--scanThreads", "4", "-t", "bloom_test");
-      diff2 = System.currentTimeMillis() - now;
-      if (diff2 < diff)
-        break;
-    }
+    long now = System.currentTimeMillis();
+    assertEquals(0,  cluster.exec(RandomBatchScanner.class,"--seed", "7", "-i", instance, "-z",
+        keepers, "-u", user, "-p", MacTest.PASSWORD, "--num", "10000", "--min", "0", "--max", "1000000000", "--size", "50",
+        "--scanThreads", "4","-t", "bloom_test").waitFor());
+    long diff = System.currentTimeMillis() - now;
+    now = System.currentTimeMillis();
+    assertEquals(0,  cluster.exec(RandomBatchScanner.class,"--seed", "8", "-i", instance, "-z",
+        keepers, "-u", user, "-p", MacTest.PASSWORD, "--num", "10000", "--min", "0", "--max", "1000000000", "--size", "50",
+        "--scanThreads", "4","-t", "bloom_test").waitFor());
+    long diff2 = System.currentTimeMillis() - now;
     assertTrue(diff2 < diff);
-  }
-
-  @Test(timeout = 2 * 60 * 1000)
-  public void testShardedIndex() throws Exception {
+    
+    log.info("Creating a sharded index of the accumulo java files");
     c.tableOperations().create("shard");
     c.tableOperations().create("doc2term");
     bw = c.createBatchWriter("shard", bwc);
     Index.index(30, new File(System.getProperty("user.dir") + "/src"), "\\W+", bw);
     bw.close();
-    BatchScanner bs = c.createBatchScanner("shard", Authorizations.EMPTY, 4);
-    List<String> found = Query.query(bs, Arrays.asList("foo", "bar"));
-    bs.close();
+    List<String> found = Query.query(c.createBatchScanner("shard", Authorizations.EMPTY, 4), Arrays.asList("foo", "bar"));
     // should find ourselves
     boolean thisFile = false;
     for (String file : found) {
@@ -235,15 +166,13 @@ public class ExamplesIT extends AbstractMacIT {
     }
     assertTrue(thisFile);
     // create a reverse index
-    c.tableOperations().create("doc2Term");
-    goodExec(Reverse.class, "-i", instance, "-z", keepers, "--shardTable", "shard", "--doc2Term", "doc2Term", "-u", "root", "-p", passwd);
+    assertEquals(0, cluster.exec(Reverse.class, "-i", instance, "-z", keepers, "-t", "shard", "--doc2Term",
+        "-u", "root", "-p", passwd).waitFor());
     // run some queries
-    goodExec(ContinuousQuery.class, "-i", instance, "-z", keepers, "--shardTable", "shard", "--doc2Term", "doc2Term", "-u", "root", "-p", passwd, "--terms",
-        "5", "--count", "1000");
-  }
-
-  @Test(timeout = 2 * 1000)
-  public void testMaxMutationConstraint() throws Exception {
+    assertEquals(0, cluster.exec(ContinuousQuery.class, "-i", instance, "-z", keepers, "-t", "shard", "--doc2Term",
+        "-u", "root", "-p", passwd, "--term", "5", "--count", "1000").waitFor());
+    
+    log.info("Testing MaxMutation constraint");
     c.tableOperations().create("test_ingest");
     c.tableOperations().addConstraint("test_ingest", MaxMutationSize.class.getName());
     TestIngest.Opts opts = new TestIngest.Opts();
@@ -254,100 +183,195 @@ public class ExamplesIT extends AbstractMacIT {
     } catch (MutationsRejectedException ex) {
       assertEquals(1, ex.getConstraintViolationSummaries().size());
     }
-  }
-
-  @Test(timeout = 20 * 1000)
-  public void testBulkIngest() throws Exception {
-    goodExec(GenerateTestData.class, "--start-row", "0", "--count", "10000", "--output", dir + "/tmp/input/data");
-    goodExec(SetupTable.class, "-i", instance, "-z", keepers, "-u", user, "-p", passwd, "--table", "bulkTable");
-    goodExec(BulkIngestExample.class, "-i", instance, "-z", keepers, "-u", user, "-p", passwd, "--table", "bulkTable", "--inputDir", dir + "/tmp/input",
-        "--workDir", dir + "/tmp");
-  }
-
-  @Test(timeout = 1 * 60 * 1000)
-  public void testTeraSortAndRead() throws Exception {
-    String sorted = "sorted";
-    goodExec(TeraSortIngest.class, "--count", (1000 * 1000) + "", "-nk", "10", "-xk", "10", "-nv", "10", "-xv", "10", "-t", sorted, "-i", instance, "-z",
-        keepers, "-u", user, "-p", passwd, "--splits", "4");
-    goodExec(RegexExample.class, "-i", instance, "-z", keepers, "-u", user, "-p", passwd, "-t", sorted, "--rowRegex", ".*999.*", "--output", dir + "/tmp/nines");
-    goodExec(RowHash.class, "-i", instance, "-z", keepers, "-u", user, "-p", passwd, "-t", sorted, "--column", "c:");
-    goodExec(TableToFile.class, "-i", instance, "-z", keepers, "-u", user, "-p", passwd, "-t", sorted, "--output", dir + "/tmp/tableFile");
-  }
 
-  @Test(timeout = 10 * 1000)
-  public void testWordCount() throws Exception {
+    log.info("Starting build ingest example");
+    assertEquals(0, cluster.exec(GenerateTestData.class, "0", "10000", dir + "/tmp/input/data").waitFor());
+    assertEquals(0, cluster.exec(SetupTable.class, instance, keepers, user, passwd, "bulkTable").waitFor());
+    assertEquals(0, cluster.exec(BulkIngestExample.class, instance, keepers, user, passwd, "bulkTable",
+        dir + "/tmp/input", dir + "/tmp").waitFor());
+    assertEquals(0, cluster.exec(VerifyIngest.class, instance, keepers, user, passwd, "bulkTable", "0", "1000000").waitFor());
+    
+    log.info("Starting bulk ingest example");
+    assertEquals(0, cluster.exec(GenerateTestData.class, "0", "1000000", dir + "/tmp/input/data").waitFor());
+    assertEquals(0, cluster.exec(SetupTable.class, instance, keepers, user, passwd, "bulkTable").waitFor());
+    assertEquals(0, cluster.exec(BulkIngestExample.class, instance, keepers, user, passwd, "bulkTable", dir + "/tmp/input", dir + "/tmp").waitFor());
+    assertEquals(0, cluster.exec(VerifyIngest.class, instance, keepers, user, passwd, "bulkTable", "0", "1000000").waitFor());
+
+    log.info("Running TeraSortIngest example");
+    TeraSortIngest.main(new String[]{
+        "--count", (1000*1000) + "",
+        "-nk", "10", "-xk", "10",
+        "-nv", "10", "-xv", "10",
+        "-t", "sorted",
+        "-i", instance,
+        "-z", keepers,
+        "-u", user,
+        "-p", passwd,
+        "--splits", "4"});
+    log.info("Running Regex example");
+    RegexExample.main(new String[] {
+        "-i", instance,
+        "-z", keepers,
+        "-u", user,
+        "-p", passwd,
+        "-t", "sorted",
+        "--rowRegex", ".*999.*",
+        "--output", dir + "/tmp/nines"
+    });
+    log.info("Running RowHash example");
+    RowHash.main(new String[]{
+        "-i", instance,
+        "-z", keepers,
+        "-u", user,
+        "-p", passwd,
+        "-t", "sorted",
+        "--column", "c:"
+    });
+    log.info("Running TableToFile example");
+    TableToFile.main(new String[]{
+        "-i", instance,
+        "-z", keepers,
+        "-u", user,
+        "-p", passwd,
+        "-t", "sorted",
+        "--output", dir + "/tmp/tableFile"
+    });
+
+    log.info("Running word count example");
     c.tableOperations().create("wordCount");
     is = new IteratorSetting(10, SummingCombiner.class);
     SummingCombiner.setColumns(is, Collections.singletonList(new IteratorSetting.Column(new Text("count"))));
     SummingCombiner.setEncodingType(is, SummingCombiner.Type.STRING);
     c.tableOperations().attachIterator("wordCount", is);
     fs.copyFromLocalFile(new Path(new Path(System.getProperty("user.dir")).getParent(), "README"), new Path(dir + "/tmp/wc/README"));
-    goodExec(WordCount.class, "-i", instance, "-u", user, "-p", passwd, "-z", keepers, "--input", dir + "/tmp/wc", "-t", "wordCount");
-  }
-
-  @Test(timeout = 30 * 1000)
-  public void testInsertWithBatchWriterAndReadData() throws Exception {
-    String helloBatch = "helloBatch";
-    goodExec(InsertWithBatchWriter.class, "-i", instance, "-z", keepers, "-u", user, "-p", passwd, "-t", helloBatch);
-    goodExec(ReadData.class, "-i", instance, "-z", keepers, "-u", user, "-p", passwd, "-t", helloBatch);
-  }
-
-  @Test(timeout = 90 * 1000)
-  public void testIsolatedScansWithInterference() throws Exception {
-    goodExec(InterferenceTest.class, "-i", instance, "-z", keepers, "-u", user, "-p", passwd, "-t", "itest1", "--iterations", "100000", "--isolated");
-  }
-
-  @Test(timeout = 75 * 1000)
-  public void testScansWithInterference() throws Exception {
-    goodExec(InterferenceTest.class, "-i", instance, "-z", keepers, "-u", user, "-p", passwd, "-t", "itest2", "--iterations", "100000");
-  }
-
-  @Test(timeout = 5 * 1000)
-  public void testRowOperations() throws Exception {
-    goodExec(RowOperations.class, "-i", instance, "-z", keepers, "-u", user, "-p", passwd);
-  }
-
-  @Test(timeout = 6 * 1000)
-  public void testBatchWriter() throws Exception {
+    WordCount.main(new String[] {
+       "-i", instance,
+       "-u", user,
+       "-p", passwd,
+       "-z", keepers,
+       "--input", dir + "/tmp/wc",
+       "-t", "wordCount"
+    });
+
+    log.info("Inserting data with a batch writer");
+    InsertWithBatchWriter.main(new String[]{
+        "-i", instance,
+        "-z", keepers,
+        "-u", user,
+        "-p", passwd,
+        "-t", "helloBatch"
+    });
+    log.info("Reading data");
+    ReadData.main(new String[]{
+        "-i", instance,
+        "-z", keepers,
+        "-u", user,
+        "-p", passwd,
+        "-t", "helloBatch"
+    });
+    log.info("Running isolated scans");
+    InterferenceTest.main(new String[]{
+        "-i", instance,
+        "-z", keepers,
+        "-u", user,
+        "-p", passwd,
+        "-t", "itest1",
+        "--iterations", "100000",
+        "--isolated"
+    });
+    log.info("Running scans without isolation");
+    InterferenceTest.main(new String[]{
+        "-i", instance,
+        "-z", keepers,
+        "-u", user,
+        "-p", passwd,
+        "-t", "itest2",
+        "--iterations", "100000",
+    });
+    log.info("Performing some row operations");
+    RowOperations.main(new String[]{
+        "-i", instance,
+        "-z", keepers,
+        "-u", user,
+        "-p", passwd,
+    });
+    log.info("Using the batch writer");
     c.tableOperations().create("test");
-    goodExec(SequentialBatchWriter.class, "-i", instance, "-z", keepers, "-u", user, "-p", passwd, "-t", "test", "--start", "0", "--num", "100000", "--size",
-        "50", "--batchMemory", "10000000", "--batchLatency", "1000", "--batchThreads", "4", "--vis", visibility);
-
-  }
-
-  @Test(timeout = 12 * 1000)
-  public void testReadWriteAndDelete() throws Exception {
-    String test2 = "test2";
-    goodExec(ReadWriteExample.class, "-i", instance, "-z", keepers, "-u", user, "-p", passwd, "--auths", auths, "--table", test2, "--createtable", "-c",
-        "--debug");
-    goodExec(ReadWriteExample.class, "-i", instance, "-z", keepers, "-u", user, "-p", passwd, "--auths", auths, "--table", test2, "-d", "--debug");
+    SequentialBatchWriter.main(new String[] {
+        "-i", instance,
+        "-z", keepers,
+        "-u", user,
+        "-p", passwd,
+        "-t", "test",
+        "--start", "0",
+        "--num", "100000",
+        "--size", "50",
+        "--batchMemory", "10000000",
+        "--batchLatency", "1000",
+        "--batchThreads", "4",
+        "--vis", visibility
+    });
+
+    log.info("Reading and writing some data");
+    ReadWriteExample.main(new String[] {
+        "-i", instance,
+        "-z", keepers,
+        "-u", user,
+        "-p", passwd,
+        "--auths", auths,
+        "--table", "test2",
+        "--createtable",
+        "-c",
+        "--debug"});
+    log.info("Deleting some data");
+    ReadWriteExample.main(new String[] {
+        "-i", instance,
+        "-z", keepers,
+        "-u", user,
+        "-p", passwd,
+        "--auths", auths,
+        "--table", "test2",
+        "-d",
+        "--debug"});
+    log.info("Writing some data with the batch writer");
+    c.tableOperations().create("test3");
+    RandomBatchWriter.main(new String[] {
+        "-i", instance,
+        "-z", keepers,
+        "-u", user,
+        "-p", passwd,
+        "--table", "test3",
+        "--num", "100000",
+        "--min", "0",
+        "--max", "99999",
+        "--size", "100",
+        "--batchMemory", "1000000",
+        "--batchLatency", "1000",
+        "--batchThreads", "4",
+        "--vis", visibility});
+    log.info("Reading some data with the batch scanner");
+    RandomBatchScanner.main(new String[] {
+        "-i", instance,
+        "-z", keepers,
+        "-u", user,
+        "-p", passwd,
+        "--table", "test3",
+        "--num", "10000",
+        "--min", "0",
+        "--max", "99999",
+        "--size", "100",
+        "--scanThreads", "4",
+        "--auths", auths});
+    log.info("Running an example table operation (Flush)");
+    Flush.main(new String[]{
+        "-i", instance,
+        "-z", keepers,
+        "-u", user,
+        "-p", passwd,
+        "--table", "test3",
+    });
+    assertEquals(0, cluster.exec(Admin.class, "stopAll").waitFor());
 
   }
 
-  @Test(timeout = 20 * 1000)
-  public void testRandomBatchesAndFlush() throws Exception {
-    String test3 = "test3";
-    c.tableOperations().create(test3);
-    goodExec(RandomBatchWriter.class, "-i", instance, "-z", keepers, "-u", user, "-p", passwd, "--table", test3, "--num", "100000", "--min", "0", "--max",
-        "100000", "--size", "100", "--batchMemory", "1000000", "--batchLatency", "1000", "--batchThreads", "4", "--vis", visibility);
-    goodExec(RandomBatchScanner.class, "-i", instance, "-z", keepers, "-u", user, "-p", passwd, "--table", test3, "--num", "10000", "--min", "0", "--max",
-        "100000", "--size", "100", "--scanThreads", "4", "--auths", auths);
-    goodExec(Flush.class, "-i", instance, "-z", keepers, "-u", user, "-p", passwd, "--table", test3);
-  }
-
-  @AfterClass
-  public static void stop() throws Exception {
-    goodExec(Admin.class, "stopAll");
-    cleanUp(cluster);
-  }
-
-  private static Process goodExec(Class<?> theClass, String... args) throws InterruptedException, IOException {
-    return expectExec(0, theClass, args);
-  }
-
-  private static Process expectExec(int exitCode, Class<?> theClass, String... args) throws InterruptedException, IOException {
-    Process p = null;
-    assertEquals(exitCode, (p = cluster.exec(theClass, Collections.singletonList(MapReduceIT.hadoopTmpDirArg), args)).waitFor());
-    return p;
-  }
 }