diff --git a/addons/hive-bridge/src/test/java/org/apache/atlas/hive/hook/HiveHookIT.java b/addons/hive-bridge/src/test/java/org/apache/atlas/hive/hook/HiveHookIT.java
index c6a796531..f7290eec4 100755
--- a/addons/hive-bridge/src/test/java/org/apache/atlas/hive/hook/HiveHookIT.java
+++ b/addons/hive-bridge/src/test/java/org/apache/atlas/hive/hook/HiveHookIT.java
@@ -20,38 +20,25 @@ package org.apache.atlas.hive.hook;
 
 import com.google.common.base.Joiner;
 import com.google.common.collect.ImmutableList;
-import com.sun.jersey.api.client.ClientResponse;
 import org.apache.atlas.ApplicationProperties;
 import org.apache.atlas.AtlasClient;
-import org.apache.atlas.AtlasServiceException;
-import org.apache.atlas.fs.model.FSDataTypes;
 import org.apache.atlas.hive.bridge.HiveMetaStoreBridge;
 import org.apache.atlas.hive.model.HiveDataModelGenerator;
 import org.apache.atlas.hive.model.HiveDataTypes;
-import org.apache.atlas.hive.rewrite.HiveASTRewriter;
 import org.apache.atlas.typesystem.Referenceable;
 import org.apache.atlas.typesystem.Struct;
-import org.apache.atlas.typesystem.persistence.Id;
-import org.apache.atlas.typesystem.types.TypeSystem;
 import org.apache.atlas.utils.ParamChecker;
 import org.apache.commons.configuration.Configuration;
 import org.apache.commons.lang.RandomStringUtils;
+import org.apache.commons.lang.StringEscapeUtils;
 import org.apache.commons.lang.StringUtils;
-import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.metastore.TableType;
-import org.apache.hadoop.hive.metastore.api.hive_metastoreConstants;
-import org.apache.hadoop.hive.ql.CommandNeedRetryException;
 import org.apache.hadoop.hive.ql.Driver;
 import org.apache.hadoop.hive.ql.hooks.Entity;
-import org.apache.hadoop.hive.ql.hooks.ReadEntity;
-import org.apache.hadoop.hive.ql.hooks.WriteEntity;
-import org.apache.hadoop.hive.ql.metadata.Table;
-import org.apache.hadoop.hive.ql.plan.HiveOperation;
 import org.apache.hadoop.hive.ql.processors.CommandProcessorResponse;
 import org.apache.hadoop.hive.ql.session.SessionState;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.codehaus.jettison.json.JSONException;
+import org.codehaus.jettison.json.JSONArray;
 import org.codehaus.jettison.json.JSONObject;
 import org.slf4j.Logger;
 import org.testng.Assert;
@@ -59,62 +46,51 @@ import org.testng.annotations.BeforeClass;
 import org.testng.annotations.Test;
 
 import java.io.File;
-import java.text.ParseException;
-import java.util.ArrayList;
-import java.util.Date;
 import java.util.HashMap;
-import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Map;
-import java.util.SortedMap;
-import java.util.TreeMap;
-
-import static org.apache.atlas.AtlasClient.NAME;
-import static org.apache.atlas.hive.hook.HiveHook.entityComparator;
-import static org.apache.atlas.hive.hook.HiveHook.getProcessQualifiedName;
-import static org.apache.atlas.hive.hook.HiveHook.lower;
-import static org.apache.atlas.hive.hook.HiveHook.normalize;
+
 import static org.testng.Assert.assertEquals;
-import static org.testng.Assert.assertNotNull;
-import static org.testng.Assert.assertTrue;
-import static org.testng.Assert.fail;
 
 public class HiveHookIT {
-    private static final Logger LOG = org.slf4j.LoggerFactory.getLogger(HiveHookIT.class);
+    public static final Logger LOG = org.slf4j.LoggerFactory.getLogger(HiveHookIT.class);
 
     private static final String DGI_URL = "http://localhost:21000/";
     private static final String CLUSTER_NAME = "test";
     public static final String DEFAULT_DB = "default";
     private Driver driver;
-    private AtlasClient atlasClient;
-    private HiveMetaStoreBridge hiveMetaStoreBridge;
+    private AtlasClient dgiCLient;
     private SessionState ss;
 
-    private HiveConf conf;
-    
-    private static final String INPUTS = AtlasClient.PROCESS_ATTRIBUTE_INPUTS;
-    private static final String OUTPUTS = AtlasClient.PROCESS_ATTRIBUTE_OUTPUTS;
+    private enum QUERY_TYPE {
+        GREMLIN,
+        DSL
+    }
 
     @BeforeClass
     public void setUp() throws Exception {
         //Set-up hive session
-        conf = new HiveConf();
+        HiveConf conf = new HiveConf();
+        //Run in local mode
+        conf.set("mapreduce.framework.name", "local");
+        conf.set("fs.default.name", "file:///'");
         conf.setClassLoader(Thread.currentThread().getContextClassLoader());
         driver = new Driver(conf);
-        ss = new SessionState(conf);
+        ss = new SessionState(conf, System.getProperty("user.name"));
         ss = SessionState.start(ss);
-
         SessionState.setCurrentSessionState(ss);
 
         Configuration configuration = ApplicationProperties.get();
-        atlasClient = new AtlasClient(configuration.getString(HiveMetaStoreBridge.ATLAS_ENDPOINT, DGI_URL));
-
-        hiveMetaStoreBridge = new HiveMetaStoreBridge(conf, atlasClient);
+        HiveMetaStoreBridge hiveMetaStoreBridge = new HiveMetaStoreBridge(conf, configuration);
         hiveMetaStoreBridge.registerHiveDataModel();
+        dgiCLient = new AtlasClient(configuration.getString(HiveMetaStoreBridge.ATLAS_ENDPOINT, DGI_URL));
     }
 
     private void runCommand(String cmd) throws Exception {
-        runCommandWithDelay(cmd, 0);
+        LOG.debug("Running command '{}'", cmd);
+        ss.setCommandType(null);
+        CommandProcessorResponse response = driver.run(cmd);
+        assertEquals(response.getResponseCode(), 0);
     }
 
     @Test
@@ -123,7 +99,7 @@ public class HiveHookIT {
         runCommand("create database " + dbName + " WITH DBPROPERTIES ('p1'='v1', 'p2'='v2')");
         String dbId = assertDatabaseIsRegistered(dbName);
 
-        Referenceable definition = atlasClient.getEntity(dbId);
+        Referenceable definition = dgiCLient.getEntity(dbId);
         Map params = (Map) definition.get(HiveDataModelGenerator.PARAMETERS);
         Assert.assertNotNull(params);
         Assert.assertEquals(params.size(), 2);
@@ -131,14 +107,12 @@ public class HiveHookIT {
 
         //There should be just one entity per dbname
         runCommand("drop database " + dbName);
-        assertDBIsNotRegistered(dbName);
-
         runCommand("create database " + dbName);
         String dbid = assertDatabaseIsRegistered(dbName);
 
         //assert on qualified name
-        Referenceable dbEntity = atlasClient.getEntity(dbid);
-        Assert.assertEquals(dbEntity.get(AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME), dbName.toLowerCase() + "@" + CLUSTER_NAME);
+        Referenceable dbEntity = dgiCLient.getEntity(dbid);
+        Assert.assertEquals(dbEntity.get("qualifiedName"), dbName.toLowerCase() + "@" + CLUSTER_NAME);
 
     }
 
@@ -167,20 +141,14 @@ public class HiveHookIT {
     private String createTable(boolean isPartitioned) throws Exception {
         String tableName = tableName();
         runCommand("create table " + tableName + "(id int, name string) comment 'table comment' " + (isPartitioned ?
-                " partitioned by(dt string)" : ""));
+            " partitioned by(dt string)" : ""));
         return tableName;
     }
 
-    private String createTable(boolean isExternal, boolean isPartitioned, boolean isTemporary) throws Exception {
+    private String createTable(boolean isPartitioned, boolean isTemporary) throws Exception {
         String tableName = tableName();
-
-        String location = "";
-        if (isExternal) {
-            location = " location '" +  createTestDFSPath("someTestPath") + "'";
-        }
-        runCommand("create " + (isExternal ? " EXTERNAL " : "") + (isTemporary ? "TEMPORARY " : "") + "table " + tableName + "(id int, name string) comment 'table comment' " + (isPartitioned ?
-            " partitioned by(dt string)" : "") + location);
-
+        runCommand("create " + (isTemporary ? "TEMPORARY " : "") + "table " + tableName + "(id int, name string) comment 'table comment' " + (isPartitioned ?
+            " partitioned by(dt string)" : ""));
         return tableName;
     }
 
@@ -190,148 +158,42 @@ public class HiveHookIT {
         String dbName = createDatabase();
         String colName = columnName();
         runCommand("create table " + dbName + "." + tableName + "(" + colName + " int, name string)");
-        String tableId = assertTableIsRegistered(dbName, tableName);
+        assertTableIsRegistered(dbName, tableName);
 
         //there is only one instance of column registered
-        String colId = assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(
-                HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, dbName, tableName), colName));
-        Referenceable colEntity = atlasClient.getEntity(colId);
-        Assert.assertEquals(colEntity.get(AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME), String.format("%s.%s.%s@%s", dbName.toLowerCase(),
+        String colId = assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, dbName, tableName), colName));
+        Referenceable colEntity = dgiCLient.getEntity(colId);
+        Assert.assertEquals(colEntity.get("qualifiedName"), String.format("%s.%s.%s@%s", dbName.toLowerCase(),
                 tableName.toLowerCase(), colName.toLowerCase(), CLUSTER_NAME));
-        Assert.assertNotNull(colEntity.get(HiveDataModelGenerator.TABLE));
-        Assert.assertEquals(((Id) colEntity.get(HiveDataModelGenerator.TABLE))._getId(), tableId);
 
-        //assert that column.owner = table.owner
-        Referenceable tableRef = atlasClient.getEntity(tableId);
-        assertEquals(tableRef.get(AtlasClient.OWNER), colEntity.get(AtlasClient.OWNER));
-
-        //create table where db is not registered
         tableName = createTable();
-        tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-        tableRef = atlasClient.getEntity(tableId);
-        Assert.assertEquals(tableRef.get(HiveDataModelGenerator.TABLE_TYPE_ATTR), TableType.MANAGED_TABLE.name());
+        String tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
+        Referenceable tableRef = dgiCLient.getEntity(tableId);
+        Assert.assertEquals(tableRef.get("tableType"), TableType.MANAGED_TABLE.name());
         Assert.assertEquals(tableRef.get(HiveDataModelGenerator.COMMENT), "table comment");
         String entityName = HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName);
-        Assert.assertEquals(tableRef.get(AtlasClient.NAME), tableName.toLowerCase());
-        Assert.assertEquals(tableRef.get(AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME), entityName);
-
-        Table t = hiveMetaStoreBridge.hiveClient.getTable(DEFAULT_DB, tableName);
-        long createTime = Long.parseLong(t.getMetadata().getProperty(hive_metastoreConstants.DDL_TIME)) * HiveMetaStoreBridge.MILLIS_CONVERT_FACTOR;
-
-        verifyTimestamps(tableRef, HiveDataModelGenerator.CREATE_TIME, createTime);
-        verifyTimestamps(tableRef, HiveDataModelGenerator.LAST_ACCESS_TIME, createTime);
+        Assert.assertEquals(tableRef.get(HiveDataModelGenerator.NAME), entityName);
+        Assert.assertEquals(tableRef.get(HiveDataModelGenerator.NAME), "default." + tableName.toLowerCase() + "@" + CLUSTER_NAME);
 
-        final Referenceable sdRef = (Referenceable) tableRef.get(HiveDataModelGenerator.STORAGE_DESC);
+        final Referenceable sdRef = (Referenceable) tableRef.get("sd");
         Assert.assertEquals(sdRef.get(HiveDataModelGenerator.STORAGE_IS_STORED_AS_SUB_DIRS), false);
-        Assert.assertNotNull(sdRef.get(HiveDataModelGenerator.TABLE));
-        Assert.assertEquals(((Id) sdRef.get(HiveDataModelGenerator.TABLE))._getId(), tableId);
 
         //Create table where database doesn't exist, will create database instance as well
         assertDatabaseIsRegistered(DEFAULT_DB);
     }
 
-    private void verifyTimestamps(Referenceable ref, String property, long expectedTime) throws ParseException {
-        //Verify timestamps.
-        String createTimeStr = (String) ref.get(property);
-        Date createDate = TypeSystem.getInstance().getDateFormat().parse(createTimeStr);
-        Assert.assertNotNull(createTimeStr);
-
-        if (expectedTime > 0) {
-            Assert.assertEquals(expectedTime, createDate.getTime());
-        }
-    }
-
-    private void verifyTimestamps(Referenceable ref, String property) throws ParseException {
-        verifyTimestamps(ref, property, 0);
-    }
-
-    @Test
-    public void testCreateExternalTable() throws Exception {
-        String tableName = tableName();
-        String colName = columnName();
-
-        String pFile = createTestDFSPath("parentPath");
-        final String query = String.format("create TEMPORARY EXTERNAL table %s.%s( %s, %s) location '%s'", DEFAULT_DB , tableName , colName + " int", "name string",  pFile);
-        runCommand(query);
-        assertTableIsRegistered(DEFAULT_DB, tableName, null, true);
-        String processId = assertEntityIsRegistered(HiveDataTypes.HIVE_PROCESS.getName(), AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME,
-                HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName, true), null);
-        Referenceable processReference = atlasClient.getEntity(processId);
-        assertEquals(processReference.get("userName"), UserGroupInformation.getCurrentUser().getShortUserName());
-
-        verifyTimestamps(processReference, "startTime");
-        verifyTimestamps(processReference, "endTime");
-
-        validateHDFSPaths(processReference, INPUTS, pFile);
-    }
-
-    private List<Entity> getInputs(String inputName, Entity.Type entityType) {
-        final ReadEntity entity = new ReadEntity();
-
-        if ( Entity.Type.DFS_DIR.equals(entityType)) {
-            entity.setName(lower(new Path(inputName).toString()));
-            entity.setTyp(Entity.Type.DFS_DIR);
-        } else {
-            entity.setName(getQualifiedTblName(inputName));
-            entity.setTyp(Entity.Type.TABLE);
-        }
-
-        return new ArrayList<Entity>() {{ add(entity); }};
-    }
-
-
-    private List<Entity> getOutputs(String inputName, Entity.Type entityType) {
-        final WriteEntity entity = new WriteEntity();
-
-        if ( Entity.Type.DFS_DIR.equals(entityType) || Entity.Type.LOCAL_DIR.equals(entityType)) {
-            entity.setName(lower(new Path(inputName).toString()));
-            entity.setTyp(entityType);
-        } else {
-            entity.setName(getQualifiedTblName(inputName));
-            entity.setTyp(Entity.Type.TABLE);
-        }
-
-        return new ArrayList<Entity>() {{ add(entity); }};
-    }
-
-
-    private void validateOutputTables(Referenceable processReference, List<Entity> expectedTables) throws Exception {
-       validateTables(processReference, OUTPUTS, expectedTables);
-    }
-
-    private void validateInputTables(Referenceable processReference, List<Entity> expectedTables) throws Exception {
-        validateTables(processReference, INPUTS, expectedTables);
-    }
-
-    private void validateTables(Referenceable processReference, String attrName, List<Entity> expectedTables) throws Exception {
-        List<Id> tableRef = (List<Id>) processReference.get(attrName);
-        for(int i = 0; i < expectedTables.size(); i++) {
-            Referenceable entity = atlasClient.getEntity(tableRef.get(i)._getId());
-            LOG.debug("Validating output {} {} ", i, entity);
-            Assert.assertEquals(entity.get(AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME), expectedTables.get(i).getName());
-        }
-    }
-
     private String assertColumnIsRegistered(String colName) throws Exception {
-        return assertColumnIsRegistered(colName, null);
-    }
-
-    private String assertColumnIsRegistered(String colName, AssertPredicate assertPredicate) throws Exception {
-        LOG.debug("Searching for column {}", colName);
-        return assertEntityIsRegistered(HiveDataTypes.HIVE_COLUMN.getName(), AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME,
-            colName, assertPredicate);
-    }
-
-    private String assertSDIsRegistered(String sdQFName, AssertPredicate assertPredicate) throws Exception {
-        LOG.debug("Searching for sd {}", sdQFName.toLowerCase());
-        return assertEntityIsRegistered(HiveDataTypes.HIVE_STORAGEDESC.getName(), AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME,
-            sdQFName.toLowerCase(), assertPredicate);
+        LOG.debug("Searching for column {}", colName.toLowerCase());
+        String query =
+                String.format("%s where qualifiedName = '%s'", HiveDataTypes.HIVE_COLUMN.getName(), colName.toLowerCase());
+        return assertEntityIsRegistered(query);
     }
 
     private void assertColumnIsNotRegistered(String colName) throws Exception {
         LOG.debug("Searching for column {}", colName);
-        assertEntityIsNotRegistered(HiveDataTypes.HIVE_COLUMN.getName(), AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME,
-            colName);
+        String query =
+            String.format("%s where qualifiedName = '%s'", HiveDataTypes.HIVE_COLUMN.getName(), colName.toLowerCase());
+        assertEntityIsNotRegistered(QUERY_TYPE.DSL, query);
     }
 
     @Test
@@ -341,50 +203,10 @@ public class HiveHookIT {
         String query = "create table " + ctasTableName + " as select * from " + tableName;
         runCommand(query);
 
-        final ReadEntity entity = new ReadEntity();
-        entity.setName(getQualifiedTblName(tableName));
-        entity.setTyp(Entity.Type.TABLE);
-
-        final WriteEntity writeEntity = new WriteEntity();
-        writeEntity.setTyp(Entity.Type.TABLE);
-        writeEntity.setName(getQualifiedTblName(ctasTableName));
-
-        assertProcessIsRegistered(query, HiveOperation.CREATETABLE_AS_SELECT, new ArrayList<Entity>() {{ add(entity); }}, new ArrayList<Entity>() {{ add(writeEntity); }});
+        assertProcessIsRegistered(query);
         assertTableIsRegistered(DEFAULT_DB, ctasTableName);
     }
 
-    @Test
-    public void testDropAndRecreateCTASOutput() throws Exception {
-        String tableName = createTable();
-        String ctasTableName = "table" + random();
-        String query = "create table " + ctasTableName + " as select * from " + tableName;
-        runCommand(query);
-
-        assertTableIsRegistered(DEFAULT_DB, ctasTableName);
-
-        List<Entity> inputs = getInputs(tableName, Entity.Type.TABLE);
-        List<Entity> outputs =  getOutputs(ctasTableName, Entity.Type.TABLE);
-
-        String processId = assertProcessIsRegistered(query, HiveOperation.CREATETABLE_AS_SELECT, inputs, outputs);
-
-        final String drpquery = String.format("drop table %s ", ctasTableName);
-        runCommand(drpquery);
-        assertTableIsNotRegistered(DEFAULT_DB, ctasTableName);
-
-        //Fix after ATLAS-876
-        runCommand(query);
-        assertTableIsRegistered(DEFAULT_DB, ctasTableName);
-        String process2Id = assertProcessIsRegistered(query, HiveOperation.CREATETABLE_AS_SELECT, inputs, outputs);
-
-        Assert.assertEquals(process2Id, processId);
-
-        Referenceable processRef = atlasClient.getEntity(processId);
-
-        validateInputTables(processRef, inputs);
-        outputs.add(outputs.get(0));
-        validateOutputTables(processRef, outputs);
-    }
-
     @Test
     public void testCreateView() throws Exception {
         String tableName = createTable();
@@ -392,7 +214,7 @@ public class HiveHookIT {
         String query = "create view " + viewName + " as select * from " + tableName;
         runCommand(query);
 
-        assertProcessIsRegistered(query, HiveOperation.CREATEVIEW, getInputs(tableName, Entity.Type.TABLE), getOutputs(viewName, Entity.Type.TABLE));
+        assertProcessIsRegistered(query);
         assertTableIsRegistered(DEFAULT_DB, viewName);
     }
 
@@ -406,15 +228,15 @@ public class HiveHookIT {
         runCommand(query);
 
         String table1Id = assertTableIsRegistered(DEFAULT_DB, table1Name);
-        assertProcessIsRegistered(query, HiveOperation.CREATEVIEW, getInputs(table1Name, Entity.Type.TABLE), getOutputs(viewName, Entity.Type.TABLE));
+        assertProcessIsRegistered(query);
         String viewId = assertTableIsRegistered(DEFAULT_DB, viewName);
 
         //Check lineage which includes table1
         String datasetName = HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, viewName);
-        JSONObject response = atlasClient.getInputGraph(datasetName);
+        JSONObject response = dgiCLient.getInputGraph(datasetName);
         JSONObject vertices = response.getJSONObject("values").getJSONObject("vertices");
-        assertTrue(vertices.has(viewId));
-        assertTrue(vertices.has(table1Id));
+        Assert.assertTrue(vertices.has(viewId));
+        Assert.assertTrue(vertices.has(table1Id));
 
         //Alter the view from table2
         String table2Name = createTable();
@@ -422,104 +244,53 @@ public class HiveHookIT {
         runCommand(query);
 
         //Check if alter view process is reqistered
-        assertProcessIsRegistered(query, HiveOperation.CREATEVIEW, getInputs(table2Name, Entity.Type.TABLE), getOutputs(viewName, Entity.Type.TABLE));
+        assertProcessIsRegistered(query);
         String table2Id = assertTableIsRegistered(DEFAULT_DB, table2Name);
         Assert.assertEquals(assertTableIsRegistered(DEFAULT_DB, viewName), viewId);
 
         datasetName = HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, viewName);
-        response = atlasClient.getInputGraph(datasetName);
+        response = dgiCLient.getInputGraph(datasetName);
         vertices = response.getJSONObject("values").getJSONObject("vertices");
-        assertTrue(vertices.has(viewId));
+        Assert.assertTrue(vertices.has(viewId));
 
         //This is through the alter view process
-        assertTrue(vertices.has(table2Id));
+        Assert.assertTrue(vertices.has(table2Id));
 
         //This is through the Create view process
-        assertTrue(vertices.has(table1Id));
+        Assert.assertTrue(vertices.has(table1Id));
 
         //Outputs dont exist
-        response = atlasClient.getOutputGraph(datasetName);
+        response = dgiCLient.getOutputGraph(datasetName);
         vertices = response.getJSONObject("values").getJSONObject("vertices");
         Assert.assertEquals(vertices.length(), 0);
     }
 
-    private String createTestDFSPath(String path) throws Exception {
-        return "pfile://" + mkdir(path);
-    }
-
-    private String createTestDFSFile(String path) throws Exception {
-        return "pfile://" + file(path);
-    }
 
     @Test
-    public void testLoadLocalPath() throws Exception {
+    public void testLoadData() throws Exception {
         String tableName = createTable(false);
 
         String loadFile = file("load");
         String query = "load data local inpath 'file://" + loadFile + "' into table " + tableName;
         runCommand(query);
 
-        List<Entity> outputs = getOutputs(tableName, Entity.Type.TABLE);
-
-        assertProcessIsRegistered(query, HiveOperation.LOAD, null, outputs);
+        assertProcessIsRegistered(query);
     }
 
     @Test
-    public void testLoadLocalPathIntoPartition() throws Exception {
+    public void testLoadDataIntoPartition() throws Exception {
         String tableName = createTable(true);
 
         String loadFile = file("load");
         String query = "load data local inpath 'file://" + loadFile + "' into table " + tableName +  " partition(dt = '2015-01-01')";
         runCommand(query);
 
-        validateProcess(query, HiveOperation.LOAD, null, getOutputs(tableName, Entity.Type.TABLE));
-    }
-
-    @Test
-    public void testLoadDFSPath() throws Exception {
-        String tableName = createTable(true, true, false);
-
-        String tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-
-        String loadFile = createTestDFSFile("loadDFSFile");
-        String query = "load data inpath '" + loadFile + "' into table " + tableName + " partition(dt = '2015-01-01')";
-        runCommand(query);
-
-        final List<Entity> outputs = getOutputs(tableName, Entity.Type.TABLE);
-        Referenceable processReference = validateProcess(query, HiveOperation.LOAD, getInputs(loadFile, Entity.Type.DFS_DIR), outputs);
-
-        validateHDFSPaths(processReference, INPUTS, loadFile);
+        String processId = assertProcessIsRegistered(query);
+        Referenceable process = dgiCLient.getEntity(processId);
+        Assert.assertNull(process.get("inputs"));
 
-        validateOutputTables(processReference, outputs);
-    }
-
-    private String getQualifiedTblName(String inputTable) {
-        String inputtblQlfdName = inputTable;
-
-        if (inputTable != null && !inputTable.contains(".")) {
-            inputtblQlfdName = HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, inputTable);
-        }
-        return inputtblQlfdName;
-    }
-
-    private Referenceable validateProcess(String query, HiveOperation op, List<Entity> inputTables, List<Entity> outputTables) throws Exception {
-        String processId = assertProcessIsRegistered(query, op, inputTables, outputTables);
-        Referenceable process = atlasClient.getEntity(processId);
-        if (inputTables == null) {
-            Assert.assertNull(process.get(INPUTS));
-        } else {
-            Assert.assertEquals(((List<Referenceable>) process.get(INPUTS)).size(), inputTables.size());
-            validateInputTables(process, inputTables);
-        }
-
-        if (outputTables == null) {
-            Assert.assertNull(process.get(OUTPUTS));
-        } else {
-            Assert.assertEquals(((List<Id>) process.get(OUTPUTS)).size(), outputTables.size());
-            validateOutputTables(process, outputTables);
-        }
-
-        return process;
+        System.out.println(" Ref Ops : " + process.get("outputs"));
+        Assert.assertEquals(((List<Referenceable>) process.get("outputs")).size(), 1);
     }
 
     @Test
@@ -530,22 +301,13 @@ public class HiveHookIT {
                 "insert into " + insertTableName + " select id, name from " + tableName;
 
         runCommand(query);
+        String processId = assertProcessIsRegistered(query);
+        Referenceable process = dgiCLient.getEntity(processId);
+        Assert.assertEquals(((List<Referenceable>) process.get("inputs")).size(), 1);
+        Assert.assertEquals(((List<Referenceable>) process.get("outputs")).size(), 1);
 
-        String inputTableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-        String opTableId = assertTableIsRegistered(DEFAULT_DB, insertTableName);
-
-        List<Entity> inputs = getInputs(tableName, Entity.Type.TABLE);
-        List<Entity> outputs = getOutputs(insertTableName, Entity.Type.TABLE);
-        ((WriteEntity)outputs.get(0)).setWriteType(WriteEntity.WriteType.INSERT);
-
-        Referenceable processRef1 = validateProcess(query, HiveOperation.QUERY, inputs, outputs);
-
-        //Rerun same query. Should result in same process
-        runCommand(query);
-
-        Referenceable processRef2 = validateProcess(query, HiveOperation.QUERY, inputs, outputs);
-        Assert.assertEquals(processRef1.getId()._getId(), processRef2.getId()._getId());
-
+        assertTableIsRegistered(DEFAULT_DB, tableName);
+        assertTableIsRegistered(DEFAULT_DB, insertTableName);
     }
 
     @Test
@@ -556,112 +318,45 @@ public class HiveHookIT {
             "insert overwrite LOCAL DIRECTORY '" + randomLocalPath.getAbsolutePath() + "' select id, name from " + tableName;
 
         runCommand(query);
-        validateProcess(query, HiveOperation.QUERY, getInputs(tableName, Entity.Type.TABLE), null);
+        String processId = assertProcessIsRegistered(query);
+        Referenceable process = dgiCLient.getEntity(processId);
+        Assert.assertEquals(((List<Referenceable>) process.get("inputs")).size(), 1);
+        Assert.assertNull(process.get("outputs"));
 
         assertTableIsRegistered(DEFAULT_DB, tableName);
     }
 
-    @Test
-    public void testUpdateProcess() throws Exception {
-        String tableName = createTable();
-        String pFile1 = createTestDFSPath("somedfspath1");
-        String query =
-            "insert overwrite DIRECTORY '" + pFile1  + "' select id, name from " + tableName;
-
-        runCommand(query);
-
-        List<Entity> inputs = getInputs(tableName, Entity.Type.TABLE);
-        final List<Entity> outputs = getOutputs(pFile1, Entity.Type.DFS_DIR);
-        ((WriteEntity)outputs.get(0)).setWriteType(WriteEntity.WriteType.PATH_WRITE);
-
-        Referenceable processReference = validateProcess(query, HiveOperation.QUERY, inputs, outputs);
-        validateHDFSPaths(processReference, OUTPUTS, pFile1);
-
-        String tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-        validateInputTables(processReference, inputs);
-
-        //Rerun same query with same HDFS path
-
-        runCommand(query);
-        Referenceable process2Reference = validateProcess(query,  HiveOperation.QUERY, inputs, outputs);
-        validateHDFSPaths(process2Reference, OUTPUTS, pFile1);
-
-        Assert.assertEquals(process2Reference.getId()._getId(), processReference.getId()._getId());
-
-        //Rerun same query with a new HDFS path. Will result in same process since HDFS paths are not part of qualifiedName.
-        final String pFile2 = createTestDFSPath("somedfspath2");
-        query = "insert overwrite DIRECTORY '" + pFile2  + "' select id, name from " + tableName;
-        runCommand(query);
-        List<Entity> p3Outputs = new ArrayList<Entity>() {{
-            addAll(getOutputs(pFile2, Entity.Type.DFS_DIR));
-            addAll(outputs);
-        }};
-
-        Referenceable process3Reference = validateProcess(query,  HiveOperation.QUERY, inputs, p3Outputs);
-        validateHDFSPaths(process3Reference, OUTPUTS, pFile2);
-
-        Assert.assertEquals(process3Reference.getId()._getId(), processReference.getId()._getId());
-    }
-
     @Test
     public void testInsertIntoDFSDir() throws Exception {
         String tableName = createTable();
-        String pFile1 = createTestDFSPath("somedfspath1");
+        String pFile = "pfile://" + mkdir("somedfspath");
         String query =
-            "insert overwrite DIRECTORY '" + pFile1  + "' select id, name from " + tableName;
+            "insert overwrite DIRECTORY '" + pFile  + "' select id, name from " + tableName;
 
         runCommand(query);
+        String processId = assertProcessIsRegistered(query);
+        Referenceable process = dgiCLient.getEntity(processId);
+        Assert.assertEquals(((List<Referenceable>) process.get("inputs")).size(), 1);
+        Assert.assertNull(process.get("outputs"));
 
-        List<Entity> inputs = getInputs(tableName, Entity.Type.TABLE);
-        final List<Entity> outputs = getOutputs(pFile1, Entity.Type.DFS_DIR);
-        ((WriteEntity)outputs.get(0)).setWriteType(WriteEntity.WriteType.PATH_WRITE);
-
-        Referenceable processReference = validateProcess(query,  HiveOperation.QUERY, inputs, outputs);
-        validateHDFSPaths(processReference, OUTPUTS, pFile1);
-
-        String tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-
-        validateInputTables(processReference, inputs);
-
-        //Rerun same query with different HDFS path
-
-        final String pFile2 = createTestDFSPath("somedfspath2");
-        query =
-            "insert overwrite DIRECTORY '" + pFile2  + "' select id, name from " + tableName;
-
-        runCommand(query);
-        List<Entity> p2Outputs = new ArrayList<Entity>() {{
-            addAll(getOutputs(pFile2, Entity.Type.DFS_DIR));
-            addAll(outputs);
-        }};
-
-        Referenceable process2Reference = validateProcess(query, HiveOperation.QUERY, inputs, p2Outputs);
-        validateHDFSPaths(process2Reference, OUTPUTS, pFile2);
-
-        Assert.assertEquals(process2Reference.getId()._getId(), processReference.getId()._getId());
+        assertTableIsRegistered(DEFAULT_DB, tableName);
     }
 
     @Test
     public void testInsertIntoTempTable() throws Exception {
         String tableName = createTable();
-        String insertTableName = createTable(false, false, true);
-        assertTableIsRegistered(DEFAULT_DB, tableName);
-        assertTableIsNotRegistered(DEFAULT_DB, insertTableName, true);
-
+        String insertTableName = createTable(false, true);
         String query =
             "insert into " + insertTableName + " select id, name from " + tableName;
 
         runCommand(query);
-
-        List<Entity> inputs = getInputs(tableName, Entity.Type.TABLE);
-        List<Entity> outputs = getOutputs(insertTableName, Entity.Type.TABLE);
-        outputs.get(0).setName(getQualifiedTblName(insertTableName + HiveMetaStoreBridge.TEMP_TABLE_PREFIX + SessionState.get().getSessionId()));
-        ((WriteEntity)outputs.get(0)).setWriteType(WriteEntity.WriteType.INSERT);
-
-        validateProcess(query,  HiveOperation.QUERY, inputs, outputs);
+        String processId = assertProcessIsRegistered(query);
+        Referenceable process = dgiCLient.getEntity(processId);
+        Assert.assertEquals(((List<Referenceable>) process.get("inputs")).size(), 1);
+        Assert.assertEquals(((List<Referenceable>) process.get("outputs")).size(), 1);
 
         assertTableIsRegistered(DEFAULT_DB, tableName);
-        assertTableIsRegistered(DEFAULT_DB, insertTableName, null, true);
+        assertTableIsRegistered(DEFAULT_DB, insertTableName);
     }
 
     @Test
@@ -672,15 +367,10 @@ public class HiveHookIT {
             "insert into " + insertTableName + " partition(dt = '2015-01-01') select id, name from " + tableName
                 + " where dt = '2015-01-01'";
         runCommand(query);
-
-        List<Entity> inputs = getInputs(tableName, Entity.Type.TABLE);
-        List<Entity> outputs = getOutputs(insertTableName, Entity.Type.TABLE);
-        ((WriteEntity)outputs.get(0)).setWriteType(WriteEntity.WriteType.INSERT);
-
-        validateProcess(query,  HiveOperation.QUERY, inputs, outputs);
-
-        assertTableIsRegistered(DEFAULT_DB, tableName);
-        assertTableIsRegistered(DEFAULT_DB, insertTableName);
+        String processId = assertProcessIsRegistered(query);
+        Referenceable process = dgiCLient.getEntity(processId);
+        Assert.assertEquals(((List<Referenceable>) process.get("inputs")).size(), 1);
+        Assert.assertEquals(((List<Referenceable>) process.get("outputs")).size(), 1);
     }
 
     private String random() {
@@ -702,70 +392,19 @@ public class HiveHookIT {
     }
 
     @Test
-    public void testExportImportUnPartitionedTable() throws Exception {
+    public void testExportImport() throws Exception {
         String tableName = createTable(false);
 
-        assertTableIsRegistered(DEFAULT_DB, tableName);
-
         String filename = "pfile://" + mkdir("export");
         String query = "export table " + tableName + " to \"" + filename + "\"";
         runCommand(query);
+        assertProcessIsRegistered(query);
 
-        List<Entity> inputs = getInputs(tableName, Entity.Type.TABLE);
-        List<Entity> outputs = getOutputs(filename, Entity.Type.DFS_DIR);
-
-        Referenceable processReference = validateProcess(query, HiveOperation.EXPORT, inputs, outputs);
-
-        validateHDFSPaths(processReference, OUTPUTS, filename);
-        validateInputTables(processReference, inputs);
-
-        //Import
         tableName = createTable(false);
-        assertTableIsRegistered(DEFAULT_DB, tableName);
 
         query = "import table " + tableName + " from '" + filename + "'";
         runCommand(query);
-        outputs = getOutputs(tableName, Entity.Type.TABLE);
-        processReference = validateProcess(query, HiveOperation.IMPORT, getInputs(filename, Entity.Type.DFS_DIR), outputs);
-        validateHDFSPaths(processReference, INPUTS, filename);
-
-        validateOutputTables(processReference, outputs);
-    }
-
-    @Test
-    public void testExportImportPartitionedTable() throws Exception {
-        String tableName = createTable(true);
-        String tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-
-        //Add a partition
-        String partFile = "pfile://" + mkdir("partition");
-        String query = "alter table " + tableName + " add partition (dt='2015-01-01') location '" + partFile + "'";
-        runCommand(query);
-
-        String filename = "pfile://" + mkdir("export");
-        query = "export table " + tableName + " to \"" + filename + "\"";
-        runCommand(query);
-
-        List<Entity> inputs = getInputs(tableName, Entity.Type.TABLE);
-        List<Entity> outputs = getOutputs(filename, Entity.Type.DFS_DIR);
-
-        Referenceable processReference = validateProcess(query, HiveOperation.EXPORT, inputs, outputs);
-        validateHDFSPaths(processReference, OUTPUTS, filename);
-
-        validateInputTables(processReference, inputs);
-
-        //Import
-        tableName = createTable(true);
-        tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-
-        query = "import table " + tableName + " from '" + filename + "'";
-        runCommand(query);
-
-        outputs = getOutputs(tableName, Entity.Type.TABLE);
-        processReference = validateProcess(query, HiveOperation.IMPORT, getInputs(filename, Entity.Type.DFS_DIR), outputs);
-        validateHDFSPaths(processReference, INPUTS, filename);
-
-        validateOutputTables(processReference, outputs);
+        assertProcessIsRegistered(query);
     }
 
     @Test
@@ -773,111 +412,29 @@ public class HiveHookIT {
         String tableName = createTable();
         String query = "select * from " + tableName;
         runCommand(query);
-        List<Entity> inputs = getInputs(tableName, Entity.Type.TABLE);
-        assertProcessIsNotRegistered(query, HiveOperation.QUERY, inputs, null);
+        assertProcessIsNotRegistered(query);
 
         //check with uppercase table name
         query = "SELECT * from " + tableName.toUpperCase();
         runCommand(query);
-        assertProcessIsNotRegistered(query, HiveOperation.QUERY, inputs, null);
-    }
-
-    @Test
-    public void testAlterTableRenameAliasRegistered() throws Exception{
-        String tableName = createTable(false);
-        String tableGuid = assertTableIsRegistered(DEFAULT_DB, tableName);
-        String newTableName = tableName();
-        String query = String.format("alter table %s rename to %s", tableName, newTableName);
-        runCommand(query);
-        String newTableGuid = assertTableIsRegistered(DEFAULT_DB, newTableName);
-        Map<String, Object> valueMap = atlasClient.getEntity(newTableGuid).getValuesMap();
-        Iterable<String> aliasList = (Iterable<String>) valueMap.get("aliases");
-        String aliasTableName = aliasList.iterator().next();
-        assert tableName.toLowerCase().equals(aliasTableName);
+        assertProcessIsNotRegistered(query);
     }
 
     @Test
     public void testAlterTableRename() throws Exception {
-        String tableName = createTable(true);
-        final String newDBName = createDatabase();
-
-        String tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-        Referenceable tableEntity = atlasClient.getEntity(tableId);
-        final String createTime = (String)tableEntity.get(HiveDataModelGenerator.CREATE_TIME);
-        Assert.assertNotNull(createTime);
-
-        String columnGuid = assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), NAME));
-        String sdGuid = assertSDIsRegistered(HiveMetaStoreBridge.getStorageDescQFName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName)), null);
-        assertDatabaseIsRegistered(newDBName);
-
-        //Add trait to column
-        String colTraitDetails = createTrait(columnGuid);
-
-        //Add trait to sd
-        String sdTraitDetails = createTrait(sdGuid);
-
-        String partColumnGuid = assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), "dt"));
-        //Add trait to part col keys
-        String partColTraitDetails = createTrait(partColumnGuid);
-
-        final String newTableName = tableName();
-        String query = String.format("alter table %s rename to %s", DEFAULT_DB + "." + tableName, newDBName + "." + newTableName);
-        runCommandWithDelay(query, 1000);
-
-        String newColGuid = assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, newDBName, newTableName), NAME));
-        Assert.assertEquals(newColGuid, columnGuid);
-
-        assertColumnIsNotRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, newDBName, tableName), NAME));
-
-        assertTrait(columnGuid, colTraitDetails);
-        String newSdGuid = assertSDIsRegistered(HiveMetaStoreBridge.getStorageDescQFName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, newDBName, newTableName)), null);
-        Assert.assertEquals(newSdGuid, sdGuid);
-
-        assertTrait(sdGuid, sdTraitDetails);
-        assertTrait(partColumnGuid, partColTraitDetails);
+        String tableName = createTable();
+        String newName = tableName();
+        String query = "alter table " + tableName + " rename to " + newName;
+        runCommand(query);
 
+        assertTableIsRegistered(DEFAULT_DB, newName);
         assertTableIsNotRegistered(DEFAULT_DB, tableName);
-
-        assertTableIsRegistered(newDBName, newTableName, new AssertPredicate() {
-            @Override
-            public void assertOnEntity(final Referenceable entity) throws Exception {
-                Referenceable sd = ((Referenceable) entity.get(HiveDataModelGenerator.STORAGE_DESC));
-                String location = (String) sd.get(HiveDataModelGenerator.LOCATION);
-                assertTrue(location.contains(newTableName));
-                Assert.assertEquals(entity.get(HiveDataModelGenerator.CREATE_TIME), createTime);
-            }
-        });
     }
 
     private List<Referenceable> getColumns(String dbName, String tableName) throws Exception {
         String tableId = assertTableIsRegistered(dbName, tableName);
-        Referenceable tableRef = atlasClient.getEntity(tableId);
-
-        //with soft delete, the deleted columns are returned as well. So, filter the deleted ones
-        List<Referenceable> columns = ((List<Referenceable>) tableRef.get(HiveDataModelGenerator.COLUMNS));
-        List<Referenceable> activeColumns = new ArrayList<>();
-        for (Referenceable col : columns) {
-            if (col.getId().getState() == Id.EntityState.ACTIVE) {
-                activeColumns.add(col);
-            }
-        }
-        return activeColumns;
-    }
-
-
-    private String createTrait(String guid) throws AtlasServiceException, JSONException {
-        //add trait
-        String traitName = "PII_Trait" + RandomStringUtils.random(10);
-        atlasClient.createTraitType(traitName);
-
-        Struct traitInstance = new Struct(traitName);
-        atlasClient.addTrait(guid, traitInstance);
-        return traitName;
-    }
-
-    private void assertTrait(String guid, String traitName) throws AtlasServiceException, JSONException {
-        List<String> traits = atlasClient.listTraits(guid);
-        Assert.assertEquals(traits.get(0), traitName);
+        Referenceable tableRef = dgiCLient.getEntity(tableId);
+        return ((List<Referenceable>)tableRef.get(HiveDataModelGenerator.COLUMNS));
     }
 
     @Test
@@ -887,9 +444,7 @@ public class HiveHookIT {
         String query = "alter table " + tableName + " add columns (" + column + " string)";
         runCommand(query);
 
-        assertColumnIsRegistered(HiveMetaStoreBridge
-            .getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName),
-                column));
+        assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), column));
 
         //Verify the number of columns present in the table
         final List<Referenceable> columns = getColumns(DEFAULT_DB, tableName);
@@ -902,229 +457,93 @@ public class HiveHookIT {
         final String colDropped = "id";
         String query = "alter table " + tableName + " replace columns (name string)";
         runCommand(query);
-
-        assertColumnIsNotRegistered(HiveMetaStoreBridge
-            .getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName),
-                colDropped));
+        assertColumnIsNotRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), colDropped));
 
         //Verify the number of columns present in the table
-        List<Referenceable> columns = getColumns(DEFAULT_DB, tableName);
-        assertEquals(columns.size(), 1);
-        assertEquals(columns.get(0).get(NAME), "name");
+        final List<Referenceable> columns = getColumns(DEFAULT_DB, tableName);
+        Assert.assertEquals(columns.size(), 1);
+
+        Assert.assertEquals(columns.get(0).get(HiveDataModelGenerator.NAME), "name");
     }
 
     @Test
     public void testAlterTableChangeColumn() throws Exception {
         //Change name
-        String oldColName = NAME;
+        String oldColName = "name";
         String newColName = "name1";
         String tableName = createTable();
         String query = String.format("alter table %s change %s %s string", tableName, oldColName, newColName);
-        runCommandWithDelay(query, 1000);
-
-        assertColumnIsNotRegistered(HiveMetaStoreBridge.getColumnQualifiedName(
-                HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), oldColName));
-        assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(
-                HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), newColName));
+        runCommand(query);
+        assertColumnIsNotRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), oldColName));
+        assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), newColName));
 
         //Verify the number of columns present in the table
         List<Referenceable> columns = getColumns(DEFAULT_DB, tableName);
         Assert.assertEquals(columns.size(), 2);
-
         //Change column type
         oldColName = "name1";
         newColName = "name2";
         final String newColType = "int";
         query = String.format("alter table %s change column %s %s %s", tableName, oldColName, newColName, newColType);
-        runCommandWithDelay(query, 1000);
+        runCommand(query);
 
         columns = getColumns(DEFAULT_DB, tableName);
         Assert.assertEquals(columns.size(), 2);
+        assertColumnIsNotRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), oldColName));
 
-        String newColQualifiedName = HiveMetaStoreBridge.getColumnQualifiedName(
-                HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), newColName);
-        assertColumnIsRegistered(newColQualifiedName, new AssertPredicate() {
-            @Override
-            public void assertOnEntity(Referenceable entity) throws Exception {
-                assertEquals(entity.get("type"), "int");
-            }
-        });
+        String newColQualifiedName = HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), newColName);
+        assertColumnIsRegistered(newColQualifiedName);
 
-        assertColumnIsNotRegistered(HiveMetaStoreBridge.getColumnQualifiedName(
-            HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), oldColName));
+        Assert.assertEquals(columns.get(1).get("type"), "int");
 
         //Change name and add comment
         oldColName = "name2";
         newColName = "name3";
         final String comment = "added comment";
-        query = String.format("alter table %s change column %s %s %s COMMENT '%s' after id", tableName, oldColName,
-            newColName, newColType, comment);
-        runCommandWithDelay(query, 1000);
+        query = String.format("alter table %s change column %s %s %s COMMENT '%s' after id", tableName, oldColName, newColName, newColType, comment);
+        runCommand(query);
 
         columns = getColumns(DEFAULT_DB, tableName);
         Assert.assertEquals(columns.size(), 2);
 
-        assertColumnIsNotRegistered(HiveMetaStoreBridge.getColumnQualifiedName(
-            HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), oldColName));
-        newColQualifiedName = HiveMetaStoreBridge.getColumnQualifiedName(
-                HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), newColName);
-        assertColumnIsRegistered(newColQualifiedName, new AssertPredicate() {
-            @Override
-            public void assertOnEntity(Referenceable entity) throws Exception {
-                assertEquals(entity.get(HiveDataModelGenerator.COMMENT), comment);
-            }
-        });
+        assertColumnIsNotRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), oldColName));
+        newColQualifiedName = HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), newColName);
+        assertColumnIsRegistered(newColQualifiedName);
+
+        Assert.assertEquals(columns.get(1).get(HiveDataModelGenerator.COMMENT), comment);
 
         //Change column position
         oldColName = "name3";
         newColName = "name4";
-        query = String.format("alter table %s change column %s %s %s first", tableName, oldColName, newColName,
-                newColType);
-        runCommandWithDelay(query, 1000);
+        query = String.format("alter table %s change column %s %s %s first", tableName, oldColName, newColName, newColType);
+        runCommand(query);
 
         columns = getColumns(DEFAULT_DB, tableName);
         Assert.assertEquals(columns.size(), 2);
 
-        assertColumnIsNotRegistered(HiveMetaStoreBridge.getColumnQualifiedName(
-                HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), oldColName));
-
-        newColQualifiedName = HiveMetaStoreBridge.getColumnQualifiedName(
-                HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), newColName);
+        assertColumnIsNotRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), oldColName));
+        newColQualifiedName = HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), newColName);
         assertColumnIsRegistered(newColQualifiedName);
 
-        final String finalNewColName = newColName;
-        assertTableIsRegistered(DEFAULT_DB, tableName, new AssertPredicate() {
-                @Override
-                public void assertOnEntity(Referenceable entity) throws Exception {
-                    List<Referenceable> columns = (List<Referenceable>) entity.get(HiveDataModelGenerator.COLUMNS);
-                    assertEquals(columns.get(0).get(NAME), finalNewColName);
-                    assertEquals(columns.get(1).get(NAME), "id");
-                }
-            }
-        );
-
         //Change col position again
+        Assert.assertEquals(columns.get(0).get(HiveDataModelGenerator.NAME), newColName);
+        Assert.assertEquals(columns.get(1).get(HiveDataModelGenerator.NAME), "id");
+
         oldColName = "name4";
         newColName = "name5";
         query = String.format("alter table %s change column %s %s %s after id", tableName, oldColName, newColName, newColType);
-        runCommandWithDelay(query, 1000);
+        runCommand(query);
 
         columns = getColumns(DEFAULT_DB, tableName);
         Assert.assertEquals(columns.size(), 2);
 
-        assertColumnIsNotRegistered(HiveMetaStoreBridge.getColumnQualifiedName(
-                HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), oldColName));
-
-        newColQualifiedName = HiveMetaStoreBridge.getColumnQualifiedName(
-                HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), newColName);
+        assertColumnIsNotRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), oldColName));
+        newColQualifiedName = HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), newColName);
         assertColumnIsRegistered(newColQualifiedName);
 
         //Check col position
-        final String finalNewColName2 = newColName;
-        assertTableIsRegistered(DEFAULT_DB, tableName, new AssertPredicate() {
-                @Override
-                public void assertOnEntity(Referenceable entity) throws Exception {
-                    List<Referenceable> columns = (List<Referenceable>) entity.get(HiveDataModelGenerator.COLUMNS);
-                    assertEquals(columns.get(1).get(NAME), finalNewColName2);
-                    assertEquals(columns.get(0).get(NAME), "id");
-                }
-            }
-        );
-    }
-
-    private void runCommandWithDelay(String cmd, int sleepMs) throws CommandNeedRetryException, InterruptedException {
-        LOG.debug("Running command '{}'", cmd);
-        ss.setCommandType(null);
-        CommandProcessorResponse response = driver.run(cmd);
-        assertEquals(response.getResponseCode(), 0);
-        if (sleepMs != 0) {
-            Thread.sleep(sleepMs);
-        }
-    }
-
-    @Test
-    public void testTruncateTable() throws Exception {
-        String tableName = createTable(false);
-        String query = String.format("truncate table %s", tableName);
-        runCommand(query);
-
-        List<Entity> outputs = getInputs(tableName, Entity.Type.TABLE);
-
-        String tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-        validateProcess(query, HiveOperation.TRUNCATETABLE, null, outputs);
-
-        //Check lineage
-        String datasetName = HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName);
-        JSONObject response = atlasClient.getInputGraph(datasetName);
-        JSONObject vertices = response.getJSONObject("values").getJSONObject("vertices");
-        //Below should be assertTrue - Fix https://issues.apache.org/jira/browse/ATLAS-653
-        Assert.assertFalse(vertices.has(tableId));
-    }
-
-    @Test
-    public void testAlterTablePartitionColumnType() throws Exception {
-        String tableName = createTable(true, true, false);
-        final String newType = "int";
-        String query = String.format("ALTER TABLE %s PARTITION COLUMN (dt %s)", tableName, newType);
-        runCommand(query);
-
-        String colQualifiedName = HiveMetaStoreBridge.getColumnQualifiedName(
-            HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), "dt");
-        final String dtColId = assertColumnIsRegistered(colQualifiedName, new AssertPredicate() {
-            @Override
-            public void assertOnEntity(Referenceable column) throws Exception {
-                Assert.assertEquals(column.get("type"), newType);
-            }
-        });
-
-        assertTableIsRegistered(DEFAULT_DB, tableName, new AssertPredicate() {
-            @Override
-            public void assertOnEntity(Referenceable table) throws Exception {
-                final List<Referenceable> partitionKeys = (List<Referenceable>) table.get("partitionKeys");
-                Assert.assertEquals(partitionKeys.size(), 1);
-                Assert.assertEquals(partitionKeys.get(0).getId()._getId(), dtColId);
-
-            }
-        });
-    }
-
-    @Test
-    public void testAlterTableWithoutHookConf() throws Exception {
-        HiveConf conf = new HiveConf();
-        conf.set("hive.exec.post.hooks", "");
-        SessionState ss = new SessionState(conf);
-        ss = SessionState.start(ss);
-        SessionState.setCurrentSessionState(ss);
-        Driver driver = new Driver(conf);
-        String tableName = tableName();
-        String createCommand = "create table " + tableName + " (id int, name string)";
-        driver.run(createCommand);
-        assertTableIsNotRegistered(DEFAULT_DB, tableName);
-        String command = "alter table " + tableName + " change id id_new string";
-        runCommand(command);
-        assertTableIsRegistered(DEFAULT_DB, tableName);
-        String tbqn = HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName);
-        assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(tbqn, "id_new"));
-    }
-
-    @Test
-    public void testTraitsPreservedOnColumnRename() throws Exception {
-        String dbName = createDatabase();
-        String tableName = tableName();
-        String createQuery = String.format("create table %s.%s (id int, name string)", dbName, tableName);
-        runCommand(createQuery);
-        String tbqn = HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, dbName, tableName);
-        String guid = assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(tbqn, "id"));
-        String trait = createTrait(guid);
-        String oldColName = "id";
-        String newColName = "id_new";
-        String query = String.format("alter table %s.%s change %s %s string", dbName, tableName, oldColName, newColName);
-        runCommand(query);
-
-        String guid2 = assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(tbqn, "id_new"));
-        assertEquals(guid2, guid);
-
-        assertTrue(atlasClient.getEntity(guid2).getTraits().contains(trait));
+        Assert.assertEquals(columns.get(1).get(HiveDataModelGenerator.NAME), newColName);
+        Assert.assertEquals(columns.get(0).get(HiveDataModelGenerator.NAME), "id");
     }
 
     @Test
@@ -1144,45 +563,16 @@ public class HiveHookIT {
 
     @Test
     public void testAlterTableLocation() throws Exception {
-        //Its an external table, so the HDFS location should also be registered as an entity
-        String tableName = createTable(true, true, false);
-        final String testPath = createTestDFSPath("testBaseDir");
+        String tableName = createTable();
+        final String testPath = "file://" + System.getProperty("java.io.tmpdir", "/tmp") + File.pathSeparator + "testPath";
         String query = "alter table " + tableName + " set location '" + testPath + "'";
         runCommand(query);
 
-        String tableId = assertTableIsRegistered(DEFAULT_DB, tableName, new AssertPredicate() {
-            @Override
-            public void assertOnEntity(Referenceable tableRef) throws Exception {
-                Referenceable sdRef = (Referenceable) tableRef.get(HiveDataModelGenerator.STORAGE_DESC);
-                Assert.assertEquals(new Path((String)sdRef.get(HiveDataModelGenerator.LOCATION)).toString(), new Path(testPath).toString());
-            }
-        });
-
-        List<Entity> inputs = getInputs(testPath, Entity.Type.DFS_DIR);
-        List<Entity> outputs = getOutputs(tableName, Entity.Type.TABLE);
-
-        Referenceable processReference = validateProcess(query, HiveOperation.ALTERTABLE_LOCATION, inputs, outputs);
-        validateHDFSPaths(processReference, INPUTS, testPath);
-    }
-
-    private void validateHDFSPaths(Referenceable processReference, String attributeName, String... testPaths) throws Exception {
-        List<Id> hdfsPathRefs = (List<Id>) processReference.get(attributeName);
-
-        for (int i = 0; i < testPaths.length; i++) {
-            final String testPathNormed = lower(new Path(testPaths[i]).toString());
-            String hdfsPathId = assertHDFSPathIsRegistered(testPathNormed);
-            Assert.assertEquals(hdfsPathRefs.get(0)._getId(), hdfsPathId);
-
-            Referenceable hdfsPathRef = atlasClient.getEntity(hdfsPathId);
-            Assert.assertEquals(hdfsPathRef.get("path"), testPathNormed);
-            Assert.assertEquals(hdfsPathRef.get(NAME), new Path(testPathNormed).getName());
-            Assert.assertEquals(hdfsPathRef.get(AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME), testPathNormed);
-        }
-    }
-
-    private String assertHDFSPathIsRegistered(String path) throws Exception {
-        LOG.debug("Searching for hdfs path {}", path);
-        return assertEntityIsRegistered(FSDataTypes.HDFS_PATH().toString(), AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME, path, null);
+        String tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
+        //Verify the number of columns present in the table
+        Referenceable tableRef = dgiCLient.getEntity(tableId);
+        Referenceable sdRef = (Referenceable)tableRef.get(HiveDataModelGenerator.STORAGE_DESC);
+        Assert.assertEquals(sdRef.get("location"), testPath);
     }
 
     @Test
@@ -1192,25 +582,18 @@ public class HiveHookIT {
         String query = "alter table " + tableName + " set FILEFORMAT " + testFormat;
         runCommand(query);
 
-        assertTableIsRegistered(DEFAULT_DB, tableName, new AssertPredicate() {
-            @Override
-            public void assertOnEntity(Referenceable tableRef) throws Exception {
-                Referenceable sdRef = (Referenceable) tableRef.get(HiveDataModelGenerator.STORAGE_DESC);
-                Assert.assertEquals(sdRef.get(HiveDataModelGenerator.STORAGE_DESC_INPUT_FMT),
-                    "org.apache.hadoop.hive.ql.io.orc.OrcInputFormat");
-                Assert.assertEquals(sdRef.get(HiveDataModelGenerator.STORAGE_DESC_OUTPUT_FMT),
-                    "org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat");
-                Assert.assertNotNull(sdRef.get("serdeInfo"));
-
-                Struct serdeInfo = (Struct) sdRef.get("serdeInfo");
-                Assert.assertEquals(serdeInfo.get("serializationLib"), "org.apache.hadoop.hive.ql.io.orc.OrcSerde");
-                Assert.assertNotNull(serdeInfo.get(HiveDataModelGenerator.PARAMETERS));
-                Assert.assertEquals(
-                    ((Map<String, String>) serdeInfo.get(HiveDataModelGenerator.PARAMETERS))
-                        .get("serialization.format"),
-                    "1");
-            }
-        });
+        String tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
+
+        Referenceable tableRef = dgiCLient.getEntity(tableId);
+        Referenceable sdRef = (Referenceable)tableRef.get(HiveDataModelGenerator.STORAGE_DESC);
+        Assert.assertEquals(sdRef.get(HiveDataModelGenerator.STORAGE_DESC_INPUT_FMT), "org.apache.hadoop.hive.ql.io.orc.OrcInputFormat");
+        Assert.assertEquals(sdRef.get(HiveDataModelGenerator.STORAGE_DESC_OUTPUT_FMT), "org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat");
+        Assert.assertNotNull(sdRef.get("serdeInfo"));
+
+        Struct serdeInfo = (Struct) sdRef.get("serdeInfo");
+        Assert.assertEquals(serdeInfo.get("serializationLib"), "org.apache.hadoop.hive.ql.io.orc.OrcSerde");
+        Assert.assertNotNull(serdeInfo.get(HiveDataModelGenerator.PARAMETERS));
+        Assert.assertEquals(((Map<String, String>)serdeInfo.get(HiveDataModelGenerator.PARAMETERS)).get("serialization.format"), "1");
 
 
         /**
@@ -1218,7 +601,7 @@ public class HiveHookIT {
          * query = "alter table " + tableName + " STORED AS " + testFormat.toUpperCase();
          * runCommand(query);
 
-         * tableRef = atlasClient.getEntity(tableId);
+         * tableRef = dgiCLient.getEntity(tableId);
          * sdRef = (Referenceable)tableRef.get(HiveDataModelGenerator.STORAGE_DESC);
          * Assert.assertEquals(sdRef.get(HiveDataModelGenerator.STORAGE_DESC_INPUT_FMT), "org.apache.hadoop.hive.ql.io.orc.OrcInputFormat");
          * Assert.assertEquals(sdRef.get(HiveDataModelGenerator.STORAGE_DESC_OUTPUT_FMT), "org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat");
@@ -1229,37 +612,31 @@ public class HiveHookIT {
     @Test
     public void testAlterTableBucketingClusterSort() throws Exception {
         String tableName = createTable();
-        ImmutableList<String> cols = ImmutableList.of("id");
+        ImmutableList<String> cols = ImmutableList.<String>of("id");
         runBucketSortQuery(tableName, 5, cols, cols);
 
-        cols = ImmutableList.of("id", NAME);
+        cols = ImmutableList.<String>of("id", "name");
         runBucketSortQuery(tableName, 2, cols, cols);
     }
 
-    private void runBucketSortQuery(String tableName, final int numBuckets,  final ImmutableList<String> bucketCols,
-                                    final ImmutableList<String> sortCols) throws Exception {
+    private void runBucketSortQuery(String tableName, int numBuckets,  ImmutableList<String> bucketCols,ImmutableList<String> sortCols) throws Exception {
         final String fmtQuery = "alter table %s CLUSTERED BY (%s) SORTED BY (%s) INTO %s BUCKETS";
-        String query = String.format(fmtQuery, tableName, stripListBrackets(bucketCols.toString()),
-                stripListBrackets(sortCols.toString()), numBuckets);
+        String query = String.format(fmtQuery, tableName, stripListBrackets(bucketCols.toString()), stripListBrackets(sortCols.toString()), numBuckets);
         runCommand(query);
-        assertTableIsRegistered(DEFAULT_DB, tableName, new AssertPredicate() {
-            @Override
-            public void assertOnEntity(Referenceable entity) throws Exception {
-                verifyBucketSortingProperties(entity, numBuckets, bucketCols, sortCols);
-            }
-        });
+        verifyBucketSortingProperties(tableName, numBuckets, bucketCols, sortCols);
     }
 
     private String stripListBrackets(String listElements) {
         return StringUtils.strip(StringUtils.strip(listElements, "["), "]");
     }
 
-    private void verifyBucketSortingProperties(Referenceable tableRef, int numBuckets,
-                                               ImmutableList<String> bucketColNames,
-                                               ImmutableList<String>  sortcolNames) throws Exception {
-        Referenceable sdRef = (Referenceable) tableRef.get(HiveDataModelGenerator.STORAGE_DESC);
-        Assert.assertEquals(((scala.math.BigInt) sdRef.get(HiveDataModelGenerator.STORAGE_NUM_BUCKETS)).intValue(),
-            numBuckets);
+    private void verifyBucketSortingProperties(String tableName, int numBuckets, ImmutableList<String> bucketColNames, ImmutableList<String>  sortcolNames) throws Exception {
+
+        String tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
+
+        Referenceable tableRef = dgiCLient.getEntity(tableId);
+        Referenceable sdRef = (Referenceable)tableRef.get(HiveDataModelGenerator.STORAGE_DESC);
+        Assert.assertEquals(((scala.math.BigInt) sdRef.get(HiveDataModelGenerator.STORAGE_NUM_BUCKETS)).intValue(), numBuckets);
         Assert.assertEquals(sdRef.get("bucketCols"), bucketColNames);
 
         List<Struct> hiveOrderStructList = (List<Struct>) sdRef.get("sortCols");
@@ -1268,7 +645,7 @@ public class HiveHookIT {
 
         for (int i = 0; i < sortcolNames.size(); i++) {
             Assert.assertEquals(hiveOrderStructList.get(i).get("col"), sortcolNames.get(i));
-            Assert.assertEquals(((scala.math.BigInt) hiveOrderStructList.get(i).get("order")).intValue(), 1);
+            Assert.assertEquals(((scala.math.BigInt)hiveOrderStructList.get(i).get("order")).intValue(), 1);
         }
     }
 
@@ -1286,123 +663,7 @@ public class HiveHookIT {
 
         //Add another property
         runSerdePropsQuery(tableName, expectedProps);
-    }
-
-    @Test
-    public void testDropTable() throws Exception {
-        //Test Deletion of tables and its corrresponding columns
-        String tableName = createTable(true, true, false);
 
-        assertTableIsRegistered(DEFAULT_DB, tableName);
-        assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), "id"));
-        assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), NAME));
-
-        final String query = String.format("drop table %s ", tableName);
-        runCommand(query);
-        assertColumnIsNotRegistered(HiveMetaStoreBridge
-            .getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName),
-                "id"));
-        assertColumnIsNotRegistered(HiveMetaStoreBridge
-            .getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName),
-                NAME));
-        assertTableIsNotRegistered(DEFAULT_DB, tableName);
-    }
-
-    @Test
-    public void testDropDatabaseWithCascade() throws Exception {
-        //Test Deletion of database and its corresponding tables
-        String dbName = "db" + random();
-        runCommand("create database " + dbName + " WITH DBPROPERTIES ('p1'='v1')");
-
-        final int numTables = 10;
-        String[] tableNames = new String[numTables];
-        for(int i = 0; i < numTables; i++) {
-            tableNames[i] = createTable(true, true, false);
-        }
-
-        final String query = String.format("drop database %s cascade", dbName);
-        runCommand(query);
-
-        //Verify columns are not registered for one of the tables
-        assertColumnIsNotRegistered(HiveMetaStoreBridge.getColumnQualifiedName(
-            HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, dbName, tableNames[0]), "id"));
-        assertColumnIsNotRegistered(HiveMetaStoreBridge
-            .getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, dbName, tableNames[0]),
-                NAME));
-
-        for(int i = 0; i < numTables; i++) {
-            assertTableIsNotRegistered(dbName, tableNames[i]);
-        }
-        assertDBIsNotRegistered(dbName);
-    }
-
-    @Test
-    public void testDropDatabaseWithoutCascade() throws Exception {
-        //Test Deletion of database and its corresponding tables
-        String dbName = "db" + random();
-        runCommand("create database " + dbName + " WITH DBPROPERTIES ('p1'='v1')");
-
-        final int numTables = 10;
-        String[] tableNames = new String[numTables];
-        for(int i = 0; i < numTables; i++) {
-            tableNames[i] = createTable(true, true, false);
-            String query = String.format("drop table %s", tableNames[i]);
-            runCommand(query);
-            assertTableIsNotRegistered(dbName, tableNames[i]);
-        }
-
-        final String query = String.format("drop database %s", dbName);
-        runCommand(query);
-
-        assertDBIsNotRegistered(dbName);
-    }
-
-    @Test
-    public void testDropNonExistingDB() throws Exception {
-        //Test Deletion of a non existing DB
-        final String dbName = "nonexistingdb";
-        assertDBIsNotRegistered(dbName);
-        final String query = String.format("drop database if exists %s cascade", dbName);
-        runCommand(query);
-
-        //Should have no effect
-        assertDBIsNotRegistered(dbName);
-    }
-
-    @Test
-    public void testDropNonExistingTable() throws Exception {
-        //Test Deletion of a non existing table
-        final String tableName = "nonexistingtable";
-        assertTableIsNotRegistered(DEFAULT_DB, tableName);
-        final String query = String.format("drop table if exists %s", tableName);
-        runCommand(query);
-
-        //Should have no effect
-        assertTableIsNotRegistered(DEFAULT_DB, tableName);
-    }
-
-    @Test
-    public void testDropView() throws Exception {
-        //Test Deletion of tables and its corrresponding columns
-        String tableName = createTable(true, true, false);
-        String viewName = tableName();
-        String query = "create view " + viewName + " as select * from " + tableName;
-        runCommand(query);
-
-        assertTableIsRegistered(DEFAULT_DB, viewName);
-        assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, viewName), "id"));
-        assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, viewName), NAME));
-
-        query = String.format("drop view %s ", viewName);
-
-        runCommand(query);
-        assertColumnIsNotRegistered(HiveMetaStoreBridge
-                .getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, viewName),
-                    "id"));
-        assertColumnIsNotRegistered(HiveMetaStoreBridge
-            .getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, viewName),
-                NAME));
-        assertTableIsNotRegistered(DEFAULT_DB, viewName);
     }
 
     private void runSerdePropsQuery(String tableName, Map<String, String> expectedProps) throws Exception {
@@ -1432,20 +693,16 @@ public class HiveHookIT {
     @Test
     public void testAlterDBOwner() throws Exception {
         String dbName = createDatabase();
-        assertDatabaseIsRegistered(dbName);
-
         final String owner = "testOwner";
+        String dbId = assertDatabaseIsRegistered(dbName);
         final String fmtQuery = "alter database %s set OWNER %s %s";
         String query = String.format(fmtQuery, dbName, "USER", owner);
 
         runCommand(query);
 
-        assertDatabaseIsRegistered(dbName, new AssertPredicate() {
-            @Override
-            public void assertOnEntity(Referenceable entity) {
-                assertEquals(entity.get(AtlasClient.OWNER), owner);
-            }
-        });
+        assertDatabaseIsRegistered(dbName);
+        Referenceable entity = dgiCLient.getEntity(dbId);
+        Assert.assertEquals(entity.get(HiveDataModelGenerator.OWNER), owner);
     }
 
     @Test
@@ -1503,38 +760,30 @@ public class HiveHookIT {
         testAlterProperties(Entity.Type.TABLE, viewName, fmtQuery);
     }
 
-    private void verifyEntityProperties(Entity.Type type, String entityName, final Map<String, String> expectedProps,
-                                        final boolean checkIfNotExists) throws Exception {
+    private void verifyEntityProperties(Entity.Type type, String entityName, Map<String, String> expectedProps, boolean checkIfNotExists) throws Exception {
+
+        String entityId = null;
+
         switch(type) {
         case TABLE:
-            assertTableIsRegistered(DEFAULT_DB, entityName, new AssertPredicate() {
-                @Override
-                public void assertOnEntity(Referenceable entity) throws Exception {
-                    verifyProperties(entity, expectedProps, checkIfNotExists);
-                }
-            });
+            entityId = assertTableIsRegistered(DEFAULT_DB, entityName);
             break;
         case DATABASE:
-            assertDatabaseIsRegistered(entityName, new AssertPredicate() {
-                @Override
-                public void assertOnEntity(Referenceable entity) throws Exception {
-                    verifyProperties(entity, expectedProps, checkIfNotExists);
-                }
-            });
+            entityId = assertDatabaseIsRegistered(entityName);
             break;
         }
+
+        Referenceable ref = dgiCLient.getEntity(entityId);
+        verifyProperties(ref, expectedProps, checkIfNotExists);
     }
 
-    private void verifyTableSdProperties(String tableName, final String serdeLib, final Map<String, String> expectedProps) throws Exception {
-        assertTableIsRegistered(DEFAULT_DB, tableName, new AssertPredicate() {
-            @Override
-            public void assertOnEntity(Referenceable tableRef) throws Exception {
-                Referenceable sdRef = (Referenceable) tableRef.get(HiveDataModelGenerator.STORAGE_DESC);
-                Struct serdeInfo = (Struct) sdRef.get("serdeInfo");
-                Assert.assertEquals(serdeInfo.get("serializationLib"), serdeLib);
-                verifyProperties(serdeInfo, expectedProps, false);
-            }
-        });
+    private void verifyTableSdProperties(String tableName, String serdeLib, Map<String, String> expectedProps) throws Exception {
+        String tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
+        Referenceable tableRef = dgiCLient.getEntity(tableId);
+        Referenceable sdRef = (Referenceable) tableRef.get(HiveDataModelGenerator.STORAGE_DESC);
+        Struct serdeInfo = (Struct) sdRef.get("serdeInfo");
+        Assert.assertEquals(serdeInfo.get("serializationLib"), serdeLib);
+        verifyProperties(serdeInfo, expectedProps, false);
     }
 
     private void verifyProperties(Struct referenceable, Map<String, String> expectedProps, boolean checkIfNotExists) {
@@ -1556,117 +805,101 @@ public class HiveHookIT {
         }
     }
 
-    private String assertProcessIsRegistered(final String queryStr, HiveOperation op, final List<Entity> inputTbls, final List<Entity> outputTbls) throws Exception {
-        String processQFName = getProcessQualifiedName(op, getSortedProcessDataSets(inputTbls), getSortedProcessDataSets(outputTbls));
-        LOG.debug("Searching for process with query {}", processQFName);
-        return assertEntityIsRegistered(HiveDataTypes.HIVE_PROCESS.getName(), AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME, processQFName, new AssertPredicate() {
-            @Override
-            public void assertOnEntity(final Referenceable entity) throws Exception {
-                List<String> recentQueries = (List<String>) entity.get("recentQueries");
-                Assert.assertEquals(recentQueries.get(0), lower(queryStr));
-            }
-        });
-    }
-
-    private String getDSTypeName(Entity entity) {
-        return Entity.Type.TABLE.equals(entity.getType()) ? HiveDataTypes.HIVE_TABLE.name() : FSDataTypes.HDFS_PATH().toString();
-    }
-
-    private SortedMap<Entity, Referenceable> getSortedProcessDataSets(List<Entity> inputTbls) {
-        SortedMap<Entity, Referenceable> inputs = new TreeMap<Entity, Referenceable>(entityComparator);
-        if (inputTbls != null) {
-            for (final Entity tbl : inputTbls) {
-                Referenceable inputTableRef = new Referenceable(getDSTypeName(tbl), new HashMap<String, Object>() {{
-                    put(AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME, tbl.getName());
-                }});
-                inputs.put(tbl, inputTableRef);
-            }
+    private String assertProcessIsRegistered(String queryStr) throws Exception {
+        //        String dslQuery = String.format("%s where queryText = \"%s\"", HiveDataTypes.HIVE_PROCESS.getName(),
+        //                normalize(queryStr));
+        //        assertEntityIsRegistered(dslQuery, true);
+        //todo replace with DSL
+        String typeName = HiveDataTypes.HIVE_PROCESS.getName();
+        String gremlinQuery =
+                String.format("g.V.has('__typeName', '%s').has('%s.queryText', \"%s\").toList()", typeName, typeName,
+                        normalize(queryStr));
+        return assertEntityIsRegistered(gremlinQuery);
+    }
+
+    private void assertProcessIsNotRegistered(String queryStr) throws Exception {
+        //        String dslQuery = String.format("%s where queryText = \"%s\"", HiveDataTypes.HIVE_PROCESS.getName(),
+        //                normalize(queryStr));
+        //        assertEntityIsRegistered(dslQuery, true);
+        //todo replace with DSL
+        String typeName = HiveDataTypes.HIVE_PROCESS.getName();
+        String gremlinQuery =
+            String.format("g.V.has('__typeName', '%s').has('%s.queryText', \"%s\").toList()", typeName, typeName,
+                normalize(queryStr));
+        assertEntityIsNotRegistered(QUERY_TYPE.GREMLIN, gremlinQuery);
+    }
+
+    private String normalize(String str) {
+        if (StringUtils.isEmpty(str)) {
+            return null;
         }
-        return inputs;
-    }
-
-    private void assertProcessIsNotRegistered(String queryStr, HiveOperation op, final List<Entity> inputTbls, final List<Entity> outputTbls) throws Exception {
-        String processQFName = getProcessQualifiedName(op, getSortedProcessDataSets(inputTbls), getSortedProcessDataSets(outputTbls));
-        LOG.debug("Searching for process with query {}", processQFName);
-        assertEntityIsNotRegistered(HiveDataTypes.HIVE_PROCESS.getName(), AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME, processQFName);
-    }
-
-    private void assertTableIsNotRegistered(String dbName, String tableName, boolean isTemporaryTable) throws Exception {
-        LOG.debug("Searching for table {}.{}", dbName, tableName);
-        String tableQualifiedName = HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, dbName, tableName, isTemporaryTable);
-        assertEntityIsNotRegistered(HiveDataTypes.HIVE_TABLE.getName(), AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME, tableQualifiedName);
+        return StringEscapeUtils.escapeJava(str.toLowerCase());
     }
 
     private void assertTableIsNotRegistered(String dbName, String tableName) throws Exception {
         LOG.debug("Searching for table {}.{}", dbName, tableName);
-        String tableQualifiedName = HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, dbName, tableName, false);
-        assertEntityIsNotRegistered(HiveDataTypes.HIVE_TABLE.getName(), AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME, tableQualifiedName);
-    }
-
-    private void assertDBIsNotRegistered(String dbName) throws Exception {
-        LOG.debug("Searching for database {}", dbName);
-        String dbQualifiedName = HiveMetaStoreBridge.getDBQualifiedName(CLUSTER_NAME, dbName);
-        assertEntityIsNotRegistered(HiveDataTypes.HIVE_DB.getName(), AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME, dbQualifiedName);
+        String query = String.format(
+                "%s as t where tableName = '%s', db where name = '%s' and clusterName = '%s'" + " select t",
+                HiveDataTypes.HIVE_TABLE.getName(), tableName.toLowerCase(), dbName.toLowerCase(), CLUSTER_NAME);
+        assertEntityIsNotRegistered(QUERY_TYPE.DSL, query);
     }
 
     private String assertTableIsRegistered(String dbName, String tableName) throws Exception {
-        return assertTableIsRegistered(dbName, tableName, null, false);
-    }
-
-
-    private String assertTableIsRegistered(String dbName, String tableName, AssertPredicate assertPredicate, boolean isTemporary) throws Exception {
         LOG.debug("Searching for table {}.{}", dbName, tableName);
-        String tableQualifiedName = HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, dbName, tableName, isTemporary);
-        return assertEntityIsRegistered(HiveDataTypes.HIVE_TABLE.getName(), AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME, tableQualifiedName,
-            assertPredicate);
+        String query = String.format(
+                "%s as t where tableName = '%s', db where name = '%s' and clusterName = '%s'" + " select t",
+                HiveDataTypes.HIVE_TABLE.getName(), tableName.toLowerCase(), dbName.toLowerCase(), CLUSTER_NAME);
+        return assertEntityIsRegistered(query, "t");
     }
 
-    private String assertTableIsRegistered(String dbName, String tableName, AssertPredicate assertPredicate) throws Exception {
-        return assertTableIsRegistered(dbName, tableName, assertPredicate, false);
+    private String getTableEntity(String dbName, String tableName) throws Exception {
+        LOG.debug("Searching for table {}.{}", dbName, tableName);
+        String query = String.format(
+            "%s as t where tableName = '%s', db where name = '%s' and clusterName = '%s'" + " select t",
+            HiveDataTypes.HIVE_TABLE.getName(), tableName.toLowerCase(), dbName.toLowerCase(), CLUSTER_NAME);
+        return assertEntityIsRegistered(query, "t");
     }
 
     private String assertDatabaseIsRegistered(String dbName) throws Exception {
-        return assertDatabaseIsRegistered(dbName, null);
-    }
-
-    private String assertDatabaseIsRegistered(String dbName, AssertPredicate assertPredicate) throws Exception {
         LOG.debug("Searching for database {}", dbName);
-        String dbQualifiedName = HiveMetaStoreBridge.getDBQualifiedName(CLUSTER_NAME, dbName);
-        return assertEntityIsRegistered(HiveDataTypes.HIVE_DB.getName(), AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME,
-                dbQualifiedName, assertPredicate);
+        String query = String.format("%s where name = '%s' and clusterName = '%s'", HiveDataTypes.HIVE_DB.getName(),
+                dbName.toLowerCase(), CLUSTER_NAME);
+        return assertEntityIsRegistered(query);
     }
 
-    private String assertEntityIsRegistered(final String typeName, final String property, final String value,
-                                            final AssertPredicate assertPredicate) throws Exception {
-        waitFor(80000, new Predicate() {
+    private String assertEntityIsRegistered(final String query, String... arg) throws Exception {
+        waitFor(60000, new Predicate() {
             @Override
-            public void evaluate() throws Exception {
-                Referenceable entity = atlasClient.getEntity(typeName, property, value);
-                assertNotNull(entity);
-                if (assertPredicate != null) {
-                    assertPredicate.assertOnEntity(entity);
-                }
+            public boolean evaluate() throws Exception {
+                JSONArray results = dgiCLient.search(query);
+                return results.length() == 1;
             }
         });
-        Referenceable entity = atlasClient.getEntity(typeName, property, value);
-        return entity.getId()._getId();
+
+        String column = (arg.length > 0) ? arg[0] : "_col_0";
+
+        JSONArray results = dgiCLient.search(query);
+        JSONObject row = results.getJSONObject(0);
+        if (row.has("__guid")) {
+            return row.getString("__guid");
+        } else if (row.has("$id$")) {
+            return row.getJSONObject("$id$").getString("id");
+        } else {
+            return row.getJSONObject(column).getString("id");
+        }
     }
 
-    private void assertEntityIsNotRegistered(final String typeName, final String property, final String value) throws Exception {
-        waitFor(80000, new Predicate() {
-            @Override
-            public void evaluate() throws Exception {
-                try {
-                    atlasClient.getEntity(typeName, property, value);
-                } catch (AtlasServiceException e) {
-                    if (e.getStatus() == ClientResponse.Status.NOT_FOUND) {
-                        return;
-                    }
-                }
-                fail(String.format("Entity was not supposed to exist for typeName = %s, attributeName = %s, "
-                    + "attributeValue = %s", typeName, property, value));
-            }
-        });
+    private void assertEntityIsNotRegistered(QUERY_TYPE queryType, String query) throws Exception {
+        JSONArray results = null;
+        switch(queryType) {
+        case DSL :
+            results = dgiCLient.searchByDSL(query);
+            break;
+        case GREMLIN :
+            results = dgiCLient.searchByGremlin(query);
+            break;
+        }
+        Assert.assertEquals(results.length(), 0);
     }
 
     @Test
@@ -1682,16 +915,16 @@ public class HiveHookIT {
         String table2Id = assertTableIsRegistered(db2, table2);
 
         String datasetName = HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, db2, table2);
-        JSONObject response = atlasClient.getInputGraph(datasetName);
+        JSONObject response = dgiCLient.getInputGraph(datasetName);
         JSONObject vertices = response.getJSONObject("values").getJSONObject("vertices");
-        assertTrue(vertices.has(table1Id));
-        assertTrue(vertices.has(table2Id));
+        Assert.assertTrue(vertices.has(table1Id));
+        Assert.assertTrue(vertices.has(table2Id));
 
         datasetName = HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, table1);
-        response = atlasClient.getOutputGraph(datasetName);
+        response = dgiCLient.getOutputGraph(datasetName);
         vertices = response.getJSONObject("values").getJSONObject("vertices");
-        assertTrue(vertices.has(table1Id));
-        assertTrue(vertices.has(table2Id));
+        Assert.assertTrue(vertices.has(table1Id));
+        Assert.assertTrue(vertices.has(table2Id));
     }
 
     //For ATLAS-448
@@ -1701,18 +934,15 @@ public class HiveHookIT {
         runCommand("show transactions");
     }
 
-    public interface AssertPredicate {
-        void assertOnEntity(Referenceable entity) throws Exception;
-    }
-
     public interface Predicate {
+
         /**
          * Perform a predicate evaluation.
          *
          * @return the boolean result of the evaluation.
          * @throws Exception thrown if the predicate evaluation could not evaluate.
          */
-        void evaluate() throws Exception;
+        boolean evaluate() throws Exception;
     }
 
     /**
@@ -1725,17 +955,13 @@ public class HiveHookIT {
         ParamChecker.notNull(predicate, "predicate");
         long mustEnd = System.currentTimeMillis() + timeout;
 
-        while (true) {
-            try {
-                predicate.evaluate();
-                return;
-            } catch(Error | Exception e) {
-                if (System.currentTimeMillis() >= mustEnd) {
-                    fail("Assertions failed. Failing after waiting for timeout " + timeout + " msecs", e);
-                }
-                LOG.debug("Waiting up to " + (mustEnd - System.currentTimeMillis()) + " msec as assertion failed", e);
-                Thread.sleep(400);
-            }
+        boolean eval;
+        while (!(eval = predicate.evaluate()) && System.currentTimeMillis() < mustEnd) {
+            LOG.info("Waiting up to {} msec", mustEnd - System.currentTimeMillis());
+            Thread.sleep(100);
+        }
+        if (!eval) {
+            throw new Exception("Waiting timed out after " + timeout + " msec");
         }
     }
 }