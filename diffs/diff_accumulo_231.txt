diff --git a/test/src/test/java/org/apache/accumulo/test/functional/CompactionIT.java b/test/src/test/java/org/apache/accumulo/test/functional/CompactionIT.java
index dc877dce14..a49670e60d 100644
--- a/test/src/test/java/org/apache/accumulo/test/functional/CompactionIT.java
+++ b/test/src/test/java/org/apache/accumulo/test/functional/CompactionIT.java
@@ -16,6 +16,7 @@
  */
 package org.apache.accumulo.test.functional;
 
+import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertTrue;
 
@@ -23,94 +24,46 @@ import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
+import java.util.Map.Entry;
 import java.util.concurrent.atomic.AtomicBoolean;
 
 import org.apache.accumulo.core.cli.ScannerOpts;
 import org.apache.accumulo.core.client.Connector;
 import org.apache.accumulo.core.client.Scanner;
-import org.apache.accumulo.core.client.admin.InstanceOperations;
 import org.apache.accumulo.core.conf.Property;
+import org.apache.accumulo.core.data.Key;
+import org.apache.accumulo.core.data.Value;
 import org.apache.accumulo.core.metadata.MetadataTable;
 import org.apache.accumulo.core.metadata.schema.MetadataSchema;
 import org.apache.accumulo.core.security.Authorizations;
-import org.apache.accumulo.harness.AccumuloClusterIT;
-import org.apache.accumulo.minicluster.ServerType;
-import org.apache.accumulo.minicluster.impl.MiniAccumuloConfigImpl;
+import org.apache.accumulo.core.util.CachedConfiguration;
+import org.apache.accumulo.minicluster.MiniAccumuloConfig;
+import org.apache.accumulo.server.util.Admin;
 import org.apache.accumulo.test.VerifyIngest;
-import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.FileSystem;
-import org.apache.hadoop.fs.Path;
-import org.junit.After;
-import org.junit.Before;
 import org.junit.Test;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-public class CompactionIT extends AccumuloClusterIT {
-  private static final Logger log = LoggerFactory.getLogger(CompactionIT.class);
 
+public class CompactionIT extends ConfigurableMacIT {
+  
   @Override
-  public void configureMiniCluster(MiniAccumuloConfigImpl cfg, Configuration hadoopCoreSite) {
+  public void configure(MiniAccumuloConfig cfg) {
     Map<String,String> map = new HashMap<String,String>();
     map.put(Property.TSERV_MAJC_THREAD_MAXOPEN.getKey(), "4");
     map.put(Property.TSERV_MAJC_DELAY.getKey(), "1");
     map.put(Property.TSERV_MAJC_MAXCONCURRENT.getKey(), "1");
     cfg.setSiteConfig(map);
   }
-
-  @Override
-  protected int defaultTimeoutSeconds() {
-    return 4 * 60;
-  }
-
-  private String majcThreadMaxOpen, majcDelay, majcMaxConcurrent;
-
-  @Before
-  public void alterConfig() throws Exception {
-    if (ClusterType.STANDALONE == getClusterType()) {
-      InstanceOperations iops = getConnector().instanceOperations();
-      Map<String,String> config = iops.getSystemConfiguration();
-      majcThreadMaxOpen = config.get(Property.TSERV_MAJC_THREAD_MAXOPEN.getKey());
-      majcDelay = config.get(Property.TSERV_MAJC_DELAY.getKey());
-      majcMaxConcurrent = config.get(Property.TSERV_MAJC_MAXCONCURRENT.getKey());
-
-      iops.setProperty(Property.TSERV_MAJC_THREAD_MAXOPEN.getKey(), "4");
-      iops.setProperty(Property.TSERV_MAJC_DELAY.getKey(), "1");
-      iops.setProperty(Property.TSERV_MAJC_MAXCONCURRENT.getKey(), "1");
-
-      getClusterControl().stopAllServers(ServerType.TABLET_SERVER);
-      getClusterControl().startAllServers(ServerType.TABLET_SERVER);
-    }
-  }
-
-  @After
-  public void resetConfig() throws Exception {
-    // We set the values..
-    if (null != majcThreadMaxOpen) {
-      InstanceOperations iops = getConnector().instanceOperations();
-
-      iops.setProperty(Property.TSERV_MAJC_THREAD_MAXOPEN.getKey(), majcThreadMaxOpen);
-      iops.setProperty(Property.TSERV_MAJC_DELAY.getKey(), majcDelay);
-      iops.setProperty(Property.TSERV_MAJC_MAXCONCURRENT.getKey(), majcMaxConcurrent);
-
-      getClusterControl().stopAllServers(ServerType.TABLET_SERVER);
-      getClusterControl().startAllServers(ServerType.TABLET_SERVER);
-    }
-  }
-
-  @Test
+  
+  @Test(timeout = 4 * 60 * 1000)
   public void test() throws Exception {
     final Connector c = getConnector();
-    final String tableName = getUniqueNames(1)[0];
-    c.tableOperations().create(tableName);
-    c.tableOperations().setProperty(tableName, Property.TABLE_MAJC_RATIO.getKey(), "1.0");
-    FileSystem fs = getFileSystem();
-    String root = getUsableDir();
-    Path testrf = new Path(root, "testrf");
-    FunctionalTestUtils.createRFiles(c, fs, testrf.toString(), 500000, 59, 4);
-    FunctionalTestUtils.bulkImport(c, fs, tableName, testrf.toString());
+    c.tableOperations().create("test_ingest");
+    c.tableOperations().setProperty("test_ingest", Property.TABLE_MAJC_RATIO.getKey(), "1.0");
+    FileSystem fs = FileSystem.get(CachedConfiguration.getInstance());
+    FunctionalTestUtils.createRFiles(c, fs, "tmp/testrf", 500000, 59, 4);
+    FunctionalTestUtils.bulkImport(c, fs, "test_ingest", "tmp/testrf");
     int beforeCount = countFiles(c);
-
+    
     final AtomicBoolean fail = new AtomicBoolean(false);
     for (int count = 0; count < 5; count++) {
       List<Thread> threads = new ArrayList<Thread>();
@@ -127,10 +80,8 @@ public class CompactionIT extends AccumuloClusterIT {
               opts.random = 56;
               opts.dataSize = 50;
               opts.cols = 1;
-              opts.tableName = tableName;
               VerifyIngest.verifyIngest(c, opts, new ScannerOpts());
             } catch (Exception ex) {
-              log.warn("Got exception verifying data", ex);
               fail.set(true);
             }
           }
@@ -140,28 +91,23 @@ public class CompactionIT extends AccumuloClusterIT {
       }
       for (Thread t : threads)
         t.join();
-      assertFalse("Failed to successfully run all threads, Check the test output for error", fail.get());
+      assertFalse(fail.get());
     }
-
+    
     int finalCount = countFiles(c);
     assertTrue(finalCount < beforeCount);
-    try {
-      getClusterControl().adminStopAll();
-    } finally {
-      // Make sure the internal state in the cluster is reset (e.g. processes in MAC)
-      getCluster().stop();
-      if (ClusterType.STANDALONE == getClusterType()) {
-        // Then restart things for the next test if it's a standalone
-        getCluster().start();
-      }
-    }
+    assertEquals(0, cluster.exec(Admin.class, "stopAll").waitFor());
   }
-
+  
   private int countFiles(Connector c) throws Exception {
     Scanner s = c.createScanner(MetadataTable.NAME, Authorizations.EMPTY);
     s.fetchColumnFamily(MetadataSchema.TabletsSection.TabletColumnFamily.NAME);
     s.fetchColumnFamily(MetadataSchema.TabletsSection.DataFileColumnFamily.NAME);
-    return FunctionalTestUtils.count(s);
+    int i = 0;
+    for (@SuppressWarnings("unused")
+    Entry<Key,Value> entry : s)
+      i++;
+    return i;
   }
-
+  
 }