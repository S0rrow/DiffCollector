diff --git a/addons/hive-bridge/src/test/java/org/apache/atlas/hive/hook/HiveHookIT.java b/addons/hive-bridge/src/test/java/org/apache/atlas/hive/hook/HiveHookIT.java
index 00c17e8e0..70100f1c8 100755
--- a/addons/hive-bridge/src/test/java/org/apache/atlas/hive/hook/HiveHookIT.java
+++ b/addons/hive-bridge/src/test/java/org/apache/atlas/hive/hook/HiveHookIT.java
@@ -29,6 +29,7 @@ import org.apache.atlas.hive.bridge.HiveMetaStoreBridge;
 import org.apache.atlas.hive.model.HiveDataModelGenerator;
 import org.apache.atlas.hive.model.HiveDataTypes;
 import org.apache.atlas.hive.rewrite.HiveASTRewriter;
+import org.apache.atlas.hive.rewrite.RewriteException;
 import org.apache.atlas.typesystem.Referenceable;
 import org.apache.atlas.typesystem.Struct;
 import org.apache.atlas.typesystem.persistence.Id;
@@ -65,10 +66,8 @@ import java.util.Map;
 
 import static org.apache.atlas.hive.hook.HiveHook.lower;
 import static org.apache.atlas.hive.hook.HiveHook.normalize;
-import static org.apache.atlas.hive.model.HiveDataModelGenerator.NAME;
 import static org.testng.Assert.assertEquals;
 import static org.testng.Assert.assertNotNull;
-import static org.testng.Assert.assertTrue;
 import static org.testng.Assert.fail;
 
 public class HiveHookIT {
@@ -198,8 +197,8 @@ public class HiveHookIT {
         Assert.assertEquals(tableRef.get(HiveDataModelGenerator.TABLE_TYPE_ATTR), TableType.MANAGED_TABLE.name());
         Assert.assertEquals(tableRef.get(HiveDataModelGenerator.COMMENT), "table comment");
         String entityName = HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName);
-        Assert.assertEquals(tableRef.get(HiveDataModelGenerator.NAME), tableName.toLowerCase());
-        Assert.assertEquals(tableRef.get(AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME), entityName);
+        Assert.assertEquals(tableRef.get(HiveDataModelGenerator.NAME), entityName);
+        Assert.assertEquals(tableRef.get(HiveDataModelGenerator.NAME), "default." + tableName.toLowerCase() + "@" + CLUSTER_NAME);
 
         Table t = hiveMetaStoreBridge.hiveClient.getTable(DEFAULT_DB, tableName);
         long createTime = Long.parseLong(t.getMetadata().getProperty(hive_metastoreConstants.DDL_TIME)) * HiveMetaStoreBridge.MILLIS_CONVERT_FACTOR;
@@ -248,7 +247,7 @@ public class HiveHookIT {
         verifyTimestamps(processReference, "startTime");
         verifyTimestamps(processReference, "endTime");
 
-        validateHDFSPaths(processReference, INPUTS, pFile);
+        validateHDFSPaths(processReference, pFile, INPUTS);
     }
 
     private void validateOutputTables(Referenceable processReference, String... expectedTableNames) throws Exception {
@@ -263,7 +262,7 @@ public class HiveHookIT {
         List<Id> tableRef = (List<Id>) processReference.get(attrName);
         for(int i = 0; i < expectedTableNames.length; i++) {
             Referenceable entity = atlasClient.getEntity(tableRef.get(i)._getId());
-            Assert.assertEquals(entity.get(AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME), expectedTableNames[i]);
+            Assert.assertEquals(entity.get(AtlasClient.NAME), expectedTableNames[i]);
         }
     }
 
@@ -300,35 +299,6 @@ public class HiveHookIT {
         assertTableIsRegistered(DEFAULT_DB, ctasTableName);
     }
 
-    @Test
-    public void testDropAndRecreateCTASOutput() throws Exception {
-        String tableName = createTable();
-        String ctasTableName = "table" + random();
-        String query = "create table " + ctasTableName + " as select * from " + tableName;
-        runCommand(query);
-
-        assertTableIsRegistered(DEFAULT_DB, ctasTableName);
-        String processId = assertProcessIsRegistered(query);
-
-        final String drpquery = String.format("drop table %s ", ctasTableName);
-        runCommand(drpquery);
-        assertTableIsNotRegistered(DEFAULT_DB, ctasTableName);
-
-        //Fix after ATLAS-876
-        runCommand(query);
-        assertTableIsRegistered(DEFAULT_DB, ctasTableName);
-        String process2Id = assertProcessIsRegistered(query);
-
-        Assert.assertEquals(process2Id, processId);
-
-        Referenceable processRef = atlasClient.getEntity(processId);
-        String tblQlfdname = getQualifiedTblName(tableName);
-        String ctasQlfdname = getQualifiedTblName(ctasTableName);
-
-        validateInputTables(processRef, tblQlfdname);
-        validateOutputTables(processRef, ctasQlfdname, ctasQlfdname);
-    }
-
     @Test
     public void testCreateView() throws Exception {
         String tableName = createTable();
@@ -357,8 +327,8 @@ public class HiveHookIT {
         String datasetName = HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, viewName);
         JSONObject response = atlasClient.getInputGraph(datasetName);
         JSONObject vertices = response.getJSONObject("values").getJSONObject("vertices");
-        assertTrue(vertices.has(viewId));
-        assertTrue(vertices.has(table1Id));
+        Assert.assertTrue(vertices.has(viewId));
+        Assert.assertTrue(vertices.has(table1Id));
 
         //Alter the view from table2
         String table2Name = createTable();
@@ -373,13 +343,13 @@ public class HiveHookIT {
         datasetName = HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, viewName);
         response = atlasClient.getInputGraph(datasetName);
         vertices = response.getJSONObject("values").getJSONObject("vertices");
-        assertTrue(vertices.has(viewId));
+        Assert.assertTrue(vertices.has(viewId));
 
         //This is through the alter view process
-        assertTrue(vertices.has(table2Id));
+        Assert.assertTrue(vertices.has(table2Id));
 
         //This is through the Create view process
-        assertTrue(vertices.has(table1Id));
+        Assert.assertTrue(vertices.has(table1Id));
 
         //Outputs dont exist
         response = atlasClient.getOutputGraph(datasetName);
@@ -431,7 +401,7 @@ public class HiveHookIT {
         final String tblQlfdName = getQualifiedTblName(tableName);
         Referenceable processReference = validateProcess(query, testPathNormed, tblQlfdName);
 
-        validateHDFSPaths(processReference, INPUTS, loadFile);
+        validateHDFSPaths(processReference, loadFile, INPUTS);
 
         validateOutputTables(processReference, tblQlfdName);
     }
@@ -445,8 +415,8 @@ public class HiveHookIT {
         return inputtblQlfdName;
     }
 
-    private Referenceable validateProcess(String query, String inputTable, String... outputTables) throws Exception {
-        String processId = assertProcessIsRegistered(query, inputTable, outputTables);
+    private Referenceable validateProcess(String query, String inputTable, String outputTable) throws Exception {
+        String processId = assertProcessIsRegistered(query, inputTable, outputTable);
         Referenceable process = atlasClient.getEntity(processId);
         if (inputTable == null) {
             Assert.assertNull(process.get(INPUTS));
@@ -455,11 +425,11 @@ public class HiveHookIT {
             validateInputTables(process, inputTable);
         }
 
-        if (outputTables == null) {
+        if (outputTable == null) {
             Assert.assertNull(process.get(OUTPUTS));
         } else {
-            Assert.assertEquals(((List<Id>) process.get(OUTPUTS)).size(), 1);
-            validateOutputTables(process, outputTables);
+            Assert.assertEquals(((List<Id>) process.get(OUTPUTS)).size(), 1 );
+            validateOutputTables(process, outputTable);
         }
 
         return process;
@@ -500,43 +470,6 @@ public class HiveHookIT {
         assertTableIsRegistered(DEFAULT_DB, tableName);
     }
 
-    @Test
-    public void testUpdateProcess() throws Exception {
-        String tableName = createTable();
-        String pFile1 = createTestDFSPath("somedfspath1");
-        String testPathNormed = lower(new Path(pFile1).toString());
-        String query =
-            "insert overwrite DIRECTORY '" + pFile1  + "' select id, name from " + tableName;
-
-        runCommand(query);
-        String tblQlfdname = getQualifiedTblName(tableName);
-        Referenceable processReference = validateProcess(query, tblQlfdname, testPathNormed);
-        validateHDFSPaths(processReference, OUTPUTS, pFile1);
-
-        String tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-
-        validateInputTables(processReference, tblQlfdname);
-
-        //Rerun same query with same HDFS path
-
-        runCommand(query);
-        Referenceable process2Reference = validateProcess(query, tblQlfdname, testPathNormed);
-        validateHDFSPaths(process2Reference, OUTPUTS, pFile1);
-
-        Assert.assertEquals(process2Reference.getId()._getId(), processReference.getId()._getId());
-
-        //Rerun same query with a new HDFS path. Should create a new process
-        String pFile2 = createTestDFSPath("somedfspath2");
-        query = "insert overwrite DIRECTORY '" + pFile2  + "' select id, name from " + tableName;
-        final String testPathNormed2 = lower(new Path(pFile2).toString());
-        runCommand(query);
-
-        Referenceable process3Reference = validateProcess(query, tblQlfdname, testPathNormed2);
-        validateHDFSPaths(process3Reference, OUTPUTS, pFile2);
-
-        Assert.assertNotEquals(process3Reference.getId()._getId(), processReference.getId()._getId());
-    }
-
     @Test
     public void testInsertIntoDFSDir() throws Exception {
         String tableName = createTable();
@@ -548,7 +481,7 @@ public class HiveHookIT {
         runCommand(query);
         String tblQlfdname = getQualifiedTblName(tableName);
         Referenceable processReference = validateProcess(query, tblQlfdname, testPathNormed);
-        validateHDFSPaths(processReference, OUTPUTS, pFile1);
+        validateHDFSPaths(processReference, pFile1, OUTPUTS);
 
         String tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
 
@@ -564,7 +497,7 @@ public class HiveHookIT {
         runCommand(query);
         tblQlfdname = getQualifiedTblName(tableName);
         Referenceable process2Reference = validateProcess(query, tblQlfdname, testPathNormed);
-        validateHDFSPaths(process2Reference, OUTPUTS, pFile2);
+        validateHDFSPaths(process2Reference, pFile2, OUTPUTS);
 
         Assert.assertNotEquals(process2Reference.getId()._getId(), processReference.getId()._getId());
     }
@@ -630,7 +563,7 @@ public class HiveHookIT {
         runCommand(query);
         String tblQlfName = getQualifiedTblName(tableName);
         Referenceable processReference = validateProcess(query, tblQlfName, testPathNormed);
-        validateHDFSPaths(processReference, OUTPUTS, filename);
+        validateHDFSPaths(processReference, filename, OUTPUTS);
         validateInputTables(processReference, tblQlfName);
 
         //Import
@@ -641,7 +574,7 @@ public class HiveHookIT {
         runCommand(query);
         tblQlfName = getQualifiedTblName(tableName);
         processReference = validateProcess(query, testPathNormed, tblQlfName);
-        validateHDFSPaths(processReference, INPUTS, filename);
+        validateHDFSPaths(processReference, filename, INPUTS);
 
         validateOutputTables(processReference, tblQlfName);
     }
@@ -662,7 +595,7 @@ public class HiveHookIT {
         runCommand(query);
         String tblQlfdName = getQualifiedTblName(tableName);
         Referenceable processReference = validateProcess(query, tblQlfdName, testPathNormed);
-        validateHDFSPaths(processReference, OUTPUTS, filename);
+        validateHDFSPaths(processReference, filename, OUTPUTS);
 
         validateInputTables(processReference, tblQlfdName);
 
@@ -674,7 +607,7 @@ public class HiveHookIT {
         runCommand(query);
         tblQlfdName = getQualifiedTblName(tableName);
         processReference = validateProcess(query, testPathNormed, tblQlfdName);
-        validateHDFSPaths(processReference, INPUTS, filename);
+        validateHDFSPaths(processReference, filename, INPUTS);
 
         validateOutputTables(processReference, tblQlfdName);
     }
@@ -692,27 +625,13 @@ public class HiveHookIT {
         assertProcessIsNotRegistered(query);
     }
 
-    @Test
-    public void testAlterTableRenameAliasRegistered() throws Exception{
-        String tableName = createTable(false);
-        String tableGuid = assertTableIsRegistered(DEFAULT_DB, tableName);
-        String newTableName = tableName();
-        String query = String.format("alter table %s rename to %s", tableName, newTableName);
-        runCommand(query);
-        String newTableGuid = assertTableIsRegistered(DEFAULT_DB, newTableName);
-        Map<String, Object> valueMap = atlasClient.getEntity(newTableGuid).getValuesMap();
-        Iterable<String> aliasList = (Iterable<String>) valueMap.get("aliases");
-        String aliasTableName = aliasList.iterator().next();
-        assert tableName.toLowerCase().equals(aliasTableName);
-    }
-
     @Test
     public void testAlterTableRename() throws Exception {
         String tableName = createTable(true);
         final String newDBName = createDatabase();
 
         assertTableIsRegistered(DEFAULT_DB, tableName);
-        String columnGuid = assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), NAME));
+        String columnGuid = assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), HiveDataModelGenerator.NAME));
         String sdGuid = assertSDIsRegistered(HiveMetaStoreBridge.getStorageDescQFName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName)), null);
         assertDatabaseIsRegistered(newDBName);
 
@@ -730,10 +649,10 @@ public class HiveHookIT {
         String query = String.format("alter table %s rename to %s", DEFAULT_DB + "." + tableName, newDBName + "." + newTableName);
         runCommand(query);
 
-        String newColGuid = assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, newDBName, newTableName), NAME));
+        String newColGuid = assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, newDBName, newTableName), HiveDataModelGenerator.NAME));
         Assert.assertEquals(newColGuid, columnGuid);
 
-        assertColumnIsNotRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, newDBName, tableName), NAME));
+        assertColumnIsNotRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, newDBName, tableName), HiveDataModelGenerator.NAME));
 
         assertTrait(columnGuid, colTraitDetails);
         String newSdGuid = assertSDIsRegistered(HiveMetaStoreBridge.getStorageDescQFName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, newDBName, newTableName)), null);
@@ -749,7 +668,7 @@ public class HiveHookIT {
             public void assertOnEntity(final Referenceable entity) throws Exception {
                 Referenceable sd = ((Referenceable) entity.get(HiveDataModelGenerator.STORAGE_DESC));
                 String location = (String) sd.get(HiveDataModelGenerator.LOCATION);
-                assertTrue(location.contains(newTableName));
+                Assert.assertTrue(location.contains(newTableName));
             }
         });
     }
@@ -757,16 +676,7 @@ public class HiveHookIT {
     private List<Referenceable> getColumns(String dbName, String tableName) throws Exception {
         String tableId = assertTableIsRegistered(dbName, tableName);
         Referenceable tableRef = atlasClient.getEntity(tableId);
-
-        //with soft delete, the deleted columns are returned as well. So, filter the deleted ones
-        List<Referenceable> columns = ((List<Referenceable>) tableRef.get(HiveDataModelGenerator.COLUMNS));
-        List<Referenceable> activeColumns = new ArrayList<>();
-        for (Referenceable col : columns) {
-            if (col.getId().getState() == Id.EntityState.ACTIVE) {
-                activeColumns.add(col);
-            }
-        }
-        return activeColumns;
+        return ((List<Referenceable>)tableRef.get(HiveDataModelGenerator.COLUMNS));
     }
 
 
@@ -813,15 +723,21 @@ public class HiveHookIT {
                 colDropped));
 
         //Verify the number of columns present in the table
-        List<Referenceable> columns = getColumns(DEFAULT_DB, tableName);
-        assertEquals(columns.size(), 1);
-        assertEquals(columns.get(0).get(NAME), "name");
+        assertTableIsRegistered(DEFAULT_DB, tableName, new AssertPredicate() {
+            @Override
+            public void assertOnEntity(Referenceable tableRef) throws Exception {
+                List<Referenceable> columns = (List<Referenceable>) tableRef.get(HiveDataModelGenerator.COLUMNS);
+                Assert.assertEquals(columns.size(), 1);
+                Assert.assertEquals(columns.get(0).get(HiveDataModelGenerator.NAME), HiveDataModelGenerator.NAME);
+
+            }
+        });
     }
 
     @Test
     public void testAlterTableChangeColumn() throws Exception {
         //Change name
-        String oldColName = NAME;
+        String oldColName = HiveDataModelGenerator.NAME;
         String newColName = "name1";
         String tableName = createTable();
         String query = String.format("alter table %s change %s %s string", tableName, oldColName, newColName);
@@ -902,8 +818,8 @@ public class HiveHookIT {
                 @Override
                 public void assertOnEntity(Referenceable entity) throws Exception {
                     List<Referenceable> columns = (List<Referenceable>) entity.get(HiveDataModelGenerator.COLUMNS);
-                    assertEquals(columns.get(0).get(NAME), finalNewColName);
-                    assertEquals(columns.get(1).get(NAME), "id");
+                    assertEquals(columns.get(0).get(HiveDataModelGenerator.NAME), finalNewColName);
+                    assertEquals(columns.get(1).get(HiveDataModelGenerator.NAME), "id");
                 }
             }
         );
@@ -930,8 +846,8 @@ public class HiveHookIT {
                 @Override
                 public void assertOnEntity(Referenceable entity) throws Exception {
                     List<Referenceable> columns = (List<Referenceable>) entity.get(HiveDataModelGenerator.COLUMNS);
-                    assertEquals(columns.get(1).get(NAME), finalNewColName2);
-                    assertEquals(columns.get(0).get(NAME), "id");
+                    assertEquals(columns.get(1).get(HiveDataModelGenerator.NAME), finalNewColName2);
+                    assertEquals(columns.get(0).get(HiveDataModelGenerator.NAME), "id");
                 }
             }
         );
@@ -992,42 +908,6 @@ public class HiveHookIT {
         });
     }
 
-    @Test
-    public void testAlterTableWithoutHookConf() throws Exception {
-        HiveConf conf = new HiveConf();
-        conf.set("hive.exec.post.hooks", "");
-        SessionState ss = new SessionState(conf);
-        ss = SessionState.start(ss);
-        SessionState.setCurrentSessionState(ss);
-        Driver driver = new Driver(conf);
-        String tableName = tableName();
-        String createCommand = "create table " + tableName + " (id int, name string)";
-        driver.run(createCommand);
-        assertTableIsNotRegistered(DEFAULT_DB, tableName);
-        String command = "alter table " + tableName + " change id id_new string";
-        runCommand(command);
-        assertTableIsRegistered(DEFAULT_DB, tableName);
-        String tbqn = HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName);
-        assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(tbqn, "id_new"));
-    }
-
-    @Test
-    public void testTraitsPreservedOnColumnRename() throws Exception {
-        String tableName = createTable();
-        String tbqn = HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName);
-        String guid = assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(tbqn, "id"));
-        String trait = createTrait(guid);
-        String oldColName = "id";
-        String newColName = "id_new";
-        String query = String.format("alter table %s change %s %s string", tableName, oldColName, newColName);
-        runCommand(query);
-
-        String guid2 = assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(tbqn, "id_new"));
-        assertEquals(guid2, guid);
-
-        assertTrue(atlasClient.getEntity(guid2).getTraits().contains(trait));
-    }
-
     @Test
     public void testAlterViewRename() throws Exception {
         String tableName = createTable();
@@ -1063,27 +943,28 @@ public class HiveHookIT {
 
         final String testPathNormed = lower(new Path(testPath).toString());
         Referenceable processReference = validateProcess(query, testPathNormed, tblQlfdName);
-        validateHDFSPaths(processReference, INPUTS, testPath);
+        validateHDFSPaths(processReference, testPath, INPUTS);
     }
 
-    private void validateHDFSPaths(Referenceable processReference, String attributeName, String... testPaths) throws Exception {
+    private String validateHDFSPaths(Referenceable processReference, String testPath, String attributeName) throws Exception {
         List<Id> hdfsPathRefs = (List<Id>) processReference.get(attributeName);
 
-        for (int i = 0; i < testPaths.length; i++) {
-            final String testPathNormed = lower(new Path(testPaths[i]).toString());
-            String hdfsPathId = assertHDFSPathIsRegistered(testPathNormed);
-            Assert.assertEquals(hdfsPathRefs.get(0)._getId(), hdfsPathId);
+        final String testPathNormed = lower(new Path(testPath).toString());
+        String hdfsPathId = assertHDFSPathIsRegistered(testPathNormed);
+        Assert.assertEquals(hdfsPathRefs.get(0)._getId(), hdfsPathId);
 
-            Referenceable hdfsPathRef = atlasClient.getEntity(hdfsPathId);
-            Assert.assertEquals(hdfsPathRef.get("path"), testPathNormed);
-            Assert.assertEquals(hdfsPathRef.get(NAME), new Path(testPathNormed).getName());
-            Assert.assertEquals(hdfsPathRef.get(AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME), testPathNormed);
-        }
+        Referenceable hdfsPathRef = atlasClient.getEntity(hdfsPathId);
+        Assert.assertEquals(hdfsPathRef.get("path"), testPathNormed);
+        Assert.assertEquals(hdfsPathRef.get(HiveDataModelGenerator.NAME), testPathNormed);
+//        Assert.assertEquals(hdfsPathRef.get("name"), new Path(testPath).getName());
+        Assert.assertEquals(hdfsPathRef.get(AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME), testPathNormed);
+
+        return hdfsPathRef.getId()._getId();
     }
 
     private String assertHDFSPathIsRegistered(String path) throws Exception {
         LOG.debug("Searching for hdfs path {}", path);
-        return assertEntityIsRegistered(FSDataTypes.HDFS_PATH().toString(), AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME, path, null);
+        return assertEntityIsRegistered(FSDataTypes.HDFS_PATH().toString(), HiveDataModelGenerator.NAME, path, null);
     }
 
     @Test
@@ -1133,7 +1014,7 @@ public class HiveHookIT {
         ImmutableList<String> cols = ImmutableList.of("id");
         runBucketSortQuery(tableName, 5, cols, cols);
 
-        cols = ImmutableList.of("id", NAME);
+        cols = ImmutableList.of("id", HiveDataModelGenerator.NAME);
         runBucketSortQuery(tableName, 2, cols, cols);
     }
 
@@ -1196,7 +1077,7 @@ public class HiveHookIT {
 
         assertTableIsRegistered(DEFAULT_DB, tableName);
         assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), "id"));
-        assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), NAME));
+        assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), HiveDataModelGenerator.NAME));
 
         final String query = String.format("drop table %s ", tableName);
         runCommand(query);
@@ -1205,7 +1086,7 @@ public class HiveHookIT {
                 "id"));
         assertColumnIsNotRegistered(HiveMetaStoreBridge
             .getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName),
-                NAME));
+                HiveDataModelGenerator.NAME));
         assertTableIsNotRegistered(DEFAULT_DB, tableName);
     }
 
@@ -1229,7 +1110,7 @@ public class HiveHookIT {
             HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, dbName, tableNames[0]), "id"));
         assertColumnIsNotRegistered(HiveMetaStoreBridge
             .getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, dbName, tableNames[0]),
-                NAME));
+                HiveDataModelGenerator.NAME));
 
         for(int i = 0; i < numTables; i++) {
             assertTableIsNotRegistered(dbName, tableNames[i]);
@@ -1294,7 +1175,7 @@ public class HiveHookIT {
 
         assertTableIsRegistered(DEFAULT_DB, viewName);
         assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, viewName), "id"));
-        assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, viewName), NAME));
+        assertColumnIsRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, viewName), HiveDataModelGenerator.NAME));
 
         query = String.format("drop view %s ", viewName);
 
@@ -1304,7 +1185,7 @@ public class HiveHookIT {
                     "id"));
         assertColumnIsNotRegistered(HiveMetaStoreBridge
             .getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, viewName),
-                NAME));
+                HiveDataModelGenerator.NAME));
         assertTableIsNotRegistered(DEFAULT_DB, viewName);
     }
 
@@ -1459,29 +1340,28 @@ public class HiveHookIT {
         }
     }
 
-    private String assertProcessIsRegistered(final String queryStr, final String inputTblName, final String... outputTblNames) throws Exception {
+    private String assertProcessIsRegistered(final String queryStr, final String inputTblName, final String outputTblName) throws Exception {
 
         HiveASTRewriter astRewriter = new HiveASTRewriter(conf);
         String normalizedQuery = normalize(astRewriter.rewrite(queryStr));
 
         List<Referenceable> inputs = null;
+
         if (inputTblName != null) {
             Referenceable inputTableRef = new Referenceable(HiveDataTypes.HIVE_TABLE.name(), new HashMap<String, Object>() {{
-                put(AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME, inputTblName);
+                put(HiveDataModelGenerator.NAME, inputTblName);
             }});
             inputs = new ArrayList<Referenceable>();
             inputs.add(inputTableRef);
         }
-        List<Referenceable> outputs = new ArrayList<Referenceable>();
-        if (outputTblNames != null) {
-            for(int i = 0; i < outputTblNames.length; i++) {
-                final String outputTblName = outputTblNames[i];
-                Referenceable outputTableRef = new Referenceable(HiveDataTypes.HIVE_TABLE.name(), new HashMap<String, Object>() {{
-                    put(AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME, outputTblName);
-                }});
-
-                outputs.add(outputTableRef);
-            }
+        List<Referenceable> outputs = null;
+        if (outputTblName != null) {
+            Referenceable outputTableRef = new Referenceable(HiveDataTypes.HIVE_TABLE.name(), new HashMap<String, Object>() {{
+                put(HiveDataModelGenerator.NAME, outputTblName);
+            }});
+
+            outputs = new ArrayList<Referenceable>();
+            outputs.add(outputTableRef);
         }
         String processQFName = HiveHook.getProcessQualifiedName(normalizedQuery, inputs, outputs);
         LOG.debug("Searching for process with query {}", processQFName);
@@ -1514,13 +1394,13 @@ public class HiveHookIT {
     private void assertTableIsNotRegistered(String dbName, String tableName, boolean isTemporaryTable) throws Exception {
         LOG.debug("Searching for table {}.{}", dbName, tableName);
         String tableQualifiedName = HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, dbName, tableName, isTemporaryTable);
-        assertEntityIsNotRegistered(HiveDataTypes.HIVE_TABLE.getName(), AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME, tableQualifiedName);
+        assertEntityIsNotRegistered(HiveDataTypes.HIVE_TABLE.getName(), AtlasClient.NAME, tableQualifiedName);
     }
 
     private void assertTableIsNotRegistered(String dbName, String tableName) throws Exception {
         LOG.debug("Searching for table {}.{}", dbName, tableName);
         String tableQualifiedName = HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, dbName, tableName, false);
-        assertEntityIsNotRegistered(HiveDataTypes.HIVE_TABLE.getName(), AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME, tableQualifiedName);
+        assertEntityIsNotRegistered(HiveDataTypes.HIVE_TABLE.getName(), AtlasClient.NAME, tableQualifiedName);
     }
 
     private void assertDBIsNotRegistered(String dbName) throws Exception {
@@ -1540,7 +1420,7 @@ public class HiveHookIT {
     private String assertTableIsRegistered(String dbName, String tableName, AssertPredicate assertPredicate, boolean isTemporary) throws Exception {
         LOG.debug("Searching for table {}.{}", dbName, tableName);
         String tableQualifiedName = HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, dbName, tableName, isTemporary);
-        return assertEntityIsRegistered(HiveDataTypes.HIVE_TABLE.getName(), AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME, tableQualifiedName,
+        return assertEntityIsRegistered(HiveDataTypes.HIVE_TABLE.getName(), AtlasClient.NAME, tableQualifiedName,
             assertPredicate);
     }
 
@@ -1607,14 +1487,14 @@ public class HiveHookIT {
         String datasetName = HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, db2, table2);
         JSONObject response = atlasClient.getInputGraph(datasetName);
         JSONObject vertices = response.getJSONObject("values").getJSONObject("vertices");
-        assertTrue(vertices.has(table1Id));
-        assertTrue(vertices.has(table2Id));
+        Assert.assertTrue(vertices.has(table1Id));
+        Assert.assertTrue(vertices.has(table2Id));
 
         datasetName = HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, table1);
         response = atlasClient.getOutputGraph(datasetName);
         vertices = response.getJSONObject("values").getJSONObject("vertices");
-        assertTrue(vertices.has(table1Id));
-        assertTrue(vertices.has(table2Id));
+        Assert.assertTrue(vertices.has(table1Id));
+        Assert.assertTrue(vertices.has(table2Id));
     }
 
     //For ATLAS-448