diff --git a/addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/events/BaseHiveEvent.java b/addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/events/BaseHiveEvent.java
index 0bf3ce27a..2b0c5d9fc 100644
--- a/addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/events/BaseHiveEvent.java
+++ b/addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/events/BaseHiveEvent.java
@@ -18,22 +18,17 @@
 
 package org.apache.atlas.hive.hook.events;
 
-import com.google.common.collect.ImmutableMap;
 import org.apache.atlas.hive.hook.AtlasHiveHookContext;
-import org.apache.atlas.hive.hook.HiveHook.PreprocessAction;
 import org.apache.atlas.model.instance.AtlasEntity;
 import org.apache.atlas.model.instance.AtlasEntity.AtlasEntitiesWithExtInfo;
 import org.apache.atlas.model.instance.AtlasEntity.AtlasEntityWithExtInfo;
 import org.apache.atlas.model.instance.AtlasEntity.AtlasEntityExtInfo;
 import org.apache.atlas.model.instance.AtlasObjectId;
-import org.apache.atlas.model.instance.AtlasRelatedObjectId;
 import org.apache.atlas.model.instance.AtlasStruct;
 import org.apache.atlas.model.notification.HookNotification;
-import org.apache.atlas.repository.Constants;
-import org.apache.atlas.type.AtlasTypeUtil;
 import org.apache.atlas.utils.HdfsNameServiceResolver;
 import org.apache.commons.collections.CollectionUtils;
-import org.apache.commons.collections.MapUtils;
+import org.apache.commons.lang.RandomStringUtils;
 import org.apache.commons.lang3.StringUtils;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.hive.metastore.api.Database;
@@ -41,19 +36,20 @@ import org.apache.hadoop.hive.metastore.api.FieldSchema;
 import org.apache.hadoop.hive.metastore.api.Order;
 import org.apache.hadoop.hive.metastore.api.SerDeInfo;
 import org.apache.hadoop.hive.metastore.api.StorageDescriptor;
-import org.apache.hadoop.hive.metastore.utils.SecurityUtils;
-import org.apache.hadoop.hive.ql.hooks.*;
+import org.apache.hadoop.hive.ql.hooks.Entity;
+import org.apache.hadoop.hive.ql.hooks.HookContext;
 import org.apache.hadoop.hive.ql.hooks.LineageInfo.BaseColumnInfo;
 import org.apache.hadoop.hive.ql.hooks.LineageInfo.DependencyKey;
+import org.apache.hadoop.hive.ql.hooks.WriteEntity;
 import org.apache.hadoop.hive.ql.metadata.Hive;
 import org.apache.hadoop.hive.ql.metadata.Table;
 import org.apache.hadoop.hive.ql.plan.HiveOperation;
+import org.apache.hadoop.hive.ql.session.SessionState;
 import org.apache.hadoop.security.UserGroupInformation;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import java.io.IOException;
-import java.net.InetAddress;
 import java.net.URI;
 import java.util.ArrayList;
 import java.util.Collection;
@@ -65,34 +61,19 @@ import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
-import static org.apache.atlas.hive.hook.AtlasHiveHookContext.QNAME_SEP_CLUSTER_NAME;
-import static org.apache.atlas.hive.hook.AtlasHiveHookContext.QNAME_SEP_ENTITY_NAME;
-import static org.apache.atlas.hive.hook.AtlasHiveHookContext.QNAME_SEP_PROCESS;
 
 public abstract class BaseHiveEvent {
     private static final Logger LOG = LoggerFactory.getLogger(BaseHiveEvent.class);
 
-    public static final String HIVE_TYPE_DB                        = "hive_db";
-    public static final String HIVE_TYPE_TABLE                     = "hive_table";
-    public static final String HIVE_TYPE_STORAGEDESC               = "hive_storagedesc";
-    public static final String HIVE_TYPE_COLUMN                    = "hive_column";
-    public static final String HIVE_TYPE_PROCESS                   = "hive_process";
-    public static final String HIVE_TYPE_COLUMN_LINEAGE            = "hive_column_lineage";
-    public static final String HIVE_TYPE_SERDE                     = "hive_serde";
-    public static final String HIVE_TYPE_ORDER                     = "hive_order";
-    public static final String HIVE_TYPE_PROCESS_EXECUTION         = "hive_process_execution";
-    public static final String HIVE_DB_DDL                         = "hive_db_ddl";
-    public static final String HIVE_TABLE_DDL                      = "hive_table_ddl";
-    public static final String HDFS_TYPE_PATH                      = "hdfs_path";
-    public static final String HBASE_TYPE_TABLE                    = "hbase_table";
-    public static final String HBASE_TYPE_NAMESPACE                = "hbase_namespace";
-    public static final String AWS_S3_BUCKET                       = "aws_s3_bucket";
-    public static final String AWS_S3_PSEUDO_DIR                   = "aws_s3_pseudo_dir";
-    public static final String AWS_S3_OBJECT                       = "aws_s3_object";
-
-    public static final String SCHEME_SEPARATOR                    = "://";
-    public static final String S3_SCHEME                           = "s3" + SCHEME_SEPARATOR;
-    public static final String S3A_SCHEME                          = "s3a" + SCHEME_SEPARATOR;
+    public static final String HIVE_TYPE_DB             = "hive_db";
+    public static final String HIVE_TYPE_TABLE          = "hive_table";
+    public static final String HIVE_TYPE_STORAGEDESC    = "hive_storagedesc";
+    public static final String HIVE_TYPE_COLUMN         = "hive_column";
+    public static final String HIVE_TYPE_PROCESS        = "hive_process";
+    public static final String HIVE_TYPE_COLUMN_LINEAGE = "hive_column_lineage";
+    public static final String HIVE_TYPE_SERDE          = "hive_serde";
+    public static final String HIVE_TYPE_ORDER          = "hive_order";
+    public static final String HDFS_TYPE_PATH           = "hdfs_path";
 
     public static final String ATTRIBUTE_QUALIFIED_NAME            = "qualifiedName";
     public static final String ATTRIBUTE_NAME                      = "name";
@@ -134,8 +115,6 @@ public abstract class BaseHiveEvent {
     public static final String ATTRIBUTE_START_TIME                = "startTime";
     public static final String ATTRIBUTE_USER_NAME                 = "userName";
     public static final String ATTRIBUTE_QUERY_TEXT                = "queryText";
-    public static final String ATTRIBUTE_PROCESS                   = "process";
-    public static final String ATTRIBUTE_PROCESS_EXECUTIONS        = "processExecutions";
     public static final String ATTRIBUTE_QUERY_ID                  = "queryId";
     public static final String ATTRIBUTE_QUERY_PLAN                = "queryPlan";
     public static final String ATTRIBUTE_END_TIME                  = "endTime";
@@ -144,38 +123,14 @@ public abstract class BaseHiveEvent {
     public static final String ATTRIBUTE_DEPENDENCY_TYPE           = "depenendencyType";
     public static final String ATTRIBUTE_EXPRESSION                = "expression";
     public static final String ATTRIBUTE_ALIASES                   = "aliases";
-    public static final String ATTRIBUTE_URI                       = "uri";
-    public static final String ATTRIBUTE_STORAGE_HANDLER           = "storage_handler";
-    public static final String ATTRIBUTE_NAMESPACE                 = "namespace";
-    public static final String ATTRIBUTE_OBJECT_PREFIX             = "objectPrefix";
-    public static final String ATTRIBUTE_BUCKET                    = "bucket";
-    public static final String ATTRIBUTE_HOSTNAME                  = "hostName";
-    public static final String ATTRIBUTE_EXEC_TIME                 = "execTime";
-    public static final String ATTRIBUTE_DDL_QUERIES               = "ddlQueries";
-    public static final String ATTRIBUTE_SERVICE_TYPE              = "serviceType";
-
-    public static final String HBASE_STORAGE_HANDLER_CLASS         = "org.apache.hadoop.hive.hbase.HBaseStorageHandler";
-    public static final String HBASE_DEFAULT_NAMESPACE             = "default";
-    public static final String HBASE_NAMESPACE_TABLE_DELIMITER     = ":";
-    public static final String HBASE_PARAM_TABLE_NAME              = "hbase.table.name";
-    public static final long   MILLIS_CONVERT_FACTOR               = 1000;
-    public static final String HDFS_PATH_PREFIX                    = "hdfs://";
-    public static final String EMPTY_ATTRIBUTE_VALUE = "";
-
-    public static final String RELATIONSHIP_DATASET_PROCESS_INPUTS = "dataset_process_inputs";
-    public static final String RELATIONSHIP_PROCESS_DATASET_OUTPUTS = "process_dataset_outputs";
-    public static final String RELATIONSHIP_HIVE_PROCESS_COLUMN_LINEAGE = "hive_process_column_lineage";
-    public static final String RELATIONSHIP_HIVE_TABLE_DB = "hive_table_db";
-    public static final String RELATIONSHIP_HIVE_TABLE_PART_KEYS = "hive_table_partitionkeys";
-    public static final String RELATIONSHIP_HIVE_TABLE_COLUMNS = "hive_table_columns";
-    public static final String RELATIONSHIP_HIVE_TABLE_STORAGE_DESC = "hive_table_storagedesc";
-    public static final String RELATIONSHIP_AWS_S3_BUCKET_S3_PSEUDO_DIRS = "aws_s3_bucket_aws_s3_pseudo_dirs";
-    public static final String RELATIONSHIP_HIVE_PROCESS_PROCESS_EXE = "hive_process_process_executions";
-    public static final String RELATIONSHIP_HIVE_DB_DDL_QUERIES = "hive_db_ddl_queries";
-    public static final String RELATIONSHIP_HIVE_TABLE_DDL_QUERIES = "hive_table_ddl_queries";
-    public static final String RELATIONSHIP_HBASE_TABLE_NAMESPACE = "hbase_table_namespace";
 
 
+    public static final char   QNAME_SEP_CLUSTER_NAME = '@';
+    public static final char   QNAME_SEP_ENTITY_NAME  = '.';
+    public static final char   QNAME_SEP_PROCESS      = ':';
+    public static final String TEMP_TABLE_PREFIX      = "_temp-";
+    public static final long   MILLIS_CONVERT_FACTOR  = 1000;
+
     public static final Map<Integer, String> OWNER_TYPE_TO_ENUM_VALUE = new HashMap<>();
 
 
@@ -204,32 +159,6 @@ public abstract class BaseHiveEvent {
         return table.getTTable() != null ? (table.getTTable().getCreateTime() * MILLIS_CONVERT_FACTOR) : System.currentTimeMillis();
     }
 
-    public static String getTableOwner(Table table) {
-        return table.getTTable() != null ? (table.getOwner()): "";
-    }
-
-
-    public static AtlasRelatedObjectId getObjectIdWithRelationshipType(AtlasEntity entity, String relationShipType) {
-        AtlasRelatedObjectId atlasRelatedObjectId = new AtlasRelatedObjectId(getObjectId(entity), relationShipType);
-        return atlasRelatedObjectId;
-    }
-
-
-
-    public static List<AtlasRelatedObjectId> getObjectIdsWithRelationshipType(List<AtlasEntity> entities,String relationshipType) {
-        final List<AtlasRelatedObjectId> ret;
-        if (CollectionUtils.isNotEmpty(entities)) {
-            ret = new ArrayList<>(entities.size());
-            for (AtlasEntity entity : entities) {
-                ret.add(getObjectIdWithRelationshipType(entity, relationshipType));
-            }
-        } else {
-            ret = Collections.emptyList();
-        }
-        return ret;
-    }
-
-
     public static AtlasObjectId getObjectId(AtlasEntity entity) {
         String        qualifiedName = (String) entity.getAttribute(ATTRIBUTE_QUALIFIED_NAME);
         AtlasObjectId ret           = new AtlasObjectId(entity.getGuid(), entity.getTypeName(), Collections.singletonMap(ATTRIBUTE_QUALIFIED_NAME, qualifiedName));
@@ -288,31 +217,17 @@ public abstract class BaseHiveEvent {
 
         switch (entity.getType()) {
             case DATABASE: {
-                if (!context.getIgnoreDummyDatabaseName().contains(entity.getDatabase().getName())) {
-                    Database db = getHive().getDatabase(entity.getDatabase().getName());
+                Database db = getHive().getDatabase(entity.getDatabase().getName());
 
-                    ret = toDbEntity(db);
-                }
+                ret = toDbEntity(db);
             }
             break;
 
             case TABLE:
             case PARTITION: {
-                String  dbName    = entity.getTable().getDbName();
-                String  tableName = entity.getTable().getTableName();
-                boolean skipTable = StringUtils.isNotEmpty(context.getIgnoreValuesTmpTableNamePrefix()) && tableName.toLowerCase().startsWith(context.getIgnoreValuesTmpTableNamePrefix());
-
-                if (!skipTable) {
-                    skipTable = context.getIgnoreDummyTableName().contains(tableName) && context.getIgnoreDummyDatabaseName().contains(dbName);
-                }
+                Table table = getHive().getTable(entity.getTable().getDbName(), entity.getTable().getTableName());
 
-                if (!skipTable) {
-                    Table table = getHive().getTable(dbName, tableName);
-
-                    ret = toTableEntity(table, entityExtInfo);
-                } else {
-                    context.registerSkippedEntity(entity);
-                }
+                ret = toTableEntity(table, entityExtInfo);
             }
             break;
 
@@ -320,7 +235,7 @@ public abstract class BaseHiveEvent {
                 URI location = entity.getLocation();
 
                 if (location != null) {
-                    ret = getPathEntity(new Path(entity.getLocation()), entityExtInfo);
+                    ret = getHDFSPathEntity(new Path(entity.getLocation()));
                 }
             }
             break;
@@ -354,7 +269,7 @@ public abstract class BaseHiveEvent {
             ret.setAttribute(ATTRIBUTE_OWNER, db.getOwnerName());
 
             ret.setAttribute(ATTRIBUTE_CLUSTER_NAME, getClusterName());
-            ret.setAttribute(ATTRIBUTE_LOCATION, HdfsNameServiceResolver.getPathWithNameServiceID(db.getLocationUri()));
+            ret.setAttribute(ATTRIBUTE_LOCATION, HdfsNameServiceResolver.getInstance().getPathWithNameServiceID(db.getLocationUri()));
             ret.setAttribute(ATTRIBUTE_PARAMETERS, db.getParameters());
 
             if (db.getOwnerType() != null) {
@@ -372,11 +287,7 @@ public abstract class BaseHiveEvent {
 
         AtlasEntity entity = toTableEntity(table, ret);
 
-        if (entity != null) {
-            ret.setEntity(entity);
-        } else {
-            ret = null;
-        }
+        ret.setEntity(entity);
 
         return ret;
     }
@@ -384,16 +295,13 @@ public abstract class BaseHiveEvent {
     protected AtlasEntity toTableEntity(Table table, AtlasEntitiesWithExtInfo entities) throws Exception {
         AtlasEntity ret = toTableEntity(table, (AtlasEntityExtInfo) entities);
 
-        if (ret != null) {
-            entities.addEntity(ret);
-        }
+        entities.addEntity(ret);
 
         return ret;
     }
 
     protected AtlasEntity toTableEntity(Table table, AtlasEntityExtInfo entityExtInfo) throws Exception {
-        Database    db       = getDatabases(table.getDbName());
-        AtlasEntity dbEntity = toDbEntity(db);
+        AtlasEntity dbEntity = toDbEntity(getHive().getDatabase(table.getDbName()));
 
         if (entityExtInfo != null) {
             if (dbEntity != null) {
@@ -413,81 +321,64 @@ public abstract class BaseHiveEvent {
         AtlasEntity ret = context.getEntity(tblQualifiedName);
 
         if (ret == null) {
-            PreprocessAction action = context.getPreprocessActionForHiveTable(tblQualifiedName);
-
-            if (action == PreprocessAction.IGNORE) {
-                LOG.info("ignoring table {}", tblQualifiedName);
-            } else {
-                ret = new AtlasEntity(HIVE_TYPE_TABLE);
-
-                // if this table was sent in an earlier notification, set 'guid' to null - which will:
-                //  - result in this entity to be not included in 'referredEntities'
-                //  - cause Atlas server to resolve the entity by its qualifiedName
-                if (isKnownTable && !isAlterTableOperation()) {
-                    ret.setGuid(null);
-                }
-
-                long createTime     = getTableCreateTime(table);
-                long lastAccessTime = table.getLastAccessTime() > 0 ? (table.getLastAccessTime() * MILLIS_CONVERT_FACTOR) : createTime;
-
-                AtlasRelatedObjectId dbRelatedObject =     new AtlasRelatedObjectId(dbId, RELATIONSHIP_HIVE_TABLE_DB);
-
-                ret.setRelationshipAttribute(ATTRIBUTE_DB, dbRelatedObject );
-                ret.setAttribute(ATTRIBUTE_QUALIFIED_NAME, tblQualifiedName);
-                ret.setAttribute(ATTRIBUTE_NAME, table.getTableName().toLowerCase());
-                ret.setAttribute(ATTRIBUTE_OWNER, table.getOwner());
-                ret.setAttribute(ATTRIBUTE_CREATE_TIME, createTime);
-                ret.setAttribute(ATTRIBUTE_LAST_ACCESS_TIME, lastAccessTime);
-                ret.setAttribute(ATTRIBUTE_RETENTION, table.getRetention());
-                ret.setAttribute(ATTRIBUTE_PARAMETERS, table.getParameters());
-                ret.setAttribute(ATTRIBUTE_COMMENT, table.getParameters().get(ATTRIBUTE_COMMENT));
-                ret.setAttribute(ATTRIBUTE_TABLE_TYPE, table.getTableType().name());
-                ret.setAttribute(ATTRIBUTE_TEMPORARY, table.isTemporary());
-
-                if (table.getViewOriginalText() != null) {
-                    ret.setAttribute(ATTRIBUTE_VIEW_ORIGINAL_TEXT, table.getViewOriginalText());
-                }
-
-                if (table.getViewExpandedText() != null) {
-                    ret.setAttribute(ATTRIBUTE_VIEW_EXPANDED_TEXT, table.getViewExpandedText());
-                }
-
-                boolean pruneTable = table.isTemporary() || action == PreprocessAction.PRUNE;
+            ret = new AtlasEntity(HIVE_TYPE_TABLE);
 
-                if (pruneTable) {
-                    LOG.info("ignoring details of table {}", tblQualifiedName);
-                } else {
-                    AtlasObjectId     tableId       = getObjectId(ret);
-                    AtlasEntity       sd            = getStorageDescEntity(tableId, table);
-                    List<AtlasEntity> partitionKeys = getColumnEntities(tableId, table, table.getPartitionKeys(), RELATIONSHIP_HIVE_TABLE_PART_KEYS);
-                    List<AtlasEntity> columns       = getColumnEntities(tableId, table, table.getCols(), RELATIONSHIP_HIVE_TABLE_COLUMNS);
+            // if this table was sent in an earlier notification, set 'guid' to null - which will:
+            //  - result in this entity to be not included in 'referredEntities'
+            //  - cause Atlas server to resolve the entity by its qualifiedName
+            if (isKnownTable && !isAlterTableOperation()) {
+                ret.setGuid(null);
+            }
 
+            long createTime     = getTableCreateTime(table);
+            long lastAccessTime = table.getLastAccessTime() > 0 ? (table.getLastAccessTime() * MILLIS_CONVERT_FACTOR) : createTime;
+
+            ret.setAttribute(ATTRIBUTE_DB, dbId);
+            ret.setAttribute(ATTRIBUTE_QUALIFIED_NAME, tblQualifiedName);
+            ret.setAttribute(ATTRIBUTE_NAME, table.getTableName().toLowerCase());
+            ret.setAttribute(ATTRIBUTE_OWNER, table.getOwner());
+            ret.setAttribute(ATTRIBUTE_CREATE_TIME, createTime);
+            ret.setAttribute(ATTRIBUTE_LAST_ACCESS_TIME, lastAccessTime);
+            ret.setAttribute(ATTRIBUTE_RETENTION, table.getRetention());
+            ret.setAttribute(ATTRIBUTE_PARAMETERS, table.getParameters());
+            ret.setAttribute(ATTRIBUTE_COMMENT, table.getParameters().get(ATTRIBUTE_COMMENT));
+            ret.setAttribute(ATTRIBUTE_TABLE_TYPE, table.getTableType().name());
+            ret.setAttribute(ATTRIBUTE_TEMPORARY, table.isTemporary());
+
+            if (table.getViewOriginalText() != null) {
+                ret.setAttribute(ATTRIBUTE_VIEW_ORIGINAL_TEXT, table.getViewOriginalText());
+            }
 
+            if (table.getViewExpandedText() != null) {
+                ret.setAttribute(ATTRIBUTE_VIEW_EXPANDED_TEXT, table.getViewExpandedText());
+            }
 
-                    if (entityExtInfo != null) {
-                        entityExtInfo.addReferredEntity(sd);
+            AtlasObjectId     tableId       = getObjectId(ret);
+            AtlasEntity       sd            = getStorageDescEntity(tableId, table);
+            List<AtlasEntity> partitionKeys = getColumnEntities(tableId, table, table.getPartitionKeys());
+            List<AtlasEntity> columns       = getColumnEntities(tableId, table, table.getCols());
 
-                        if (partitionKeys != null) {
-                            for (AtlasEntity partitionKey : partitionKeys) {
-                                entityExtInfo.addReferredEntity(partitionKey);
-                            }
-                        }
+            if (entityExtInfo != null) {
+                entityExtInfo.addReferredEntity(sd);
 
-                        if (columns != null) {
-                            for (AtlasEntity column : columns) {
-                                entityExtInfo.addReferredEntity(column);
-                            }
-                        }
+                if (partitionKeys != null) {
+                    for (AtlasEntity partitionKey : partitionKeys) {
+                        entityExtInfo.addReferredEntity(partitionKey);
                     }
-
-
-                    ret.setRelationshipAttribute(ATTRIBUTE_STORAGEDESC, getObjectIdWithRelationshipType(sd, RELATIONSHIP_HIVE_TABLE_STORAGE_DESC));
-                    ret.setRelationshipAttribute(ATTRIBUTE_PARTITION_KEYS, getObjectIdsWithRelationshipType(partitionKeys, RELATIONSHIP_HIVE_TABLE_PART_KEYS));
-                    ret.setRelationshipAttribute(ATTRIBUTE_COLUMNS, getObjectIdsWithRelationshipType(columns, RELATIONSHIP_HIVE_TABLE_COLUMNS));
                 }
 
-                context.putEntity(tblQualifiedName, ret);
+                if (columns != null) {
+                    for (AtlasEntity column : columns) {
+                        entityExtInfo.addReferredEntity(column);
+                    }
+                }
             }
+
+            ret.setAttribute(ATTRIBUTE_STORAGEDESC, getObjectId(sd));
+            ret.setAttribute(ATTRIBUTE_PARTITION_KEYS, getObjectIds(partitionKeys));
+            ret.setAttribute(ATTRIBUTE_COLUMNS, getObjectIds(columns));
+
+            context.putEntity(tblQualifiedName, ret);
         }
 
         return ret;
@@ -511,19 +402,17 @@ public abstract class BaseHiveEvent {
 
             StorageDescriptor sd = table.getSd();
 
-            AtlasRelatedObjectId tableRelatedObject =     new AtlasRelatedObjectId(tableId, RELATIONSHIP_HIVE_TABLE_STORAGE_DESC);
-
-            ret.setRelationshipAttribute(ATTRIBUTE_TABLE, tableRelatedObject);
+            ret.setAttribute(ATTRIBUTE_TABLE, tableId);
             ret.setAttribute(ATTRIBUTE_QUALIFIED_NAME, sdQualifiedName);
             ret.setAttribute(ATTRIBUTE_PARAMETERS, sd.getParameters());
-            ret.setAttribute(ATTRIBUTE_LOCATION, HdfsNameServiceResolver.getPathWithNameServiceID(sd.getLocation()));
+            ret.setAttribute(ATTRIBUTE_LOCATION, HdfsNameServiceResolver.getInstance().getPathWithNameServiceID(sd.getLocation()));
             ret.setAttribute(ATTRIBUTE_INPUT_FORMAT, sd.getInputFormat());
             ret.setAttribute(ATTRIBUTE_OUTPUT_FORMAT, sd.getOutputFormat());
             ret.setAttribute(ATTRIBUTE_COMPRESSED, sd.isCompressed());
             ret.setAttribute(ATTRIBUTE_NUM_BUCKETS, sd.getNumBuckets());
             ret.setAttribute(ATTRIBUTE_STORED_AS_SUB_DIRECTORIES, sd.isStoredAsSubDirectories());
 
-            if (sd.getBucketCols() != null && sd.getBucketCols().size() > 0) {
+            if (sd.getBucketCols().size() > 0) {
                 ret.setAttribute(ATTRIBUTE_BUCKET_COLS, sd.getBucketCols());
             }
 
@@ -559,108 +448,62 @@ public abstract class BaseHiveEvent {
         return ret;
     }
 
-    protected List<AtlasEntity> getColumnEntities(AtlasObjectId tableId, Table table, List<FieldSchema> fieldSchemas, String relationshipType) {
-        List<AtlasEntity> ret            = new ArrayList<>();
-        boolean           isKnownTable   = tableId.getGuid() == null;
-        int               columnPosition = 0;
+    protected List<AtlasEntity> getColumnEntities(AtlasObjectId tableId, Table table, List<FieldSchema> fieldSchemas) {
+        List<AtlasEntity> ret          = new ArrayList<>();
+        boolean           isKnownTable = tableId.getGuid() == null;
 
-        if (CollectionUtils.isNotEmpty(fieldSchemas)) {
-            for (FieldSchema fieldSchema : fieldSchemas) {
-                String      colQualifiedName = getQualifiedName(table, fieldSchema);
-                AtlasEntity column           = context.getEntity(colQualifiedName);
+        int columnPosition = 0;
+        for (FieldSchema fieldSchema : fieldSchemas) {
+            String      colQualifiedName = getQualifiedName(table, fieldSchema);
+            AtlasEntity column           = context.getEntity(colQualifiedName);
 
-                if (column == null) {
-                    column = new AtlasEntity(HIVE_TYPE_COLUMN);
+            if (column == null) {
+                column = new AtlasEntity(HIVE_TYPE_COLUMN);
 
-                    // if column's table was sent in an earlier notification, set 'guid' to null - which will:
-                    //  - result in this entity to be not included in 'referredEntities'
-                    //  - cause Atlas server to resolve the entity by its qualifiedName
-                    if (isKnownTable) {
-                        column.setGuid(null);
-                    }
-                    AtlasRelatedObjectId relatedObjectId = new AtlasRelatedObjectId(tableId, relationshipType);
-                    column.setRelationshipAttribute(ATTRIBUTE_TABLE, (relatedObjectId));
-                    column.setAttribute(ATTRIBUTE_QUALIFIED_NAME, colQualifiedName);
-                    column.setAttribute(ATTRIBUTE_NAME, fieldSchema.getName());
-                    column.setAttribute(ATTRIBUTE_OWNER, table.getOwner());
-                    column.setAttribute(ATTRIBUTE_COL_TYPE, fieldSchema.getType());
-                    column.setAttribute(ATTRIBUTE_COL_POSITION, columnPosition++);
-                    column.setAttribute(ATTRIBUTE_COMMENT, fieldSchema.getComment());
-
-                    context.putEntity(colQualifiedName, column);
+                // if column's table was sent in an earlier notification, set 'guid' to null - which will:
+                //  - result in this entity to be not included in 'referredEntities'
+                //  - cause Atlas server to resolve the entity by its qualifiedName
+                if (isKnownTable) {
+                    column.setGuid(null);
                 }
 
-                ret.add(column);
+                column.setAttribute(ATTRIBUTE_TABLE, tableId);
+                column.setAttribute(ATTRIBUTE_QUALIFIED_NAME, colQualifiedName);
+                column.setAttribute(ATTRIBUTE_NAME, fieldSchema.getName());
+                column.setAttribute(ATTRIBUTE_OWNER, table.getOwner());
+                column.setAttribute(ATTRIBUTE_COL_TYPE, fieldSchema.getType());
+                column.setAttribute(ATTRIBUTE_COL_POSITION, columnPosition++);
+                column.setAttribute(ATTRIBUTE_COMMENT, fieldSchema.getComment());
+
+                context.putEntity(colQualifiedName, column);
             }
+
+            ret.add(column);
         }
 
         return ret;
     }
 
-    protected AtlasEntity getPathEntity(Path path, AtlasEntityExtInfo extInfo) {
-        AtlasEntity ret;
-        String strPath = path.toString();
-
-        if (strPath.startsWith(HDFS_PATH_PREFIX) && context.isConvertHdfsPathToLowerCase()) {
-            strPath = strPath.toLowerCase();
-        }
-
-        if (isS3Path(strPath)) {
-            String      bucketName          = path.toUri().getAuthority();
-            String      bucketQualifiedName = (path.toUri().getScheme() + SCHEME_SEPARATOR + path.toUri().getAuthority() + QNAME_SEP_CLUSTER_NAME).toLowerCase() + getClusterName();
-            String      pathQualifiedName   = (strPath + QNAME_SEP_CLUSTER_NAME).toLowerCase() + getClusterName();
-            AtlasEntity bucketEntity        = context.getEntity(bucketQualifiedName);
-
-            ret = context.getEntity(pathQualifiedName);
+    protected AtlasEntity getHDFSPathEntity(Path path) {
+        String      strPath           = path.toString().toLowerCase();
+        String      nameServiceID     = HdfsNameServiceResolver.getInstance().getNameServiceIDForPath(strPath);
+        String      attrPath          = StringUtils.isEmpty(nameServiceID) ? strPath : HdfsNameServiceResolver.getInstance().getPathWithNameServiceID(strPath);
+        String      pathQualifiedName = getQualifiedName(attrPath);
+        AtlasEntity ret               = context.getEntity(pathQualifiedName);
 
-            if (ret == null) {
-                if (bucketEntity == null) {
-                    bucketEntity = new AtlasEntity(AWS_S3_BUCKET);
-
-                    bucketEntity.setAttribute(ATTRIBUTE_QUALIFIED_NAME, bucketQualifiedName);
-                    bucketEntity.setAttribute(ATTRIBUTE_NAME, bucketName);
-
-                    context.putEntity(bucketQualifiedName, bucketEntity);
-                }
-
-                extInfo.addReferredEntity(bucketEntity);
-
-                ret = new AtlasEntity(AWS_S3_PSEUDO_DIR);
-
-                ret.setRelationshipAttribute(ATTRIBUTE_BUCKET, getObjectIdWithRelationshipType(bucketEntity, RELATIONSHIP_AWS_S3_BUCKET_S3_PSEUDO_DIRS));
-                ret.setAttribute(ATTRIBUTE_OBJECT_PREFIX, Path.getPathWithoutSchemeAndAuthority(path).toString().toLowerCase());
-                ret.setAttribute(ATTRIBUTE_QUALIFIED_NAME, pathQualifiedName);
-                ret.setAttribute(ATTRIBUTE_NAME, Path.getPathWithoutSchemeAndAuthority(path).toString().toLowerCase());
+        if (ret == null) {
+            ret = new AtlasEntity(HDFS_TYPE_PATH);
 
-                context.putEntity(pathQualifiedName, ret);
+            if (StringUtils.isNotEmpty(nameServiceID)) {
+                ret.setAttribute(ATTRIBUTE_NAMESERVICE_ID, nameServiceID);
             }
-        } else {
-            String nameServiceID     = HdfsNameServiceResolver.getNameServiceIDForPath(strPath);
-            String attrPath          = StringUtils.isEmpty(nameServiceID) ? strPath : HdfsNameServiceResolver.getPathWithNameServiceID(strPath);
-            String pathQualifiedName = getQualifiedName(attrPath);
-
-            ret = context.getEntity(pathQualifiedName);
-
-            if (ret == null) {
-                ret = new AtlasEntity(HDFS_TYPE_PATH);
-
-                if (StringUtils.isNotEmpty(nameServiceID)) {
-                    ret.setAttribute(ATTRIBUTE_NAMESERVICE_ID, nameServiceID);
-                }
 
-                String name = Path.getPathWithoutSchemeAndAuthority(path).toString();
-
-                if (strPath.startsWith(HDFS_PATH_PREFIX) && context.isConvertHdfsPathToLowerCase()) {
-                    name = name.toLowerCase();
-                }
-
-                ret.setAttribute(ATTRIBUTE_PATH, attrPath);
-                ret.setAttribute(ATTRIBUTE_QUALIFIED_NAME, pathQualifiedName);
-                ret.setAttribute(ATTRIBUTE_NAME, name);
-                ret.setAttribute(ATTRIBUTE_CLUSTER_NAME, getClusterName());
+            ret.setAttribute(ATTRIBUTE_PATH, attrPath);
+            ret.setAttribute(ATTRIBUTE_QUALIFIED_NAME, pathQualifiedName);
+            ret.setAttribute(ATTRIBUTE_NAME, Path.getPathWithoutSchemeAndAuthority(path).toString().toLowerCase());
+            ret.setAttribute(ATTRIBUTE_CLUSTER_NAME, getClusterName());
 
-                context.putEntity(pathQualifiedName, ret);
-            }
+            context.putEntity(pathQualifiedName, ret);
         }
 
         return ret;
@@ -668,176 +511,61 @@ public abstract class BaseHiveEvent {
 
     protected AtlasEntity getHiveProcessEntity(List<AtlasEntity> inputs, List<AtlasEntity> outputs) throws Exception {
         AtlasEntity ret         = new AtlasEntity(HIVE_TYPE_PROCESS);
-        String      queryStr    = getQueryString();
+        HookContext hookContext = getHiveContext();
+        String      queryStr    = hookContext.getQueryPlan().getQueryStr();
 
         if (queryStr != null) {
-            queryStr = queryStr.toLowerCase().trim();
+            queryStr = queryStr.toLowerCase();
         }
 
         ret.setAttribute(ATTRIBUTE_QUALIFIED_NAME, getQualifiedName(inputs, outputs));
-        ret.setRelationshipAttribute(ATTRIBUTE_INPUTS, getObjectIdsWithRelationshipType(inputs, RELATIONSHIP_DATASET_PROCESS_INPUTS));
-        ret.setRelationshipAttribute(ATTRIBUTE_OUTPUTS, getObjectIdsWithRelationshipType(outputs, RELATIONSHIP_PROCESS_DATASET_OUTPUTS));
+        ret.setAttribute(ATTRIBUTE_INPUTS, getObjectIds(inputs));
+        ret.setAttribute(ATTRIBUTE_OUTPUTS,  getObjectIds(outputs));
         ret.setAttribute(ATTRIBUTE_NAME, queryStr);
-        ret.setAttribute(ATTRIBUTE_OPERATION_TYPE, getOperationName());
-
-        // We are setting an empty value to these attributes, since now we have a new entity type called hive process
-        // execution which captures these values. We have to set empty values here because these attributes are
-        // mandatory attributes for hive process entity type.
-        ret.setAttribute(ATTRIBUTE_START_TIME, EMPTY_ATTRIBUTE_VALUE);
-        ret.setAttribute(ATTRIBUTE_END_TIME, EMPTY_ATTRIBUTE_VALUE);
-        ret.setAttribute(ATTRIBUTE_USER_NAME, EMPTY_ATTRIBUTE_VALUE);
-        ret.setAttribute(ATTRIBUTE_QUERY_TEXT, EMPTY_ATTRIBUTE_VALUE);
-        ret.setAttribute(ATTRIBUTE_QUERY_ID, EMPTY_ATTRIBUTE_VALUE);
-        ret.setAttribute(ATTRIBUTE_QUERY_PLAN, "Not Supported");
-        ret.setAttribute(ATTRIBUTE_RECENT_QUERIES, Collections.singletonList(queryStr));
-        return ret;
-    }
-
-    protected AtlasEntity getHiveProcessExecutionEntity(AtlasEntity hiveProcess) throws Exception {
-        AtlasEntity ret         = new AtlasEntity(HIVE_TYPE_PROCESS_EXECUTION);
-        String      queryStr    = getQueryString();
-
-        if (queryStr != null) {
-            queryStr = queryStr.toLowerCase().trim();
-        }
-
-        Long endTime = System.currentTimeMillis();
-        ret.setAttribute(ATTRIBUTE_QUALIFIED_NAME, hiveProcess.getAttribute(ATTRIBUTE_QUALIFIED_NAME).toString() +
-                QNAME_SEP_PROCESS + getQueryStartTime().toString() +
-                QNAME_SEP_PROCESS + endTime.toString());
-        ret.setAttribute(ATTRIBUTE_NAME, queryStr + QNAME_SEP_PROCESS + getQueryStartTime().toString());
-        ret.setAttribute(ATTRIBUTE_START_TIME, getQueryStartTime());
-        ret.setAttribute(ATTRIBUTE_END_TIME, endTime);
+        ret.setAttribute(ATTRIBUTE_OPERATION_TYPE, hookContext.getOperationName());
+        ret.setAttribute(ATTRIBUTE_START_TIME, hookContext.getQueryPlan().getQueryStartTime());
+        ret.setAttribute(ATTRIBUTE_END_TIME, System.currentTimeMillis());
         ret.setAttribute(ATTRIBUTE_USER_NAME, getUserName());
         ret.setAttribute(ATTRIBUTE_QUERY_TEXT, queryStr);
-        ret.setAttribute(ATTRIBUTE_QUERY_ID, getQueryId());
+        ret.setAttribute(ATTRIBUTE_QUERY_ID, hookContext.getQueryPlan().getQuery().getQueryId());
         ret.setAttribute(ATTRIBUTE_QUERY_PLAN, "Not Supported");
-        ret.setAttribute(ATTRIBUTE_HOSTNAME, getContext().getHostName()); //
-        AtlasRelatedObjectId hiveProcessRelationObjectId = AtlasTypeUtil.toAtlasRelatedObjectId(hiveProcess, RELATIONSHIP_HIVE_PROCESS_PROCESS_EXE);
-        ret.setRelationshipAttribute(ATTRIBUTE_PROCESS, hiveProcessRelationObjectId);
-        return ret;
-    }
-
-    protected AtlasEntity createHiveDDLEntity(AtlasEntity dbOrTable) {
-        return createHiveDDLEntity(dbOrTable, false);
-    }
-
-    protected AtlasEntity createHiveDDLEntity(AtlasEntity dbOrTable, boolean excludeEntityGuid) {
-        AtlasObjectId objId   = BaseHiveEvent.getObjectId(dbOrTable);
-        AtlasEntity   hiveDDL = null;
-
-        if (excludeEntityGuid) {
-            objId.setGuid(null);
-        }
-        AtlasRelatedObjectId objIdRelatedObject =     new AtlasRelatedObjectId(objId);
-
-        if (StringUtils.equals(objId.getTypeName(), HIVE_TYPE_DB)) {
-            hiveDDL = new AtlasEntity(HIVE_DB_DDL);
-            objIdRelatedObject.setRelationshipType(RELATIONSHIP_HIVE_DB_DDL_QUERIES);
-            hiveDDL.setRelationshipAttribute(ATTRIBUTE_DB, objIdRelatedObject);
-        } else if (StringUtils.equals(objId.getTypeName(), HIVE_TYPE_TABLE)) {
-            hiveDDL = new AtlasEntity(HIVE_TABLE_DDL);
-            objIdRelatedObject.setRelationshipType(RELATIONSHIP_HIVE_TABLE_DDL_QUERIES);
-            hiveDDL.setRelationshipAttribute( ATTRIBUTE_TABLE, objIdRelatedObject);
-        }
-
-        if (hiveDDL != null) {
-            hiveDDL.setAttribute(ATTRIBUTE_SERVICE_TYPE, "hive");
-            hiveDDL.setAttribute(ATTRIBUTE_EXEC_TIME, getQueryStartTime());
-            hiveDDL.setAttribute(ATTRIBUTE_QUERY_TEXT, getQueryString());
-            hiveDDL.setAttribute(ATTRIBUTE_USER_NAME, getUserName());
-            hiveDDL.setAttribute(ATTRIBUTE_NAME, getQueryString());
-            hiveDDL.setAttribute(ATTRIBUTE_QUALIFIED_NAME, dbOrTable.getAttribute(ATTRIBUTE_QUALIFIED_NAME).toString()
-                                                           + QNAME_SEP_PROCESS + getQueryStartTime().toString());
-        }
+        ret.setAttribute(ATTRIBUTE_RECENT_QUERIES, Collections.singletonList(queryStr));
 
-        return hiveDDL;
+        return ret;
     }
 
     protected String getClusterName() {
         return context.getClusterName();
     }
 
-    protected Database getDatabases(String dbName) throws Exception {
-        return context.isMetastoreHook() ? context.getMetastoreHandler().get_database(dbName) :
-                                           context.getHive().getDatabase(dbName);
-    }
-
     protected Hive getHive() {
         return context.getHive();
     }
 
-    protected Set<ReadEntity> getInputs() {
-        return context != null ? context.getInputs() : Collections.emptySet();
-    }
-
-    protected Set<WriteEntity> getOutputs() {
-        return context != null ? context.getOutputs() : Collections.emptySet();
-    }
-
-    protected LineageInfo getLineageInfo() {
-        return context != null ? context.getLineageInfo() : null;
-    }
-
-    protected String getQueryString() {
-        return isHiveContextValid() ? context.getHiveContext().getQueryPlan().getQueryStr() : null;
-    }
-
-    protected String getOperationName() {
-        return isHiveContextValid() ? context.getHiveContext().getOperationName() : null;
-    }
-
-    protected String getHiveUserName() {
-        return isHiveContextValid() ? context.getHiveContext().getUserName() : null;
-    }
-
-    protected UserGroupInformation getUgi() {
-        return isHiveContextValid() ? context.getHiveContext().getUgi() : null;
-    }
-
-    protected Long getQueryStartTime() {
-        return isHiveContextValid() ? context.getHiveContext().getQueryPlan().getQueryStartTime() : System.currentTimeMillis();
-    }
-
-    protected String getQueryId() {
-        return isHiveContextValid() ? context.getHiveContext().getQueryPlan().getQueryId() : null;
-    }
-
-    private boolean isHiveContextValid() {
-        return context != null && context.getHiveContext() != null;
+    protected HookContext getHiveContext() {
+        return context.getHiveContext();
     }
 
     protected String getUserName() {
-        String               ret = null;
-        UserGroupInformation ugi = null;
+        String ret = getHiveContext().getUserName();
 
-        if (context.isMetastoreHook()) {
-            try {
-                ugi = SecurityUtils.getUGI();
-            } catch (Exception e) {
-                //do nothing
+        if (StringUtils.isEmpty(ret)) {
+            UserGroupInformation ugi = getHiveContext().getUgi();
+
+            if (ugi != null) {
+                ret = ugi.getShortUserName();
             }
-        } else {
-            ret = getHiveUserName();
 
             if (StringUtils.isEmpty(ret)) {
-                ugi = getUgi();
+                try {
+                    ret = UserGroupInformation.getCurrentUser().getShortUserName();
+                } catch (IOException e) {
+                    LOG.warn("Failed for UserGroupInformation.getCurrentUser() ", e);
+                    ret = System.getProperty("user.name");
+                }
             }
         }
 
-        if (ugi != null) {
-            ret = ugi.getShortUserName();
-        }
-
-        if (StringUtils.isEmpty(ret)) {
-            try {
-                ret = UserGroupInformation.getCurrentUser().getShortUserName();
-            } catch (IOException e) {
-                LOG.warn("Failed for UserGroupInformation.getCurrentUser() ", e);
-
-                ret = System.getProperty("user.name");
-            }
-        }
 
         return ret;
     }
@@ -859,11 +587,21 @@ public abstract class BaseHiveEvent {
     }
 
     protected String getQualifiedName(Database db) {
-        return context.getQualifiedName(db);
+        return (db.getName() + QNAME_SEP_CLUSTER_NAME).toLowerCase() + getClusterName();
     }
 
     protected String getQualifiedName(Table table) {
-        return context.getQualifiedName(table);
+        String tableName = table.getTableName();
+
+        if (table.isTemporary()) {
+            if (SessionState.get() != null && SessionState.get().getSessionId() != null) {
+                tableName = tableName + TEMP_TABLE_PREFIX + SessionState.get().getSessionId();
+            } else {
+                tableName = tableName + TEMP_TABLE_PREFIX + RandomStringUtils.random(10);
+            }
+        }
+
+        return (table.getDbName() + QNAME_SEP_ENTITY_NAME + tableName + QNAME_SEP_CLUSTER_NAME).toLowerCase() + getClusterName();
     }
 
     protected String getQualifiedName(Table table, StorageDescriptor sd) {
@@ -893,13 +631,9 @@ public abstract class BaseHiveEvent {
     protected String getQualifiedName(BaseColumnInfo column) {
         String dbName    = column.getTabAlias().getTable().getDbName();
         String tableName = column.getTabAlias().getTable().getTableName();
-        String colName   = column.getColumn() != null ? column.getColumn().getName() : null;
+        String colName   = column.getColumn().getName();
 
-        if (colName == null) {
-            return (dbName + QNAME_SEP_ENTITY_NAME + tableName + QNAME_SEP_CLUSTER_NAME).toLowerCase() + getClusterName();
-        } else {
-            return (dbName + QNAME_SEP_ENTITY_NAME + tableName + QNAME_SEP_ENTITY_NAME + colName + QNAME_SEP_CLUSTER_NAME).toLowerCase() + getClusterName();
-        }
+        return getQualifiedName(dbName, tableName, colName);
     }
 
     protected String getQualifiedName(String dbName, String tableName, String colName) {
@@ -907,37 +641,21 @@ public abstract class BaseHiveEvent {
     }
 
     protected String getQualifiedName(URI location) {
-        String strPath = new Path(location).toString();
-
-        if (strPath.startsWith(HDFS_PATH_PREFIX) && context.isConvertHdfsPathToLowerCase()) {
-            strPath = strPath.toLowerCase();
-        }
-
-        String nameServiceID = HdfsNameServiceResolver.getNameServiceIDForPath(strPath);
-        String attrPath      = StringUtils.isEmpty(nameServiceID) ? strPath : HdfsNameServiceResolver.getPathWithNameServiceID(strPath);
+        String strPath       = new Path(location).toString().toLowerCase();
+        String nameServiceID = HdfsNameServiceResolver.getInstance().getNameServiceIDForPath(strPath);
+        String attrPath      = StringUtils.isEmpty(nameServiceID) ? strPath : HdfsNameServiceResolver.getInstance().getPathWithNameServiceID(strPath);
 
         return getQualifiedName(attrPath);
     }
 
     protected String getQualifiedName(String path) {
         if (path.startsWith(HdfsNameServiceResolver.HDFS_SCHEME)) {
-            return path + QNAME_SEP_CLUSTER_NAME + getClusterName();
+            return (path + QNAME_SEP_CLUSTER_NAME).toLowerCase() + getClusterName();
         }
 
         return path.toLowerCase();
     }
 
-    protected String getColumnQualifiedName(String tblQualifiedName, String columnName) {
-        int sepPos = tblQualifiedName.lastIndexOf(QNAME_SEP_CLUSTER_NAME);
-
-        if (sepPos == -1) {
-            return tblQualifiedName + QNAME_SEP_ENTITY_NAME + columnName.toLowerCase();
-        } else {
-            return tblQualifiedName.substring(0, sepPos) + QNAME_SEP_ENTITY_NAME + columnName.toLowerCase() + tblQualifiedName.substring(sepPos);
-        }
-
-    }
-
     protected String getQualifiedName(List<AtlasEntity> inputs, List<AtlasEntity> outputs) throws Exception {
         HiveOperation operation = context.getHiveOperation();
 
@@ -946,7 +664,7 @@ public abstract class BaseHiveEvent {
             operation == HiveOperation.CREATEVIEW ||
             operation == HiveOperation.ALTERVIEW_AS ||
             operation == HiveOperation.ALTERTABLE_LOCATION) {
-            List<? extends Entity> sortedEntities = new ArrayList<>(getOutputs());
+            List<? extends Entity> sortedEntities = new ArrayList<>(getHiveContext().getOutputs());
 
             Collections.sort(sortedEntities, entityComparator);
 
@@ -963,82 +681,24 @@ public abstract class BaseHiveEvent {
             }
         }
 
-        String qualifiedName = null;
-        String operationName = getOperationName();
-
-        if (operationName != null) {
-            StringBuilder sb = new StringBuilder(operationName);
-
-            boolean ignoreHDFSPaths = ignoreHDFSPathsinProcessQualifiedName();
-
-            addToProcessQualifiedName(sb, getInputs(), ignoreHDFSPaths);
-            sb.append("->");
-            addToProcessQualifiedName(sb, getOutputs(), ignoreHDFSPaths);
-
-            qualifiedName = sb.toString();
-        }
-
-
-        return qualifiedName;
-    }
-
-    protected AtlasEntity toReferencedHBaseTable(Table table, AtlasEntitiesWithExtInfo entities) {
-        AtlasEntity    ret            = null;
-        HBaseTableInfo hBaseTableInfo = new HBaseTableInfo(table);
-        String         hbaseNameSpace = hBaseTableInfo.getHbaseNameSpace();
-        String         hbaseTableName = hBaseTableInfo.getHbaseTableName();
-
-        if (hbaseTableName != null) {
-            AtlasEntity nsEntity = new AtlasEntity(HBASE_TYPE_NAMESPACE);
-            nsEntity.setAttribute(ATTRIBUTE_NAME, hbaseNameSpace);
-            nsEntity.setAttribute(ATTRIBUTE_CLUSTER_NAME, getClusterName());
-            nsEntity.setAttribute(ATTRIBUTE_QUALIFIED_NAME, getHBaseNameSpaceQualifiedName(getClusterName(), hbaseNameSpace));
-
-            ret = new AtlasEntity(HBASE_TYPE_TABLE);
-
-            ret.setAttribute(ATTRIBUTE_NAME, hbaseTableName);
-            ret.setAttribute(ATTRIBUTE_URI, hbaseTableName);
-
-            AtlasRelatedObjectId objIdRelatedObject =     new AtlasRelatedObjectId(getObjectId(nsEntity), RELATIONSHIP_HBASE_TABLE_NAMESPACE);
-
-            ret.setRelationshipAttribute(ATTRIBUTE_NAMESPACE, objIdRelatedObject);
-            ret.setAttribute(ATTRIBUTE_QUALIFIED_NAME, getHBaseTableQualifiedName(getClusterName(), hbaseNameSpace, hbaseTableName));
-
-            entities.addReferredEntity(nsEntity);
-            entities.addEntity(ret);
-        }
-
-        return ret;
-    }
-
-    protected boolean isHBaseStore(Table table) {
-        boolean             ret        = false;
-        Map<String, String> parameters = table.getParameters();
+        StringBuilder sb = new StringBuilder(getHiveContext().getOperationName());
 
-        if (MapUtils.isNotEmpty(parameters)) {
-            String storageHandler = parameters.get(ATTRIBUTE_STORAGE_HANDLER);
+        boolean ignoreHDFSPaths = ignoreHDFSPathsinProcessQualifiedName();
 
-            ret = (storageHandler != null && storageHandler.equals(HBASE_STORAGE_HANDLER_CLASS));
-        }
-
-        return ret;
-    }
-
-    private static String getHBaseTableQualifiedName(String clusterName, String nameSpace, String tableName) {
-        return String.format("%s:%s@%s", nameSpace.toLowerCase(), tableName.toLowerCase(), clusterName);
-    }
+        addToProcessQualifiedName(sb, getHiveContext().getInputs(), ignoreHDFSPaths);
+        sb.append("->");
+        addToProcessQualifiedName(sb, getHiveContext().getOutputs(), ignoreHDFSPaths);
 
-    private static String getHBaseNameSpaceQualifiedName(String clusterName, String nameSpace) {
-        return String.format("%s@%s", nameSpace.toLowerCase(), clusterName);
+        return sb.toString();
     }
 
     private boolean ignoreHDFSPathsinProcessQualifiedName() {
         switch (context.getHiveOperation()) {
             case LOAD:
             case IMPORT:
-                return hasPartitionEntity(getOutputs());
+                return hasPartitionEntity(getHiveContext().getOutputs());
             case EXPORT:
-                return hasPartitionEntity(getInputs());
+                return hasPartitionEntity(getHiveContext().getInputs());
             case QUERY:
                 return true;
         }
@@ -1145,17 +805,12 @@ public abstract class BaseHiveEvent {
             case ALTERTABLE_RENAMECOL:
             case ALTERVIEW_PROPERTIES:
             case ALTERVIEW_RENAME:
-            case ALTERVIEW_AS:
                 return true;
         }
 
         return false;
     }
 
-    private boolean isS3Path(String strPath) {
-        return strPath != null && (strPath.startsWith(S3_SCHEME) || strPath.startsWith(S3A_SCHEME));
-    }
-
 
     static final class EntityComparator implements Comparator<Entity> {
         @Override
@@ -1173,41 +828,4 @@ public abstract class BaseHiveEvent {
     }
 
     static final Comparator<Entity> entityComparator = new EntityComparator();
-
-    static final class HBaseTableInfo {
-        String hbaseNameSpace = null;
-        String hbaseTableName = null;
-
-         HBaseTableInfo(Table table) {
-            Map<String, String> parameters = table.getParameters();
-
-            if (MapUtils.isNotEmpty(parameters)) {
-                hbaseNameSpace = HBASE_DEFAULT_NAMESPACE;
-                hbaseTableName = parameters.get(HBASE_PARAM_TABLE_NAME);
-
-                if (hbaseTableName != null) {
-                    if (hbaseTableName.contains(HBASE_NAMESPACE_TABLE_DELIMITER)) {
-                        String[] hbaseTableInfo = hbaseTableName.split(HBASE_NAMESPACE_TABLE_DELIMITER);
-
-                        if (hbaseTableInfo.length > 1) {
-                            hbaseNameSpace = hbaseTableInfo[0];
-                            hbaseTableName = hbaseTableInfo[1];
-                        }
-                    }
-                }
-            }
-        }
-
-        public String getHbaseNameSpace() {
-            return hbaseNameSpace;
-        }
-
-        public String getHbaseTableName() {
-            return hbaseTableName;
-        }
-    }
-
-    public static Table toTable(org.apache.hadoop.hive.metastore.api.Table table) {
-        return new Table(table);
-    }
 }