diff --git a/modules/gfac/gfac-monitor/src/main/java/org/apache/airavata/gfac/monitor/impl/pull/qstat/HPCPullMonitor.java b/modules/gfac/gfac-monitor/src/main/java/org/apache/airavata/gfac/monitor/impl/pull/qstat/HPCPullMonitor.java
index e165bfd5b..34a6065a6 100644
--- a/modules/gfac/gfac-monitor/src/main/java/org/apache/airavata/gfac/monitor/impl/pull/qstat/HPCPullMonitor.java
+++ b/modules/gfac/gfac-monitor/src/main/java/org/apache/airavata/gfac/monitor/impl/pull/qstat/HPCPullMonitor.java
@@ -21,13 +21,16 @@
 package org.apache.airavata.gfac.monitor.impl.pull.qstat;
 
 import com.google.common.eventbus.EventBus;
-import org.apache.airavata.common.logger.AiravataLogger;
-import org.apache.airavata.common.logger.AiravataLoggerFactory;
 import org.apache.airavata.common.utils.MonitorPublisher;
 import org.apache.airavata.common.utils.ServerSettings;
 import org.apache.airavata.commons.gfac.type.HostDescription;
+import org.apache.airavata.gfac.GFacException;
+import org.apache.airavata.gfac.core.cpi.BetterGfacImpl;
 import org.apache.airavata.gfac.core.cpi.GFac;
 import org.apache.airavata.gfac.core.monitor.MonitorID;
+import org.apache.airavata.gfac.core.monitor.TaskIdentity;
+import org.apache.airavata.gfac.core.monitor.state.JobStatusChangeRequest;
+import org.apache.airavata.gfac.core.monitor.state.TaskStatusChangeRequest;
 import org.apache.airavata.gfac.core.utils.GFacThreadPoolExecutor;
 import org.apache.airavata.gfac.core.utils.OutHandlerWorker;
 import org.apache.airavata.gfac.monitor.HostMonitorData;
@@ -38,12 +41,13 @@ import org.apache.airavata.gfac.monitor.impl.push.amqp.SimpleJobFinishConsumer;
 import org.apache.airavata.gfac.monitor.util.CommonUtils;
 import org.apache.airavata.gsi.ssh.api.SSHApiException;
 import org.apache.airavata.gsi.ssh.api.authentication.AuthenticationInfo;
-import org.apache.airavata.model.messaging.event.JobIdentifier;
-import org.apache.airavata.model.messaging.event.JobStatusChangeRequestEvent;
 import org.apache.airavata.model.workspace.experiment.JobState;
+import org.apache.airavata.model.workspace.experiment.TaskState;
 import org.apache.airavata.schemas.gfac.GsisshHostType;
 import org.apache.airavata.schemas.gfac.SSHHostType;
 import org.apache.zookeeper.ZooKeeper;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
 
 import java.sql.Timestamp;
 import java.util.*;
@@ -56,9 +60,8 @@ import java.util.concurrent.LinkedBlockingQueue;
  * in grid resources and retrieve the job status.
  */
 public class HPCPullMonitor extends PullMonitor {
-
-    private final static AiravataLogger logger = AiravataLoggerFactory.getLogger(HPCPullMonitor.class);
-    public static final int FAILED_COUNT = 1;
+    private final static Logger logger = LoggerFactory.getLogger(HPCPullMonitor.class);
+    public static final int FAILED_COUNT = 3;
 
     // I think this should use DelayedBlocking Queue to do the monitoring*/
     private BlockingQueue<UserMonitorData> queue;
@@ -113,12 +116,12 @@ public class HPCPullMonitor extends PullMonitor {
         this.startPulling = true;
         while (this.startPulling && !ServerSettings.isStopAllThreads()) {
             try {
-                // After finishing one iteration of the full queue this thread sleeps 1 second
-                synchronized (this.queue) {
-                    if (this.queue.size() > 0) {
+                if (this.queue.size() > 0) {
+                    synchronized (this.queue) {
                         startPulling();
+                    }
                 }
-            }
+                // After finishing one iteration of the full queue this thread sleeps 1 second
                 Thread.sleep(10000);
             } catch (Exception e) {
                 // we catch all the exceptions here because no matter what happens we do not stop running this
@@ -152,12 +155,12 @@ public class HPCPullMonitor extends PullMonitor {
         //todo this polling will not work with multiple usernames but with single user
         // and multiple hosts, currently monitoring will work
         UserMonitorData take = null;
-        JobStatusChangeRequestEvent jobStatus = new JobStatusChangeRequestEvent();
+        JobStatusChangeRequest jobStatus = new JobStatusChangeRequest();
         MonitorID currentMonitorID = null;
         HostDescription currentHostDescription = null;
         try {
             take = this.queue.take();
-            Map<String,MonitorID> completedJobs = new HashMap<String,MonitorID>();
+            List<MonitorID> completedJobs = new ArrayList<MonitorID>();
             List<HostMonitorData> hostMonitorData = take.getHostMonitorData();
             for (HostMonitorData iHostMonitorData : hostMonitorData) {
                 if (iHostMonitorData.getHost().getType() instanceof GsisshHostType
@@ -186,33 +189,33 @@ public class HPCPullMonitor extends PullMonitor {
                         while(iterator1.hasNext()) {
                             String cancelMId = iterator1.next();
                             if (cancelMId.equals(iMonitorID.getExperimentID() + "+" + iMonitorID.getTaskID())) {
+                                logger.info("Found a match in monitoring Queue, so marking this job to remove from monitor queue " + cancelMId);
+                                logger.info("ExperimentID: " + cancelMId.split("\\+")[0] + ",TaskID: " + cancelMId.split("\\+")[1] + "JobID" + iMonitorID.getJobID());
+                                completedJobs.add(iMonitorID);
                                 iMonitorID.setStatus(JobState.CANCELED);
-                                completedJobs.put(iMonitorID.getJobName(), iMonitorID);
                                 iterator1.remove();
-                                logger.debugId(cancelMId, "Found a match in cancel monitor queue, hence moved to the " +
-                                                "completed job queue, experiment {}, task {} , job {}",
-                                        iMonitorID.getExperimentID(), iMonitorID.getTaskID(), iMonitorID.getJobID());
                                 break;
                             }
                         }
                         iterator1 = cancelJobList.iterator();
                     }
                     synchronized (completedJobsFromPush) {
-                        ListIterator<String> iterator = completedJobsFromPush.listIterator();
+                        Iterator<String> iterator = completedJobsFromPush.iterator();
                         for (MonitorID iMonitorID : monitorID) {
                             String completeId = null;
                             while (iterator.hasNext()) {
                                  completeId = iterator.next();
                                 if (completeId.equals(iMonitorID.getUserName() + "," + iMonitorID.getJobName())) {
                                     logger.info("This job is finished because push notification came with <username,jobName> " + completeId);
-                                    completedJobs.put(iMonitorID.getJobName(), iMonitorID);
+                                    completedJobs.add(iMonitorID);
                                     iMonitorID.setStatus(JobState.COMPLETE);
-                                    iterator.remove();//we have to make this empty everytime we iterate, otherwise this list will accumulate and will lead to a memory leak
-                                    logger.debugId(completeId, "Push notification updated job {} status to {}. " +
-                                                    "experiment {} , task {}.", iMonitorID.getJobID(), JobState.COMPLETE.toString(),
-                                            iMonitorID.getExperimentID(), iMonitorID.getTaskID());
                                     break;
                                 }
+                                //we have to make this empty everytime we iterate, otherwise this list will accumulate and will
+                                // lead to a memory leak
+                            }
+                            if(completeId!=null) {
+                                completedJobsFromPush.remove(completeId);
                             }
                             iterator = completedJobsFromPush.listIterator();
                         }
@@ -226,36 +229,27 @@ public class HPCPullMonitor extends PullMonitor {
                                 !JobState.COMPLETE.equals(iMonitorID.getStatus())) {
                             iMonitorID.setStatus(jobStatuses.get(iMonitorID.getJobID() + "," + iMonitorID.getJobName()));    //IMPORTANT this is NOT a simple setter we have a logic
                         }else if(JobState.COMPLETE.equals(iMonitorID.getStatus())){
-                            completedJobs.put(iMonitorID.getJobName(), iMonitorID);
-                            logger.debugId(iMonitorID.getJobID(), "Moved job {} to completed jobs map, experiment {}, " +
-                                    "task {}", iMonitorID.getJobID(), iMonitorID.getExperimentID(), iMonitorID.getTaskID());
+                            completedJobs.add(iMonitorID);
                         }
-                        jobStatus = new JobStatusChangeRequestEvent();
-                        iMonitorID.setStatus(jobStatuses.get(iMonitorID.getJobID()+","+iMonitorID.getJobName()));    //IMPORTANT this is not a simple setter we have a logic
+                        jobStatus = new JobStatusChangeRequest(iMonitorID);
+                        // we have this JobStatus class to handle amqp monitoring
+
+                        publisher.publish(jobStatus);
+                        // if the job is completed we do not have to put the job to the queue again
+                        iMonitorID.setLastMonitored(new Timestamp((new Date()).getTime()));
 
                         if (iMonitorID.getFailedCount() > FAILED_COUNT) {
+                            logger.error("Tried to monitor the job with ID " + iMonitorID.getJobID() + " But failed" + iMonitorID.getFailedCount() +
+                                    " 3 times, so skip this Job from Monitor");
                             iMonitorID.setLastMonitored(new Timestamp((new Date()).getTime()));
-                            String outputDir = iMonitorID.getJobExecutionContext().getApplicationContext()
-                                    .getApplicationDeploymentDescription().getType().getOutputDataDirectory();
-                            List<String> stdOut = null;
+                            completedJobs.add(iMonitorID);
                             try {
-                                stdOut = connection.getCluster().listDirectory(outputDir); // check the outputs directory
-                            } catch (SSHApiException e) {
-                                if (e.getMessage().contains("No such file or directory")) {
-                                    // this is because while we run output handler something failed and during exception
-                                    // we store all the jobs in the monitor queue again
-                                    logger.error("We know this  job is already attempted to run out-handlers");
-                                    CommonUtils.removeMonitorFromQueue(queue, iMonitorID);
-                                }
-                            }
-                            if (stdOut != null && stdOut.size() > 0 && !stdOut.get(0).isEmpty()) { // have to be careful with this
-                                iMonitorID.setStatus(JobState.COMPLETE);
-                                completedJobs.put(iMonitorID.getJobName(), iMonitorID);
-                                logger.errorId(iMonitorID.getJobID(), "Job monitoring failed {} times, removed job {} from " +
-                                                "monitor queue. Experiment {} , task {}", iMonitorID.getFailedCount(),
-                                        iMonitorID.getExperimentID(), iMonitorID.getTaskID());
-                            } else {
-                                iMonitorID.setFailedCount(0);
+                                logger.error("Launching outflow handlers to check output are genereated or not");
+                                gfac.invokeOutFlowHandlers(iMonitorID.getJobExecutionContext());
+                            } catch (GFacException e) {
+                                publisher.publish(new TaskStatusChangeRequest(new TaskIdentity(iMonitorID.getExperimentID(), iMonitorID.getWorkflowNodeID(),
+                                        iMonitorID.getTaskID()), TaskState.FAILED));
+                                logger.info(e.getLocalizedMessage(), e);
                             }
                         } else {
                             // Evey
@@ -263,25 +257,9 @@ public class HPCPullMonitor extends PullMonitor {
                             // if the job is complete we remove it from the Map, if any of these maps
                             // get empty this userMonitorData will get delete from the queue
                         }
-                        JobIdentifier jobIdentity = new JobIdentifier(iMonitorID.getJobID(),
-                                iMonitorID.getTaskID(),
-                                iMonitorID.getWorkflowNodeID(),
-                                iMonitorID.getExperimentID(),
-                                iMonitorID.getJobExecutionContext().getGatewayID());
-                        jobStatus.setJobIdentity(jobIdentity);
-                        jobStatus.setState(iMonitorID.getStatus());
-                        // we have this JobStatus class to handle amqp monitoring
-
-                        publisher.publish(jobStatus);
-                        logger.debugId(jobStatus.getJobIdentity().getJobId(), "Published job status change request, " +
-                                        "experiment {} , task {}", jobStatus.getJobIdentity().getExperimentId(),
-                                jobStatus.getJobIdentity().getTaskId());
-                        // if the job is completed we do not have to put the job to the queue again
-                        iMonitorID.setLastMonitored(new Timestamp((new Date()).getTime()));
                     }
                 } else {
-                    logger.debug("Qstat Monitor doesn't handle non-gsissh hosts , host {}", iHostMonitorData.getHost()
-                            .getType().getHostAddress());
+                    logger.debug("Qstat Monitor doesn't handle non-gsissh hosts");
                 }
             }
             // We have finished all the HostMonitorData object in userMonitorData, now we need to put it back
@@ -291,12 +269,9 @@ public class HPCPullMonitor extends PullMonitor {
             // they become empty
             Map<String, Integer> jobRemoveCountMap = new HashMap<String, Integer>();
             ZooKeeper zk = null;
-            Set<String> keys = completedJobs.keySet();
-            for (String jobName: keys) {
-                MonitorID completedJob = completedJobs.get(jobName);
+            for (MonitorID completedJob : completedJobs) {
+                GFacThreadPoolExecutor.getCachedThreadPool().submit(new OutHandlerWorker(gfac, completedJob, publisher));
                 CommonUtils.removeMonitorFromQueue(queue, completedJob);
-                    gfac.invokeOutFlowHandlers(completedJob.getJobExecutionContext());
-//                  GFacThreadPoolExecutor.getFixedThreadPool().submit(new OutHandlerWorker(gfac, completedJob, publisher));
                 if (zk == null) {
                     zk = completedJob.getJobExecutionContext().getZk();
                 }
@@ -326,34 +301,50 @@ public class HPCPullMonitor extends PullMonitor {
             if (e.getMessage().contains("Unknown Job Id Error")) {
                 // in this case job is finished or may be the given job ID is wrong
                 jobStatus.setState(JobState.UNKNOWN);
-                JobIdentifier jobIdentifier = new JobIdentifier("UNKNOWN", "UNKNOWN", "UNKNOWN", "UNKNOWN", "UNKNOWN");
-                if (currentMonitorID != null){
-                    jobIdentifier.setExperimentId(currentMonitorID.getExperimentID());
-                    jobIdentifier.setTaskId(currentMonitorID.getTaskID());
-                    jobIdentifier.setWorkflowNodeId(currentMonitorID.getWorkflowNodeID());
-                    jobIdentifier.setJobId(currentMonitorID.getJobID());
-                    jobIdentifier.setGatewayId(currentMonitorID.getJobExecutionContext().getGatewayID());
-                }
-                jobStatus.setJobIdentity(jobIdentifier);
                 publisher.publish(jobStatus);
             } else if (e.getMessage().contains("illegally formed job identifier")) {
                 logger.error("Wrong job ID is given so dropping the job from monitoring system");
-            } else if (!this.queue.contains(take)) {
-                try {
-                    queue.put(take);
-                } catch (InterruptedException e1) {
-                    e1.printStackTrace();
+            } else if (!this.queue.contains(take)) {   // we put the job back to the queue only if its state is not unknown
+                if (currentMonitorID == null) {
+                    logger.error("Monitoring the jobs failed, for user: " + take.getUserName()
+                            + " in Host: " + currentHostDescription.getType().getHostAddress());
+                } else {
+                    if (currentMonitorID != null) {
+                        if (currentMonitorID.getFailedCount() < 2) {
+                            try {
+                                currentMonitorID.setFailedCount(currentMonitorID.getFailedCount() + 1);
+                                this.queue.put(take);
+                            } catch (InterruptedException e1) {
+                                e1.printStackTrace();
+                            }
+                        } else {
+                            logger.error(e.getMessage());
+                            logger.error("Tried to monitor the job 3 times, so dropping of the the Job with ID: " + currentMonitorID.getJobID());
+                        }
+                    }
                 }
             }
             throw new AiravataMonitorException("Error retrieving the job status", e);
         } catch (Exception e) {
-            try {
-                queue.put(take);
-            } catch (InterruptedException e1) {
-                e1.printStackTrace();
+            if (currentMonitorID != null) {
+                if (currentMonitorID.getFailedCount() < 3) {
+                    try {
+                        currentMonitorID.setFailedCount(currentMonitorID.getFailedCount() + 1);
+                        this.queue.put(take);
+                        // if we get a wrong status we wait for a while and request again
+                        Thread.sleep(10000);
+                    } catch (InterruptedException e1) {
+                        e1.printStackTrace();
+                    }
+                } else {
+                    logger.error(e.getMessage());
+                    logger.error("Tryied to monitor the job 3 times, so dropping of the the Job with ID: " + currentMonitorID.getJobID());
+                }
             }
             throw new AiravataMonitorException("Error retrieving the job status", e);
         }
+
+
         return true;
     }
 