diff --git a/modules/gfac/gfac-monitor/src/main/java/org/apache/airavata/gfac/monitor/impl/pull/qstat/HPCPullMonitor.java b/modules/gfac/gfac-monitor/src/main/java/org/apache/airavata/gfac/monitor/impl/pull/qstat/HPCPullMonitor.java
index 952b30ef2..15c638090 100644
--- a/modules/gfac/gfac-monitor/src/main/java/org/apache/airavata/gfac/monitor/impl/pull/qstat/HPCPullMonitor.java
+++ b/modules/gfac/gfac-monitor/src/main/java/org/apache/airavata/gfac/monitor/impl/pull/qstat/HPCPullMonitor.java
@@ -28,8 +28,6 @@ import org.apache.airavata.common.utils.ServerSettings;
 import org.apache.airavata.commons.gfac.type.HostDescription;
 import org.apache.airavata.gfac.core.cpi.GFac;
 import org.apache.airavata.gfac.core.monitor.MonitorID;
-import org.apache.airavata.gfac.core.utils.GFacThreadPoolExecutor;
-import org.apache.airavata.gfac.core.utils.OutHandlerWorker;
 import org.apache.airavata.gfac.monitor.HostMonitorData;
 import org.apache.airavata.gfac.monitor.UserMonitorData;
 import org.apache.airavata.gfac.monitor.core.PullMonitor;
@@ -113,12 +111,12 @@ public class HPCPullMonitor extends PullMonitor {
         this.startPulling = true;
         while (this.startPulling && !ServerSettings.isStopAllThreads()) {
             try {
-                // After finishing one iteration of the full queue this thread sleeps 1 second
-                synchronized (this.queue) {
-                    if (this.queue.size() > 0) {
+                if (this.queue.size() > 0) {
+                    synchronized (this.queue) {
                         startPulling();
+                    }
                 }
-            }
+                // After finishing one iteration of the full queue this thread sleeps 1 second
                 Thread.sleep(10000);
             } catch (Exception e) {
                 // we catch all the exceptions here because no matter what happens we do not stop running this
@@ -157,10 +155,12 @@ public class HPCPullMonitor extends PullMonitor {
         HostDescription currentHostDescription = null;
         try {
             take = this.queue.take();
+            Map<String,MonitorID> completedJobs = new HashMap<String,MonitorID>();
             List<HostMonitorData> hostMonitorData = take.getHostMonitorData();
             for (HostMonitorData iHostMonitorData : hostMonitorData) {
                 if (iHostMonitorData.getHost().getType() instanceof GsisshHostType
                         || iHostMonitorData.getHost().getType() instanceof SSHHostType) {
+                    currentHostDescription = iHostMonitorData.getHost();
                     String hostName =  iHostMonitorData.getHost().getType().getHostAddress();
                     ResourceConnection connection = null;
                     if (connections.containsKey(hostName)) {
@@ -179,22 +179,17 @@ public class HPCPullMonitor extends PullMonitor {
                     // before we get the statuses, we check the cancel job list and remove them permanently
                     List<MonitorID> monitorID = iHostMonitorData.getMonitorIDs();
                     Iterator<String> iterator1 = cancelJobList.iterator();
-                    ListIterator<MonitorID> monitorIDListIterator = monitorID.listIterator();
-                    while (monitorIDListIterator.hasNext()){
-                        MonitorID iMonitorID = monitorIDListIterator.next();
+
+                    for(MonitorID iMonitorID:monitorID){
                         while(iterator1.hasNext()) {
                             String cancelMId = iterator1.next();
                             if (cancelMId.equals(iMonitorID.getExperimentID() + "+" + iMonitorID.getTaskID())) {
                                 iMonitorID.setStatus(JobState.CANCELED);
+                                completedJobs.put(iMonitorID.getJobName(), iMonitorID);
                                 iterator1.remove();
                                 logger.debugId(cancelMId, "Found a match in cancel monitor queue, hence moved to the " +
                                                 "completed job queue, experiment {}, task {} , job {}",
                                         iMonitorID.getExperimentID(), iMonitorID.getTaskID(), iMonitorID.getJobID());
-                                logger.info("Job cancelled: marking the Job as ************CANCELLED************ experiment {}, task {}, job name {} .",
-                                        iMonitorID.getExperimentID(),iMonitorID.getTaskID(),iMonitorID.getJobName());
-                                sendNotification(iMonitorID);
-                                monitorIDListIterator.remove();
-                                GFacThreadPoolExecutor.getFixedThreadPool().submit(new OutHandlerWorker(gfac, iMonitorID, publisher));
                                 break;
                             }
                         }
@@ -202,36 +197,26 @@ public class HPCPullMonitor extends PullMonitor {
                     }
                     synchronized (completedJobsFromPush) {
                         ListIterator<String> iterator = completedJobsFromPush.listIterator();
-                        monitorIDListIterator = monitorID.listIterator();
-                        while (monitorIDListIterator.hasNext()) {
-                            MonitorID iMonitorID = monitorIDListIterator.next();
+                        for (MonitorID iMonitorID : monitorID) {
                             String completeId = null;
                             while (iterator.hasNext()) {
                                  completeId = iterator.next();
                                 if (completeId.equals(iMonitorID.getUserName() + "," + iMonitorID.getJobName())) {
                                     logger.info("This job is finished because push notification came with <username,jobName> " + completeId);
+                                    completedJobs.put(iMonitorID.getJobName(), iMonitorID);
                                     iMonitorID.setStatus(JobState.COMPLETE);
                                     iterator.remove();//we have to make this empty everytime we iterate, otherwise this list will accumulate and will lead to a memory leak
                                     logger.debugId(completeId, "Push notification updated job {} status to {}. " +
                                                     "experiment {} , task {}.", iMonitorID.getJobID(), JobState.COMPLETE.toString(),
                                             iMonitorID.getExperimentID(), iMonitorID.getTaskID());
-                                    logger.info("AMQP message recieved: marking the Job as ************COMPLETE************ experiment {}, task {}, job name {} .",
-                                            iMonitorID.getExperimentID(),iMonitorID.getTaskID(),iMonitorID.getJobName());
-
-                                    monitorIDListIterator.remove();
-                                    sendNotification(iMonitorID);
-                                    GFacThreadPoolExecutor.getFixedThreadPool().submit(new OutHandlerWorker(gfac, iMonitorID, publisher));
                                     break;
                                 }
                             }
                             iterator = completedJobsFromPush.listIterator();
                         }
                     }
-
-                    // we have to get this again because we removed the already completed jobs with amqp messages
-                    monitorID = iHostMonitorData.getMonitorIDs();
                     Map<String, JobState> jobStatuses = connection.getJobStatuses(monitorID);
-                    Iterator<MonitorID> iterator = monitorID.listIterator();
+                    Iterator<MonitorID> iterator = monitorID.iterator();
                     while (iterator.hasNext()) {
                         MonitorID iMonitorID = iterator.next();
                         currentMonitorID = iMonitorID;
@@ -239,50 +224,44 @@ public class HPCPullMonitor extends PullMonitor {
                                 !JobState.COMPLETE.equals(iMonitorID.getStatus())) {
                             iMonitorID.setStatus(jobStatuses.get(iMonitorID.getJobID() + "," + iMonitorID.getJobName()));    //IMPORTANT this is NOT a simple setter we have a logic
                         }else if(JobState.COMPLETE.equals(iMonitorID.getStatus())){
+                            completedJobs.put(iMonitorID.getJobName(), iMonitorID);
                             logger.debugId(iMonitorID.getJobID(), "Moved job {} to completed jobs map, experiment {}, " +
                                     "task {}", iMonitorID.getJobID(), iMonitorID.getExperimentID(), iMonitorID.getTaskID());
-                            iterator.remove();
-                            logger.info("PULL Notification is complete: marking the Job as ************COMPLETE************ experiment {}, task {}, job name {} .",
-                                    iMonitorID.getExperimentID(),iMonitorID.getTaskID(),iMonitorID.getJobName());
-                            GFacThreadPoolExecutor.getFixedThreadPool().submit(new OutHandlerWorker(gfac, iMonitorID, publisher));
                         }
+                        jobStatus = new JobStatusChangeRequestEvent();
                         iMonitorID.setStatus(jobStatuses.get(iMonitorID.getJobID()+","+iMonitorID.getJobName()));    //IMPORTANT this is not a simple setter we have a logic
-                        iMonitorID.setLastMonitored(new Timestamp((new Date()).getTime()));
-                        sendNotification(iMonitorID);
+                        JobIdentifier jobIdentity = new JobIdentifier(iMonitorID.getJobID(), iMonitorID.getTaskID(), iMonitorID.getWorkflowNodeID(), iMonitorID.getExperimentID());
+                        jobStatus.setJobIdentity(jobIdentity);
+                        jobStatus.setState(iMonitorID.getStatus());
+                        // we have this JobStatus class to handle amqp monitoring
+
+                        publisher.publish(jobStatus);
                         logger.debugId(jobStatus.getJobIdentity().getJobId(), "Published job status change request, " +
                                         "experiment {} , task {}", jobStatus.getJobIdentity().getExperimentId(),
                                 jobStatus.getJobIdentity().getTaskId());
                         // if the job is completed we do not have to put the job to the queue again
                         iMonitorID.setLastMonitored(new Timestamp((new Date()).getTime()));
-                    }
-                    iterator = monitorID.listIterator();
-                    while(iterator.hasNext()){
-                        MonitorID iMonitorID = iterator.next();
+
                         if (iMonitorID.getFailedCount() > FAILED_COUNT) {
                             iMonitorID.setLastMonitored(new Timestamp((new Date()).getTime()));
                             String outputDir = iMonitorID.getJobExecutionContext().getApplicationContext()
                                     .getApplicationDeploymentDescription().getType().getOutputDataDirectory();
-                            List<String> stdOut = null;
-                            try {
-                                stdOut = connection.getCluster().listDirectory(outputDir); // check the outputs directory
-                            } catch (SSHApiException e) {
-                                if (e.getMessage().contains("No such file or directory")) {
-                                    // this is because while we run output handler something failed and during exception
-                                    // we store all the jobs in the monitor queue again
-                                    logger.error("We know this  job is already attempted to run out-handlers");
-//                                    CommonUtils.removeMonitorFromQueue(queue, iMonitorID);
+                            List<String> stdOut = connection.getCluster().listDirectory(outputDir); // check the outputs directory
+                            if (stdOut.size() > 0) { // have to be careful with this
+                                for(int i=0;i<stdOut.size();i++) {
+                                    logger.info("--------------------------------------------------------------------------------------------");
+                                    logger.info("--------------------------------------------------------------------------------------------");
+                                    logger.info("--------------------------------------------------------------------------------------------");
+                                    logger.info("--------------------------------------------------------------------------------------------");
+                                    logger.info("--------------------------------------------------------------------------------------------");
+                                    logger.info("--------------------------------------------------------------------------------------------");
+                                    logger.info("--------------------------------------------------------------------------------------------");
+                                    logger.info(stdOut.get(i));
                                 }
-                            }
-                            if (stdOut != null && stdOut.size() > 0 && !stdOut.get(0).isEmpty()) { // have to be careful with this
-                                iMonitorID.setStatus(JobState.COMPLETE);
-                                logger.errorId(iMonitorID.getJobID(), "Job monitoring failed {} times, " +
-                                                " Experiment {} , task {}", iMonitorID.getFailedCount(),
+                                completedJobs.put(iMonitorID.getJobName(), iMonitorID);
+                                logger.errorId(iMonitorID.getJobID(), "Job monitoring failed {} times, removed job {} from " +
+                                                "monitor queue. Experiment {} , task {}", iMonitorID.getFailedCount(),
                                         iMonitorID.getExperimentID(), iMonitorID.getTaskID());
-                                logger.info("Listing directory came as complete: marking the Job as ************COMPLETE************ experiment {}, task {}, job name {} .",
-                                        iMonitorID.getExperimentID(),iMonitorID.getTaskID(),iMonitorID.getJobName());
-                                sendNotification(iMonitorID);
-                                iterator.remove();
-                                GFacThreadPoolExecutor.getFixedThreadPool().submit(new OutHandlerWorker(gfac, iMonitorID, publisher));
                             } else {
                                 iMonitorID.setFailedCount(0);
                             }
@@ -293,8 +272,6 @@ public class HPCPullMonitor extends PullMonitor {
                             // get empty this userMonitorData will get delete from the queue
                         }
                     }
-
-
                 } else {
                     logger.debug("Qstat Monitor doesn't handle non-gsissh hosts , host {}", iHostMonitorData.getHost()
                             .getType().getHostAddress());
@@ -303,6 +280,30 @@ public class HPCPullMonitor extends PullMonitor {
             // We have finished all the HostMonitorData object in userMonitorData, now we need to put it back
             // now the userMonitorData goes back to the tail of the queue
             queue.put(take);
+            // cleaning up the completed jobs, this method will remove some of the userMonitorData from the queue if
+            // they become empty
+            Map<String, Integer> jobRemoveCountMap = new HashMap<String, Integer>();
+            ZooKeeper zk = null;
+            Set<String> keys = completedJobs.keySet();
+            for (String jobName: keys) {
+                MonitorID completedJob = completedJobs.get(jobName);
+                CommonUtils.removeMonitorFromQueue(queue, completedJob);
+                gfac.invokeOutFlowHandlers(completedJob.getJobExecutionContext());
+//                GFacThreadPoolExecutor.getCachedThreadPool().submit(new OutHandlerWorker(gfac, completedJob, publisher));
+                if (zk == null) {
+                    zk = completedJob.getJobExecutionContext().getZk();
+                }
+                String key = CommonUtils.getJobCountUpdatePath(completedJob);
+                int i = 0;
+                if (jobRemoveCountMap.containsKey(key)) {
+                    i = Integer.valueOf(jobRemoveCountMap.get(key));
+                }
+                jobRemoveCountMap.put(key, ++i);
+            }
+            if (completedJobs.size() > 0) {
+                // reduce completed job count from zookeeper
+                CommonUtils.updateZkWithJobCount(zk, jobRemoveCountMap, false);
+            }
         } catch (InterruptedException e) {
             if (!this.queue.contains(take)) {
                 try {
@@ -318,13 +319,12 @@ public class HPCPullMonitor extends PullMonitor {
             if (e.getMessage().contains("Unknown Job Id Error")) {
                 // in this case job is finished or may be the given job ID is wrong
                 jobStatus.setState(JobState.UNKNOWN);
-                JobIdentifier jobIdentifier = new JobIdentifier("UNKNOWN", "UNKNOWN", "UNKNOWN", "UNKNOWN", "UNKNOWN");
+                JobIdentifier jobIdentifier = new JobIdentifier("UNKNOWN", "UNKNOWN", "UNKNOWN", "UNKNOWN");
                 if (currentMonitorID != null){
                     jobIdentifier.setExperimentId(currentMonitorID.getExperimentID());
                     jobIdentifier.setTaskId(currentMonitorID.getTaskID());
                     jobIdentifier.setWorkflowNodeId(currentMonitorID.getWorkflowNodeID());
                     jobIdentifier.setJobId(currentMonitorID.getJobID());
-                    jobIdentifier.setGatewayId(currentMonitorID.getJobExecutionContext().getGatewayID());
                 }
                 jobStatus.setJobIdentity(jobIdentifier);
                 publisher.publish(jobStatus);
@@ -349,20 +349,6 @@ public class HPCPullMonitor extends PullMonitor {
         return true;
     }
 
-    private void sendNotification(MonitorID iMonitorID) {
-        JobStatusChangeRequestEvent jobStatus = new JobStatusChangeRequestEvent();
-        JobIdentifier jobIdentity = new JobIdentifier(iMonitorID.getJobID(),
-                iMonitorID.getTaskID(),
-                iMonitorID.getWorkflowNodeID(),
-                iMonitorID.getExperimentID(),
-                iMonitorID.getJobExecutionContext().getGatewayID());
-        jobStatus.setJobIdentity(jobIdentity);
-        jobStatus.setState(iMonitorID.getStatus());
-        // we have this JobStatus class to handle amqp monitoring
-
-        publisher.publish(jobStatus);
-    }
-
     /**
      * This is the method to stop the polling process
      *