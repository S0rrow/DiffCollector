diff --git a/asterixdb/asterix-app/src/main/java/org/apache/asterix/app/function/TPCDSDataGeneratorReader.java b/asterixdb/asterix-app/src/main/java/org/apache/asterix/app/function/TPCDSDataGeneratorReader.java
index 1122a29832..626dee34a9 100644
--- a/asterixdb/asterix-app/src/main/java/org/apache/asterix/app/function/TPCDSDataGeneratorReader.java
+++ b/asterixdb/asterix-app/src/main/java/org/apache/asterix/app/function/TPCDSDataGeneratorReader.java
@@ -19,7 +19,6 @@
 package org.apache.asterix.app.function;
 
 import java.io.IOException;
-import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
 import java.util.stream.Collectors;
@@ -36,161 +35,72 @@ import com.teradata.tpcds.Session;
 import com.teradata.tpcds.Table;
 
 /**
- * Each partition will be running a TPCDS data generator reader instance. Depending on the number of partitions, the
- * data generator will parallelize its work based on the number of partitions. The reader is passed the parallelism
- * level based on the number of partition instances.
+ * Each partition will be running a TPCDSDataGeneratorReader instance. Depending on the number of partitions, the data
+ * generator will parallelize its work based on the number of partitions. The reader is passed the parallelism level
+ * (depending on the number of partitions).
  *
- * The function automatically handles generating the data for a single specified table or for all the tables. Also,
- * the parallelism will take place regardless of the selected data size to be generated.
+ * Note: The data generator does not apply the parallelism unless at least 1,000,000 rows generation is requested (this
+ * depends on the scaling factor and the table for whose the rows are being generated). This means, despite the number
+ * of available partitions, if the minimum number of rows is not met, a single partition will generate all the rows
+ * while all the other partitions will generate 0 rows.
  */
-
 public class TPCDSDataGeneratorReader extends FunctionReader {
 
-    private final FunctionIdentifier functionIdentifier;
-
-    // Table members
-    private final List<Table> selectedTables;
+    private final int parallelism;
+    private final int chunkNumber;
+    private final String tableName;
+    private final double scalingFactor;
+    private Table selectedTable;
     private final StringBuilder builder = new StringBuilder();
-    private final List<Iterator<List<List<String>>>> tableIterators = new ArrayList<>();
-    private Table currentTable;
-    private final int tableCount;
-    private int currentTableIndex;
-
-    // Parent tables will generate 2 records, 1 for the main, and another for the child's row, we'll push the parent
-    // record, and in the next rotation we'll push the child row, then go to next row generation
-    private String childRow = null;
-
-    // This will guide the next() method to know where to get the next record from (Parent or child record)
-    private boolean getFromParent = true;
-    private final boolean generateAllTables;
-
-    TPCDSDataGeneratorReader(String tableName, double scalingFactor, int parallelism, int partitionNumber,
-            FunctionIdentifier functionIdentifier) throws HyracksDataException {
-        this.functionIdentifier = functionIdentifier;
-
-        // Note: chunk numbers start with 1, so each chunk will be partition number + 1
-        // Create the session with the specified properties, the sessions also specifies the chunk to be generated
-        Session session = Session.getDefaultSession().withScale(scalingFactor).withParallelism(parallelism)
-                .withChunkNumber(partitionNumber + 1);
-
-        // If the tableName is null, then we're generating all the tables
-        generateAllTables = tableName == null;
-
-        // Get the table(s)
-        selectedTables = getTableFromStringTableName(tableName);
-
-        // These variables will monitor and assist with each table's data generation
-        currentTableIndex = 0;
-        tableCount = selectedTables.size();
-        currentTable = selectedTables.get(currentTableIndex);
-
-        // Iterators for the tables to generate the data for
-        for (Table table : selectedTables) {
-            Results result = calculateParallelism(table, session);
-            tableIterators.add(result.iterator());
-        }
+    private final Iterator<List<List<String>>> dataGeneratorIterator;
+
+    public TPCDSDataGeneratorReader(String tableName, double scalingFactor, int parallelism, int partitionNumber)
+            throws HyracksDataException {
+        this.tableName = tableName;
+        this.scalingFactor = scalingFactor;
+        this.parallelism = parallelism;
+
+        /*
+         Since we already ensured the parallelism level for the TPC-DS matches the number of partitions we have, we
+         need a way to tell each partition which chunk to generate. Since each TPCDSDataGeneratorReader is receiving
+         the partition number that's running it, we're gonna use that as the chunk to be produced by the data
+         generator.
+         Note that the indexing for the partitions starts at position 0, but the data generator chunks start at 1,
+         so the chunk will always be the partitionNumber + 1
+         */
+        chunkNumber = partitionNumber + 1;
+
+        dataGeneratorIterator = getDataGeneratorIterator();
     }
 
     @Override
     public boolean hasNext() {
-
-        // Return children generated records of current table
-        if (generateAllTables && childRow != null) {
-            getFromParent = false;
-            return true;
-        }
-
-        // Current table still has more
-        if (tableIterators.get(currentTableIndex).hasNext()) {
-            return true;
-        }
-
-        // We went over all the tables
-        if (currentTableIndex == tableCount - 1) {
-            return false;
-        }
-
-        // Go to the next table
-        currentTableIndex++;
-        currentTable = selectedTables.get(currentTableIndex);
-
-        return hasNext();
+        return dataGeneratorIterator.hasNext();
     }
 
     @Override
     public IRawRecord<char[]> next() throws IOException, InterruptedException {
         CharArrayRecord record = new CharArrayRecord();
-
-        if (getFromParent) {
-            record.append((formatRecord(tableIterators.get(currentTableIndex).next())).toCharArray());
-        } else {
-            record.append(childRow.toCharArray());
-            childRow = null; // Always reset the child row after writing it
-            getFromParent = true;
-        }
-
+        record.append((formatRecord(dataGeneratorIterator.next())).toCharArray());
         record.endRecord();
         return record;
     }
 
     /**
-     * Builds the string record from the generated values by the data generator. The column name for each value is
-     * extracted from the table from which the data is being generated.
+     * Create the data generator iterator with the specified properties passed to the session.
      *
-     * @param values List containing all the generated column values
-     *
-     * @return The built string record from the generated values
+     * @return A lazy iterator to generate the data based on the specified properties.
      */
-    private String formatRecord(List<List<String>> values) {
-        // Clear the builder (This is faster than re-creating the builder each iteration)
-        builder.setLength(0);
-
-        builder.append("{\"tableName\":\"");
-        builder.append(currentTable.toString());
-        builder.append("\"");
+    private Iterator<List<List<String>>> getDataGeneratorIterator() throws HyracksDataException {
+        selectedTable = getTableFromStringTableName(tableName);
 
-        // Build the record data
-        for (int counter = 0; counter < values.get(0).size(); counter++) {
-            builder.append(",\"");
-            builder.append(currentTable.getColumns()[counter].getName());
-            builder.append("\":\"");
-            builder.append(values.get(0).get(counter));
-            builder.append("\"");
-        }
-
-        // Close the record
-        builder.append("}");
-
-        // Reference to the parent row to be returned, before resetting the builder again
-        String parentRow = builder.toString();
-
-        // In some cases, the generate generates 2 records, one for current table, and one for child table. If a child
-        // record is generated, we're gonna add it to a list, and start pushing it once all the parent records
-        // are done
-        if (generateAllTables && values.size() > 1) {
-            builder.setLength(0);
-            builder.append("{\"tableName\":\"");
-            builder.append(currentTable.getChild().toString());
-            builder.append("\"");
-
-            // Build the record data
-            for (int counter = 0; counter < values.get(1).size(); counter++) {
-                builder.append(",\"");
-                builder.append(currentTable.getChild().getColumns()[counter].getName());
-                builder.append("\":\"");
-                builder.append(values.get(0).get(counter));
-                builder.append("\"");
-            }
-
-            // Close the record
-            builder.append("}");
-
-            // Add it to the children rows list
-            childRow = builder.toString();
-        }
+        // Create the session with the specified properties, the sessions also specifies the chunk to be generated
+        Session session = Session.getDefaultSession().withTable(selectedTable).withScale(scalingFactor)
+                .withParallelism(parallelism).withChunkNumber(chunkNumber);
 
-        // Return parent row
-        return parentRow;
+        // Construct the Results and Results iterator
+        Results results = Results.constructResults(selectedTable, session);
+        return results.iterator();
     }
 
     /**
@@ -199,91 +109,55 @@ public class TPCDSDataGeneratorReader extends FunctionReader {
      * @param tableName String table name to search for.
      * @return Table if found, throws an exception otherwise.
      */
-    private List<Table> getTableFromStringTableName(String tableName) throws HyracksDataException {
-
-        // Get all the tables
-        if (generateAllTables) {
-            // Remove the DBGEN_VERSION table and all children tables, parent tables will generate them
-            return Table.getBaseTables().stream()
-                    .filter(table -> !table.equals(Table.DBGEN_VERSION) && !table.isChild())
-                    .collect(Collectors.toList());
-        }
+    private Table getTableFromStringTableName(String tableName) throws HyracksDataException {
 
-        // Search for the table
         List<Table> matchedTables = Table.getBaseTables().stream()
                 .filter(table -> tableName.equalsIgnoreCase(table.getName())).collect(Collectors.toList());
 
         // Ensure the table was found
         if (matchedTables.size() != 1) {
-            throw new RuntimeDataException(ErrorCode.TPCDS_INVALID_TABLE_NAME, getFunctionIdentifier().getName(),
-                    tableName);
+            throw new RuntimeDataException(ErrorCode.TPCDS_INVALID_TABLE_NAME, getIdentifier().getName(), tableName);
         }
 
-        return matchedTables;
+        return matchedTables.get(0);
     }
 
     /**
-     * As the TPC-DS library has constraints on activating the parallelism (table must be generating 1,000,000 records
-     * based on a scaling factor), we're gonna override that behavior and calculate the parallelism manually. This
-     * will ensure the activation of the parallelism regardless of the data size being generated.
+     * Builds the string record from the generated values by the data generator. The column name for each value is
+     * extracted from the table from which the data is being generated.
      *
-     * @param table table to generate the data for
-     * @param session session containing the parallelism and scaling information
+     * @param values List containing all the generated column values
      *
-     * @return Results that holds a lazy-iterator to generate the data based on the calculated parameters.
+     * @return The built string record from the generated values
      */
-    private Results calculateParallelism(Table table, Session session) {
-
-        // Total and parallelism level
-        long total = session.getScaling().getRowCount(table);
-        int parallelism = session.getParallelism();
-
-        // Row set size to be generated for each partition
-        long rowSetSize = total / parallelism;
+    private String formatRecord(List<List<String>> values) {
+        // Clear the builder (This is faster than re-creating the builder each iteration)
+        builder.setLength(0);
 
-        // Special case: WEB_SITE table sometimes relies on the previous records, this could be a problem if the
-        // previous record is on a different thread. Since it's a small table, we'll generate it all on the first
-        // thread and let the other threads generate nothing
-        if (table.equals(Table.WEB_SITE)) {
-            if (session.getChunkNumber() - 1 == 0) {
-                return new Results(table, 1, total, session);
-            }
-            // Don't generate anything on other partition (start > end)
-            else {
-                return new Results(table, 2, 1, session);
-            }
-        }
+        int counter;
+        builder.append("{");
 
-        // Special case: For very small tables, if the rowSetSize ends up being 1, this will cause an issue in the
-        // parallelism, so we'll just let the first thread do all the work
-        if (rowSetSize == 1) {
-            if (session.getChunkNumber() - 1 == 0) {
-                return new Results(table, 1, total, session);
-            }
-            // Don't generate anything on other partition (start > end)
-            else {
-                return new Results(table, 2, 1, session);
-            }
+        // We loop only to the item before the last, then add the last item manually to avoid appending the ","
+        // at the end, this way we avoid constantly checking if we're at the last item or substring the whole record
+        for (counter = 0; counter < values.get(0).size() - 1; counter++) {
+            builder.append("\"");
+            builder.append(selectedTable.getColumns()[counter].getName());
+            builder.append("\":\"");
+            builder.append(values.get(0).get(counter));
+            builder.append("\",");
         }
 
-        // Start and end calculated for each partition
-        long startRow = (session.getChunkNumber() - 1) * rowSetSize + 1;
-        long rowCount = startRow + rowSetSize - 1;
-
-        // Any extra rows (not evenly divided) will be done by the last partition
-        if (session.getChunkNumber() == parallelism) {
-            rowCount += total % parallelism;
-        }
+        // This is the last item to be appended, don't append the "," after appending the field
+        builder.append("\"");
+        builder.append(selectedTable.getColumns()[counter].getName());
+        builder.append("\":\"");
+        builder.append(values.get(0).get(counter));
+        builder.append("\"}");
 
-        return new Results(table, startRow, rowCount, session);
+        return builder.toString();
     }
 
-    /**
-     * Gets the function identifier
-     *
-     * @return function identifier
-     */
-    private FunctionIdentifier getFunctionIdentifier() {
-        return functionIdentifier;
+    private FunctionIdentifier getIdentifier() {
+        return TPCDSDataGeneratorRewriter.TPCDS_DATA_GENERATOR;
     }
 }