diff --git a/asterixdb/asterix-transactions/src/main/java/org/apache/asterix/transaction/management/service/logging/LogManager.java b/asterixdb/asterix-transactions/src/main/java/org/apache/asterix/transaction/management/service/logging/LogManager.java
index 7f74f5284d..f10520b9a9 100644
--- a/asterixdb/asterix-transactions/src/main/java/org/apache/asterix/transaction/management/service/logging/LogManager.java
+++ b/asterixdb/asterix-transactions/src/main/java/org/apache/asterix/transaction/management/service/logging/LogManager.java
@@ -27,7 +27,6 @@ import java.nio.channels.FileChannel;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.Comparator;
-import java.util.HashMap;
 import java.util.List;
 import java.util.concurrent.Callable;
 import java.util.concurrent.ExecutionException;
@@ -48,7 +47,6 @@ import org.apache.asterix.common.transactions.ITransactionManager;
 import org.apache.asterix.common.transactions.LogManagerProperties;
 import org.apache.asterix.common.transactions.LogType;
 import org.apache.asterix.common.transactions.MutableLong;
-import org.apache.asterix.common.transactions.TxnLogFile;
 import org.apache.asterix.transaction.management.service.transaction.TransactionSubsystem;
 import org.apache.hyracks.api.lifecycle.ILifeCycleComponent;
 
@@ -73,16 +71,14 @@ public class LogManager implements ILogManager, ILifeCycleComponent {
     private LogFlusher logFlusher;
     private Future<? extends Object> futureLogFlusher;
     private static final long SMALLEST_LOG_FILE_ID = 0;
-    private static final int INITIAL_LOG_SIZE = 0;
     private final String nodeId;
     protected LinkedBlockingQueue<ILogRecord> flushLogsQ;
     private final FlushLogsLogger flushLogsLogger;
-    private final HashMap<Long, Integer> txnLogFileId2ReaderCount = new HashMap<>();
 
     public LogManager(TransactionSubsystem txnSubsystem) {
         this.txnSubsystem = txnSubsystem;
-        logManagerProperties =
-                new LogManagerProperties(this.txnSubsystem.getTransactionProperties(), this.txnSubsystem.getId());
+        logManagerProperties = new LogManagerProperties(this.txnSubsystem.getTransactionProperties(),
+                this.txnSubsystem.getId());
         logFileSize = logManagerProperties.getLogPartitionSize();
         logPageSize = logManagerProperties.getLogPageSize();
         numLogPages = logManagerProperties.getNumLogPages();
@@ -108,7 +104,7 @@ public class LogManager implements ILogManager, ILifeCycleComponent {
             LOGGER.info("LogManager starts logging in LSN: " + appendLSN);
         }
         appendChannel = getFileChannel(appendLSN.get(), false);
-        getAndInitNewPage(INITIAL_LOG_SIZE);
+        getAndInitNewPage();
         logFlusher = new LogFlusher(this, emptyQ, flushQ);
         futureLogFlusher = txnSubsystem.getAsterixAppRuntimeContextProvider().getThreadExecutor().submit(logFlusher);
         if (!flushLogsLogger.isAlive()) {
@@ -143,80 +139,63 @@ public class LogManager implements ILogManager, ILifeCycleComponent {
     }
 
     protected synchronized void syncAppendToLogTail(ILogRecord logRecord) throws ACIDException {
+        ITransactionContext txnCtx = null;
+
         if (logRecord.getLogType() != LogType.FLUSH) {
-            ITransactionContext txnCtx = logRecord.getTxnCtx();
+            txnCtx = logRecord.getTxnCtx();
             if (txnCtx.getTxnState() == ITransactionManager.ABORTED && logRecord.getLogType() != LogType.ABORT) {
                 throw new ACIDException(
                         "Aborted job(" + txnCtx.getJobId() + ") tried to write non-abort type log record.");
             }
         }
-
-        /**
-         * To eliminate the case where the modulo of the next appendLSN = 0 (the next
-         * appendLSN = the first LSN of the next log file), we do not allow a log to be
-         * written at the last offset of the current file.
-         */
-        final int logSize = logRecord.getLogSize();
-        if (!appendPage.hasSpace(logSize)) {
-            if (getLogFileOffset(appendLSN.get()) + logSize >= logFileSize) {
-                prepareNextLogFile();
-            }
+        if (getLogFileOffset(appendLSN.get()) + logRecord.getLogSize() > logFileSize) {
+            prepareNextLogFile();
             appendPage.isFull(true);
-            getAndInitNewPage(logSize);
+            getAndInitNewPage();
+        } else if (!appendPage.hasSpace(logRecord.getLogSize())) {
+            appendPage.isFull(true);
+            if (logRecord.getLogSize() > logPageSize) {
+                getAndInitNewLargePage(logRecord.getLogSize());
+            } else {
+                getAndInitNewPage();
+            }
+        }
+        if (logRecord.getLogType() == LogType.UPDATE) {
+            logRecord.setPrevLSN(txnCtx.getLastLSN());
         }
         appendPage.append(logRecord, appendLSN.get());
 
         if (logRecord.getLogType() == LogType.FLUSH) {
             logRecord.setLSN(appendLSN.get());
         }
-        if (logRecord.isMarker()) {
-            logRecord.logAppended(appendLSN.get());
-        }
-        appendLSN.addAndGet(logSize);
+        appendLSN.addAndGet(logRecord.getLogSize());
     }
 
-    protected void getAndInitNewPage(int logSize) {
-        if (logSize > logPageSize) {
-            // for now, alloc a new buffer for each large page
-            // TODO: pool large pages
-            appendPage = new LogBuffer(txnSubsystem, logSize, flushLSN);
-            appendPage.setFileChannel(appendChannel);
-            flushQ.offer(appendPage);
-        } else {
-            appendPage = null;
-            while (appendPage == null) {
-                try {
-                    appendPage = emptyQ.take();
-                } catch (InterruptedException e) {
-                    //ignore
-                }
-            }
-            appendPage.reset();
-            appendPage.setFileChannel(appendChannel);
-            flushQ.offer(appendPage);
-        }
+    protected void getAndInitNewLargePage(int logSize) {
+        // for now, alloc a new buffer for each large page
+        // TODO: pool large pages
+        appendPage = new LogBuffer(txnSubsystem, logSize, flushLSN);
+        appendPage.setFileChannel(appendChannel);
+        flushQ.offer(appendPage);
     }
 
-    protected void prepareNextLogFile() {
-        //wait until all log records have been flushed in the current file
-        synchronized (flushLSN) {
+    protected void getAndInitNewPage() {
+        appendPage = null;
+        while (appendPage == null) {
             try {
-                while (flushLSN.get() != appendLSN.get()) {
-                    //notification will come from LogBuffer.internalFlush(.)
-                    flushLSN.wait();
-                }
+                appendPage = emptyQ.take();
             } catch (InterruptedException e) {
-                Thread.currentThread().interrupt();
+                //ignore
             }
         }
-        //move appendLSN and flushLSN to the first LSN of the next log file
+        appendPage.reset();
+        appendPage.setFileChannel(appendChannel);
+        flushQ.offer(appendPage);
+    }
+
+    protected void prepareNextLogFile() {
         appendLSN.addAndGet(logFileSize - getLogFileOffset(appendLSN.get()));
-        flushLSN.set(appendLSN.get());
         appendChannel = getFileChannel(appendLSN.get(), true);
-        if (LOGGER.isLoggable(Level.INFO)) {
-            LOGGER.info("Created new txn log file with id(" + getLogFileId(appendLSN.get()) + ") starting with LSN = "
-                    + appendLSN.get());
-        }
         appendPage.isLastPage(true);
         //[Notice]
         //the current log file channel is closed if
@@ -344,32 +323,15 @@ public class LogManager implements ILogManager, ILifeCycleComponent {
 
     @Override
     public void deleteOldLogFiles(long checkpointLSN) {
+
         Long checkpointLSNLogFileID = getLogFileId(checkpointLSN);
         List<Long> logFileIds = getLogFileIds();
         if (logFileIds != null) {
-            //sort log files from oldest to newest
-            Collections.sort(logFileIds);
-            /**
-             * At this point, any future LogReader should read from LSN >= checkpointLSN
-             */
-            synchronized (txnLogFileId2ReaderCount) {
-                for (Long id : logFileIds) {
-                    /**
-                     * Stop deletion if:
-                     * The log file which contains the checkpointLSN has been reached.
-                     * The oldest log file being accessed by a LogReader has been reached.
-                     */
-                    if (id >= checkpointLSNLogFileID
-                            || (txnLogFileId2ReaderCount.containsKey(id) && txnLogFileId2ReaderCount.get(id) > 0)) {
-                        break;
-                    }
-
-                    //delete old log file
+            for (Long id : logFileIds) {
+                if (id < checkpointLSNLogFileID) {
                     File file = new File(getLogFilePath(id));
-                    file.delete();
-                    txnLogFileId2ReaderCount.remove(id);
-                    if (LOGGER.isLoggable(Level.INFO)) {
-                        LOGGER.info("Deleted log file " + file.getAbsolutePath());
+                    if (!file.delete()) {
+                        throw new IllegalStateException("Failed to delete a file: " + file.getAbsolutePath());
                     }
                 }
             }
@@ -403,7 +365,6 @@ public class LogManager implements ILogManager, ILifeCycleComponent {
                 throw new IllegalStateException("Failed to close a fileChannel of a log file");
             }
         }
-        txnLogFileId2ReaderCount.clear();
         List<Long> logFileIds = getLogFileIds();
         if (logFileIds != null) {
             for (Long id : logFileIds) {
@@ -473,7 +434,7 @@ public class LogManager implements ILogManager, ILifeCycleComponent {
         return (new File(path)).mkdir();
     }
 
-    private FileChannel getFileChannel(long lsn, boolean create) {
+    public FileChannel getFileChannel(long lsn, boolean create) {
         FileChannel newFileChannel = null;
         try {
             long fileId = getLogFileId(lsn);
@@ -535,55 +496,6 @@ public class LogManager implements ILogManager, ILifeCycleComponent {
         return numLogPages;
     }
 
-    @Override
-    public TxnLogFile getLogFile(long LSN) throws IOException {
-        long fileId = getLogFileId(LSN);
-        String logFilePath = getLogFilePath(fileId);
-        File file = new File(logFilePath);
-        if (!file.exists()) {
-            throw new IOException("Log file with id(" + fileId + ") was not found. Requested LSN: " + LSN);
-        }
-        RandomAccessFile raf = new RandomAccessFile(new File(logFilePath), "r");
-        FileChannel newFileChannel = raf.getChannel();
-        TxnLogFile logFile = new TxnLogFile(this, newFileChannel, fileId, fileId * logFileSize);
-        touchLogFile(fileId);
-        return logFile;
-    }
-
-    @Override
-    public void closeLogFile(TxnLogFile logFileRef, FileChannel fileChannel) throws IOException {
-        if (!fileChannel.isOpen()) {
-            throw new IllegalStateException("File channel is not open");
-        }
-        fileChannel.close();
-        untouchLogFile(logFileRef.getLogFileId());
-    }
-
-    private void touchLogFile(long fileId) {
-        synchronized (txnLogFileId2ReaderCount) {
-            if (txnLogFileId2ReaderCount.containsKey(fileId)) {
-                txnLogFileId2ReaderCount.put(fileId, txnLogFileId2ReaderCount.get(fileId) + 1);
-            } else {
-                txnLogFileId2ReaderCount.put(fileId, 1);
-            }
-        }
-    }
-
-    private void untouchLogFile(long fileId) {
-        synchronized (txnLogFileId2ReaderCount) {
-            if (txnLogFileId2ReaderCount.containsKey(fileId)) {
-                int newReaderCount = txnLogFileId2ReaderCount.get(fileId) - 1;
-                if (newReaderCount < 0) {
-                    throw new IllegalStateException(
-                            "Invalid log file reader count (ID=" + fileId + ", count: " + newReaderCount + ")");
-                }
-                txnLogFileId2ReaderCount.put(fileId, newReaderCount);
-            } else {
-                throw new IllegalStateException("Trying to close log file id(" + fileId + ") which was not opened.");
-            }
-        }
-    }
-
     /**
      * This class is used to log FLUSH logs.
      * FLUSH logs are flushed on a different thread to avoid a possible deadlock in LogBuffer batchUnlock which calls PrimaryIndexOpeartionTracker.completeOperation