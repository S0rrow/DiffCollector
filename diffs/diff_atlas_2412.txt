diff --git a/addons/hive-bridge/src/test/java/org/apache/atlas/hive/hook/HiveHookIT.java b/addons/hive-bridge/src/test/java/org/apache/atlas/hive/hook/HiveHookIT.java
index 8ef8479bf..1611bc212 100755
--- a/addons/hive-bridge/src/test/java/org/apache/atlas/hive/hook/HiveHookIT.java
+++ b/addons/hive-bridge/src/test/java/org/apache/atlas/hive/hook/HiveHookIT.java
@@ -18,27 +18,21 @@
 
 package org.apache.atlas.hive.hook;
 
-import com.google.common.base.Joiner;
-import com.google.common.collect.ImmutableList;
 import org.apache.atlas.ApplicationProperties;
 import org.apache.atlas.AtlasClient;
-import org.apache.atlas.fs.model.FSDataTypes;
 import org.apache.atlas.hive.bridge.HiveMetaStoreBridge;
 import org.apache.atlas.hive.model.HiveDataModelGenerator;
 import org.apache.atlas.hive.model.HiveDataTypes;
 import org.apache.atlas.typesystem.Referenceable;
 import org.apache.atlas.typesystem.Struct;
-import org.apache.atlas.typesystem.persistence.Id;
 import org.apache.atlas.utils.ParamChecker;
 import org.apache.commons.configuration.Configuration;
 import org.apache.commons.lang.RandomStringUtils;
 import org.apache.commons.lang.StringEscapeUtils;
 import org.apache.commons.lang.StringUtils;
-import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.metastore.TableType;
 import org.apache.hadoop.hive.ql.Driver;
-import org.apache.hadoop.hive.ql.hooks.Entity;
 import org.apache.hadoop.hive.ql.processors.CommandProcessorResponse;
 import org.apache.hadoop.hive.ql.session.SessionState;
 import org.codehaus.jettison.json.JSONArray;
@@ -49,7 +43,6 @@ import org.testng.annotations.BeforeClass;
 import org.testng.annotations.Test;
 
 import java.io.File;
-import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
@@ -64,23 +57,11 @@ public class HiveHookIT {
     private Driver driver;
     private AtlasClient dgiCLient;
     private SessionState ss;
-    
-    private static final String INPUTS = AtlasClient.PROCESS_ATTRIBUTE_INPUTS;
-    private static final String OUTPUTS = AtlasClient.PROCESS_ATTRIBUTE_OUTPUTS;
-
-    private enum QUERY_TYPE {
-        GREMLIN,
-        DSL
-    }
 
     @BeforeClass
     public void setUp() throws Exception {
         //Set-up hive session
         HiveConf conf = new HiveConf();
-        //Run in local mode
-        conf.set("mapreduce.framework.name", "local");
-        conf.set("fs.default.name", "file:///'");
-        conf.setClassLoader(Thread.currentThread().getContextClassLoader());
         driver = new Driver(conf);
         ss = new SessionState(conf, System.getProperty("user.name"));
         ss = SessionState.start(ss);
@@ -88,10 +69,6 @@ public class HiveHookIT {
 
         Configuration configuration = ApplicationProperties.get();
         dgiCLient = new AtlasClient(configuration.getString(HiveMetaStoreBridge.ATLAS_ENDPOINT, DGI_URL));
-
-        HiveMetaStoreBridge hiveMetaStoreBridge = new HiveMetaStoreBridge(conf, configuration);
-        hiveMetaStoreBridge.registerHiveDataModel();
-
     }
 
     private void runCommand(String cmd) throws Exception {
@@ -108,7 +85,7 @@ public class HiveHookIT {
         String dbId = assertDatabaseIsRegistered(dbName);
 
         Referenceable definition = dgiCLient.getEntity(dbId);
-        Map params = (Map) definition.get(HiveDataModelGenerator.PARAMETERS);
+        Map params = (Map) definition.get("parameters");
         Assert.assertNotNull(params);
         Assert.assertEquals(params.size(), 2);
         Assert.assertEquals(params.get("p1"), "v1");
@@ -143,28 +120,16 @@ public class HiveHookIT {
     }
 
     private String createTable() throws Exception {
-        return createTable(false);
+        return createTable(true);
     }
 
-    private String createTable(boolean isPartitioned) throws Exception {
+    private String createTable(boolean partition) throws Exception {
         String tableName = tableName();
-        runCommand("create table " + tableName + "(id int, name string) comment 'table comment' " + (isPartitioned ?
+        runCommand("create table " + tableName + "(id int, name string) comment 'table comment' " + (partition ?
             " partitioned by(dt string)" : ""));
         return tableName;
     }
 
-    private String createTable(boolean isExternal, boolean isPartitioned, boolean isTemporary) throws Exception {
-        String tableName = tableName();
-
-        String location = "";
-        if (isExternal) {
-            location = " location '" +  createTestDFSPath("someTestPath") + "'";
-        }
-        runCommand("create " + (isExternal ? " EXTERNAL " : "") + (isTemporary ? "TEMPORARY " : "") + "table " + tableName + "(id int, name string) comment 'table comment' " + (isPartitioned ?
-            " partitioned by(dt string)" : "") + location);
-        return tableName;
-    }
-
     @Test
     public void testCreateTable() throws Exception {
         String tableName = tableName();
@@ -195,37 +160,6 @@ public class HiveHookIT {
         assertDatabaseIsRegistered(DEFAULT_DB);
     }
 
-    @Test
-    public void testCreateExternalTable() throws Exception {
-        String tableName = tableName();
-        String dbName = createDatabase();
-        String colName = columnName();
-
-        String pFile = createTestDFSPath("parentPath");
-        final String query = String.format("create EXTERNAL table %s.%s( %s, %s) location '%s'", dbName , tableName , colName + " int", "name string",  pFile);
-        runCommand(query);
-        String tableId = assertTableIsRegistered(dbName, tableName);
-
-        Referenceable processReference = validateProcess(query, 1, 1);
-        validateHDFSPaths(processReference, pFile, INPUTS);
-        validateOutputTables(processReference, tableId);
-    }
-
-    private void validateOutputTables(Referenceable processReference, String... expectedTableGuids) throws Exception {
-       validateTables(processReference, OUTPUTS, expectedTableGuids);
-    }
-
-    private void validateInputTables(Referenceable processReference, String... expectedTableGuids) throws Exception {
-        validateTables(processReference, INPUTS, expectedTableGuids);
-    }
-
-    private void validateTables(Referenceable processReference, String attrName, String... expectedTableGuids) throws Exception {
-        List<Id> tableRef = (List<Id>) processReference.get(attrName);
-        for(int i = 0; i < expectedTableGuids.length; i++) {
-            Assert.assertEquals(tableRef.get(i)._getId(), expectedTableGuids[i]);
-        }
-    }
-
     private String assertColumnIsRegistered(String colName) throws Exception {
         LOG.debug("Searching for column {}", colName.toLowerCase());
         String query =
@@ -237,7 +171,7 @@ public class HiveHookIT {
         LOG.debug("Searching for column {}", colName);
         String query =
             String.format("%s where qualifiedName = '%s'", HiveDataTypes.HIVE_COLUMN.getName(), colName.toLowerCase());
-        assertEntityIsNotRegistered(QUERY_TYPE.DSL, query);
+        assertEntityIsNotRegistered(query);
     }
 
     @Test
@@ -263,62 +197,7 @@ public class HiveHookIT {
     }
 
     @Test
-    public void testAlterViewAsSelect() throws Exception {
-
-        //Create the view from table1
-        String table1Name = createTable();
-        String viewName = tableName();
-        String query = "create view " + viewName + " as select * from " + table1Name;
-        runCommand(query);
-
-        String table1Id = assertTableIsRegistered(DEFAULT_DB, table1Name);
-        assertProcessIsRegistered(query);
-        String viewId = assertTableIsRegistered(DEFAULT_DB, viewName);
-
-        //Check lineage which includes table1
-        String datasetName = HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, viewName);
-        JSONObject response = dgiCLient.getInputGraph(datasetName);
-        JSONObject vertices = response.getJSONObject("values").getJSONObject("vertices");
-        Assert.assertTrue(vertices.has(viewId));
-        Assert.assertTrue(vertices.has(table1Id));
-
-        //Alter the view from table2
-        String table2Name = createTable();
-        query = "alter view " + viewName + " as select * from " + table2Name;
-        runCommand(query);
-
-        //Check if alter view process is reqistered
-        assertProcessIsRegistered(query);
-        String table2Id = assertTableIsRegistered(DEFAULT_DB, table2Name);
-        Assert.assertEquals(assertTableIsRegistered(DEFAULT_DB, viewName), viewId);
-
-        datasetName = HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, viewName);
-        response = dgiCLient.getInputGraph(datasetName);
-        vertices = response.getJSONObject("values").getJSONObject("vertices");
-        Assert.assertTrue(vertices.has(viewId));
-
-        //This is through the alter view process
-        Assert.assertTrue(vertices.has(table2Id));
-
-        //This is through the Create view process
-        Assert.assertTrue(vertices.has(table1Id));
-
-        //Outputs dont exist
-        response = dgiCLient.getOutputGraph(datasetName);
-        vertices = response.getJSONObject("values").getJSONObject("vertices");
-        Assert.assertEquals(vertices.length(), 0);
-    }
-
-    private String createTestDFSPath(String path) throws Exception {
-        return "pfile://" + mkdir(path);
-    }
-
-    private String createTestDFSFile(String path) throws Exception {
-        return "pfile://" + file(path);
-    }
-
-    @Test
-    public void testLoadLocalPath() throws Exception {
+    public void testLoadData() throws Exception {
         String tableName = createTable(false);
 
         String loadFile = file("load");
@@ -329,143 +208,19 @@ public class HiveHookIT {
     }
 
     @Test
-    public void testLoadLocalPathIntoPartition() throws Exception {
-        String tableName = createTable(true);
-
-        String loadFile = file("load");
-        String query = "load data local inpath 'file://" + loadFile + "' into table " + tableName +  " partition(dt = '2015-01-01')";
-        runCommand(query);
-
-        validateProcess(query, 0, 1);
-    }
-
-    @Test
-    public void testLoadDFSPath() throws Exception {
-        String tableName = createTable(true, true, false);
-
-        String tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-
-        String loadFile = createTestDFSFile("loadDFSFile");
-        String query = "load data inpath '" + loadFile + "' into table " + tableName + " partition(dt = '2015-01-01')";
-        runCommand(query);
-
-        Referenceable processReference = validateProcess(query, 1, 1);
-
-        validateHDFSPaths(processReference, loadFile, INPUTS);
-
-        validateOutputTables(processReference, tableId);
-    }
-
-    private Referenceable validateProcess(String query, int numInputs, int numOutputs) throws Exception {
-        String processId = assertProcessIsRegistered(query);
-        Referenceable process = dgiCLient.getEntity(processId);
-        if (numInputs == 0) {
-            Assert.assertNull(process.get(INPUTS));
-        } else {
-            Assert.assertEquals(((List<Referenceable>) process.get(INPUTS)).size(), numInputs);
-        }
-
-        if (numOutputs == 0) {
-            Assert.assertNull(process.get(OUTPUTS));
-        } else {
-            Assert.assertEquals(((List<Id>) process.get(OUTPUTS)).size(), numOutputs);
-        }
-
-        return process;
-    }
-
-    private Referenceable validateProcess(String query, String[] inputs, String[] outputs) throws Exception {
-        String processId = assertProcessIsRegistered(query);
-        Referenceable process = dgiCLient.getEntity(processId);
-        if (inputs == null) {
-            Assert.assertNull(process.get(INPUTS));
-        } else {
-            Assert.assertEquals(((List<Referenceable>) process.get(INPUTS)).size(), inputs.length);
-            validateInputTables(process, inputs);
-        }
-
-        if (outputs == null) {
-            Assert.assertNull(process.get(OUTPUTS));
-        } else {
-            Assert.assertEquals(((List<Id>) process.get(OUTPUTS)).size(), outputs.length);
-            validateOutputTables(process, outputs);
-        }
-
-        return process;
-    }
-
-    @Test
-    public void testInsertIntoTable() throws Exception {
+    public void testInsert() throws Exception {
         String tableName = createTable();
         String insertTableName = createTable();
         String query =
-                "insert into " + insertTableName + " select id, name from " + tableName;
-
-        runCommand(query);
-
-        String inputTableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-        String opTableId = assertTableIsRegistered(DEFAULT_DB, insertTableName);
-
-        validateProcess(query, new String[] {inputTableId}, new String[] {opTableId});
-    }
-
-    @Test
-    public void testInsertIntoLocalDir() throws Exception {
-        String tableName = createTable();
-        File randomLocalPath = File.createTempFile("hiverandom", ".tmp");
-        String query =
-            "insert overwrite LOCAL DIRECTORY '" + randomLocalPath.getAbsolutePath() + "' select id, name from " + tableName;
-
-        runCommand(query);
-        validateProcess(query, 1, 0);
-
-        assertTableIsRegistered(DEFAULT_DB, tableName);
-    }
-
-    @Test
-    public void testInsertIntoDFSDir() throws Exception {
-        String tableName = createTable();
-        String pFile = createTestDFSPath("somedfspath");
-        String query =
-            "insert overwrite DIRECTORY '" + pFile  + "' select id, name from " + tableName;
-
-        runCommand(query);
-        Referenceable processReference = validateProcess(query, 1, 1);
-        validateHDFSPaths(processReference, pFile, OUTPUTS);
-
-        String tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-
-        validateInputTables(processReference, tableId);
-    }
-
-    @Test
-    public void testInsertIntoTempTable() throws Exception {
-        String tableName = createTable();
-        String insertTableName = createTable(false, false, true);
-        String query =
-            "insert into " + insertTableName + " select id, name from " + tableName;
-
-        runCommand(query);
-        validateProcess(query, 1, 1);
-
-        String ipTableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-        String opTableId = assertTableIsRegistered(DEFAULT_DB, insertTableName);
-        validateProcess(query, new String[] {ipTableId}, new String[] {opTableId});
-    }
+                "insert into " + insertTableName + " partition(dt = '2015-01-01') select id, name from " + tableName
+                        + " where dt = '2015-01-01'";
 
-    @Test
-    public void testInsertIntoPartition() throws Exception {
-        String tableName = createTable(true);
-        String insertTableName = createTable(true);
-        String query =
-            "insert into " + insertTableName + " partition(dt = '2015-01-01') select id, name from " + tableName
-                + " where dt = '2015-01-01'";
         runCommand(query);
-        validateProcess(query, 1, 1);
-
-        String ipTableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-        String opTableId = assertTableIsRegistered(DEFAULT_DB, insertTableName);
-        validateProcess(query, new String[] {ipTableId}, new String[] {opTableId});
+        assertProcessIsRegistered(query);
+        String partId = assertPartitionIsRegistered(DEFAULT_DB, insertTableName, "2015-01-01");
+        Referenceable partitionEntity = dgiCLient.getEntity(partId);
+        Assert.assertEquals(partitionEntity.get("qualifiedName"),
+            String.format("%s.%s.%s@%s", "default", insertTableName.toLowerCase(), "2015-01-01", CLUSTER_NAME));
     }
 
     private String random() {
@@ -487,75 +242,34 @@ public class HiveHookIT {
     }
 
     @Test
-    public void testExportImportUnPartitionedTable() throws Exception {
+    public void testExportImport() throws Exception {
         String tableName = createTable(false);
 
-        String tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-
         String filename = "pfile://" + mkdir("export");
         String query = "export table " + tableName + " to \"" + filename + "\"";
         runCommand(query);
-        Referenceable processReference = validateProcess(query, 1, 1);
-        validateHDFSPaths(processReference, filename, OUTPUTS);
-
-        validateInputTables(processReference, tableId);
+        assertProcessIsRegistered(query);
 
-        //Import
         tableName = createTable(false);
-        tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-
-        query = "import table " + tableName + " from '" + filename + "'";
-        runCommand(query);
-        processReference = validateProcess(query, 1, 1);
-        validateHDFSPaths(processReference, filename, INPUTS);
-
-        validateOutputTables(processReference, tableId);
-
-    }
-
-    @Test
-    public void testExportImportPartitionedTable() throws Exception {
-        String tableName = createTable(true);
-        String tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-
-        //Add a partition
-        String partFile = "pfile://" + mkdir("partition");
-        String query = "alter table " + tableName + " add partition (dt='2015-01-01') location '" + partFile + "'";
-        runCommand(query);
-
-        String filename = "pfile://" + mkdir("export");
-        query = "export table " + tableName + " to \"" + filename + "\"";
-        runCommand(query);
-        Referenceable processReference = validateProcess(query, 1, 1);
-        validateHDFSPaths(processReference, filename, OUTPUTS);
-
-        validateInputTables(processReference, tableId);
-
-        //Import
-        tableName = createTable(true);
-        tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
 
         query = "import table " + tableName + " from '" + filename + "'";
         runCommand(query);
-        processReference = validateProcess(query, 1, 1);
-        validateHDFSPaths(processReference, filename, INPUTS);
-
-        validateOutputTables(processReference, tableId);
-
-
+        assertProcessIsRegistered(query);
     }
 
     @Test
-    public void testIgnoreSelect() throws Exception {
+    public void testSelect() throws Exception {
         String tableName = createTable();
         String query = "select * from " + tableName;
         runCommand(query);
-        assertProcessIsNotRegistered(query);
+        String pid = assertProcessIsRegistered(query);
+        Referenceable processEntity = dgiCLient.getEntity(pid);
+        Assert.assertEquals(processEntity.get("name"), query.toLowerCase());
 
-        //check with uppercase table name
+        //single entity per query
         query = "SELECT * from " + tableName.toUpperCase();
         runCommand(query);
-        assertProcessIsNotRegistered(query);
+        assertProcessIsRegistered(query);
     }
 
     @Test
@@ -592,16 +306,14 @@ public class HiveHookIT {
     @Test
     public void testAlterTableDropColumn() throws Exception {
         String tableName = createTable();
-        final String colDropped = "id";
-        String query = "alter table " + tableName + " replace columns (name string)";
+        final String colDropped = "name";
+        String query = "alter table " + tableName + " replace columns (id int)";
         runCommand(query);
         assertColumnIsNotRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), colDropped));
 
         //Verify the number of columns present in the table
         final List<Referenceable> columns = getColumns(DEFAULT_DB, tableName);
         Assert.assertEquals(columns.size(), 1);
-
-        Assert.assertEquals(columns.get(0).get(HiveDataModelGenerator.NAME), "name");
     }
 
     @Test
@@ -649,39 +361,6 @@ public class HiveHookIT {
         assertColumnIsRegistered(newColQualifiedName);
 
         Assert.assertEquals(columns.get(1).get(HiveDataModelGenerator.COMMENT), comment);
-
-        //Change column position
-        oldColName = "name3";
-        newColName = "name4";
-        query = String.format("alter table %s change column %s %s %s first", tableName, oldColName, newColName, newColType);
-        runCommand(query);
-
-        columns = getColumns(DEFAULT_DB, tableName);
-        Assert.assertEquals(columns.size(), 2);
-
-        assertColumnIsNotRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), oldColName));
-        newColQualifiedName = HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), newColName);
-        assertColumnIsRegistered(newColQualifiedName);
-
-        //Change col position again
-        Assert.assertEquals(columns.get(0).get(HiveDataModelGenerator.NAME), newColName);
-        Assert.assertEquals(columns.get(1).get(HiveDataModelGenerator.NAME), "id");
-
-        oldColName = "name4";
-        newColName = "name5";
-        query = String.format("alter table %s change column %s %s %s after id", tableName, oldColName, newColName, newColType);
-        runCommand(query);
-
-        columns = getColumns(DEFAULT_DB, tableName);
-        Assert.assertEquals(columns.size(), 2);
-
-        assertColumnIsNotRegistered(HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), oldColName));
-        newColQualifiedName = HiveMetaStoreBridge.getColumnQualifiedName(HiveMetaStoreBridge.getTableQualifiedName(CLUSTER_NAME, DEFAULT_DB, tableName), newColName);
-        assertColumnIsRegistered(newColQualifiedName);
-
-        //Check col position
-        Assert.assertEquals(columns.get(1).get(HiveDataModelGenerator.NAME), newColName);
-        Assert.assertEquals(columns.get(0).get(HiveDataModelGenerator.NAME), "id");
     }
 
     @Test
@@ -699,283 +378,6 @@ public class HiveHookIT {
         assertTableIsNotRegistered(DEFAULT_DB, viewName);
     }
 
-    @Test
-    public void testAlterTableLocation() throws Exception {
-        //Its an external table, so the HDFS location should also be registered as an entity
-        String tableName = createTable(true, true, false);
-        final String testPath = createTestDFSPath("testBaseDir");
-        String query = "alter table " + tableName + " set location '" + testPath + "'";
-        runCommand(query);
-
-        String tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-        //Verify the number of columns present in the table
-        Referenceable tableRef = dgiCLient.getEntity(tableId);
-        Referenceable sdRef = (Referenceable)tableRef.get(HiveDataModelGenerator.STORAGE_DESC);
-        Assert.assertEquals(sdRef.get("location"), testPath);
-
-        Referenceable processReference = validateProcess(query, 1, 1);
-        validateHDFSPaths(processReference, testPath, INPUTS);
-
-        validateOutputTables(processReference, tableId);
-
-    }
-
-    private String validateHDFSPaths(Referenceable processReference, String testPath, String attributeName) throws Exception {
-        List<Id> hdfsPathRefs = (List<Id>) processReference.get(attributeName);
-
-        final String testPathNormed = normalize(new Path(testPath).toString());
-        String hdfsPathId = assertHDFSPathIsRegistered(testPathNormed);
-        Assert.assertEquals(hdfsPathRefs.get(0)._getId(), hdfsPathId);
-
-        Referenceable hdfsPathRef = dgiCLient.getEntity(hdfsPathId);
-        Assert.assertEquals(hdfsPathRef.get("path"), testPathNormed);
-        Assert.assertEquals(hdfsPathRef.get("name"), testPathNormed);
-//        Assert.assertEquals(hdfsPathRef.get("name"), new Path(testPath).getName());
-        Assert.assertEquals(hdfsPathRef.get(AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME), testPathNormed);
-
-        return hdfsPathRef.getId()._getId();
-    }
-
-
-    private String assertHDFSPathIsRegistered(String path) throws Exception {
-        final String typeName = FSDataTypes.HDFS_PATH().toString();
-        final String parentTypeName = FSDataTypes.FS_PATH().toString();
-        String gremlinQuery =
-            String.format("g.V.has('__typeName', '%s').has('%s.path', \"%s\").toList()", typeName, parentTypeName,
-                normalize(path));
-        return assertEntityIsRegistered(gremlinQuery);
-    }
-
-    @Test
-    public void testAlterTableFileFormat() throws Exception {
-        String tableName = createTable();
-        final String testFormat = "orc";
-        String query = "alter table " + tableName + " set FILEFORMAT " + testFormat;
-        runCommand(query);
-
-        String tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-
-        Referenceable tableRef = dgiCLient.getEntity(tableId);
-        Referenceable sdRef = (Referenceable)tableRef.get(HiveDataModelGenerator.STORAGE_DESC);
-        Assert.assertEquals(sdRef.get(HiveDataModelGenerator.STORAGE_DESC_INPUT_FMT), "org.apache.hadoop.hive.ql.io.orc.OrcInputFormat");
-        Assert.assertEquals(sdRef.get(HiveDataModelGenerator.STORAGE_DESC_OUTPUT_FMT), "org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat");
-        Assert.assertNotNull(sdRef.get("serdeInfo"));
-
-        Struct serdeInfo = (Struct) sdRef.get("serdeInfo");
-        Assert.assertEquals(serdeInfo.get("serializationLib"), "org.apache.hadoop.hive.ql.io.orc.OrcSerde");
-        Assert.assertNotNull(serdeInfo.get(HiveDataModelGenerator.PARAMETERS));
-        Assert.assertEquals(((Map<String, String>)serdeInfo.get(HiveDataModelGenerator.PARAMETERS)).get("serialization.format"), "1");
-
-
-        /**
-         * Hive 'alter table stored as' is not supported - See https://issues.apache.org/jira/browse/HIVE-9576
-         * query = "alter table " + tableName + " STORED AS " + testFormat.toUpperCase();
-         * runCommand(query);
-
-         * tableRef = dgiCLient.getEntity(tableId);
-         * sdRef = (Referenceable)tableRef.get(HiveDataModelGenerator.STORAGE_DESC);
-         * Assert.assertEquals(sdRef.get(HiveDataModelGenerator.STORAGE_DESC_INPUT_FMT), "org.apache.hadoop.hive.ql.io.orc.OrcInputFormat");
-         * Assert.assertEquals(sdRef.get(HiveDataModelGenerator.STORAGE_DESC_OUTPUT_FMT), "org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat");
-         * Assert.assertEquals(((Map) sdRef.get(HiveDataModelGenerator.PARAMETERS)).get("orc.compress"), "ZLIB");
-         */
-    }
-
-    @Test
-    public void testAlterTableBucketingClusterSort() throws Exception {
-        String tableName = createTable();
-        ImmutableList<String> cols = ImmutableList.<String>of("id");
-        runBucketSortQuery(tableName, 5, cols, cols);
-
-        cols = ImmutableList.<String>of("id", "name");
-        runBucketSortQuery(tableName, 2, cols, cols);
-    }
-
-    private void runBucketSortQuery(String tableName, int numBuckets,  ImmutableList<String> bucketCols,ImmutableList<String> sortCols) throws Exception {
-        final String fmtQuery = "alter table %s CLUSTERED BY (%s) SORTED BY (%s) INTO %s BUCKETS";
-        String query = String.format(fmtQuery, tableName, stripListBrackets(bucketCols.toString()), stripListBrackets(sortCols.toString()), numBuckets);
-        runCommand(query);
-        verifyBucketSortingProperties(tableName, numBuckets, bucketCols, sortCols);
-    }
-
-    private String stripListBrackets(String listElements) {
-        return StringUtils.strip(StringUtils.strip(listElements, "["), "]");
-    }
-
-    private void verifyBucketSortingProperties(String tableName, int numBuckets, ImmutableList<String> bucketColNames, ImmutableList<String>  sortcolNames) throws Exception {
-
-        String tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-
-        Referenceable tableRef = dgiCLient.getEntity(tableId);
-        Referenceable sdRef = (Referenceable)tableRef.get(HiveDataModelGenerator.STORAGE_DESC);
-        Assert.assertEquals(((scala.math.BigInt) sdRef.get(HiveDataModelGenerator.STORAGE_NUM_BUCKETS)).intValue(), numBuckets);
-        Assert.assertEquals(sdRef.get("bucketCols"), bucketColNames);
-
-        List<Struct> hiveOrderStructList = (List<Struct>) sdRef.get("sortCols");
-        Assert.assertNotNull(hiveOrderStructList);
-        Assert.assertEquals(hiveOrderStructList.size(), sortcolNames.size());
-
-        for (int i = 0; i < sortcolNames.size(); i++) {
-            Assert.assertEquals(hiveOrderStructList.get(i).get("col"), sortcolNames.get(i));
-            Assert.assertEquals(((scala.math.BigInt)hiveOrderStructList.get(i).get("order")).intValue(), 1);
-        }
-    }
-
-    @Test
-    public void testAlterTableSerde() throws Exception {
-        //SERDE PROPERTIES
-        String tableName = createTable();
-        Map<String, String> expectedProps = new HashMap<String, String>() {{
-            put("key1", "value1");
-        }};
-
-        runSerdePropsQuery(tableName, expectedProps);
-
-        expectedProps.put("key2", "value2");
-
-        //Add another property
-        runSerdePropsQuery(tableName, expectedProps);
-
-    }
-
-    private void runSerdePropsQuery(String tableName, Map<String, String> expectedProps) throws Exception {
-
-        final String serdeLib = "org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe";
-
-        final String serializedProps = getSerializedProps(expectedProps);
-        String query = String.format("alter table %s set SERDE '%s' WITH SERDEPROPERTIES (%s)", tableName, serdeLib, serializedProps);
-        runCommand(query);
-
-        verifyTableSdProperties(tableName, serdeLib, expectedProps);
-    }
-
-    private String getSerializedProps(Map<String, String> expectedProps) {
-        StringBuilder sb = new StringBuilder();
-        for(String expectedPropKey : expectedProps.keySet()) {
-            if(sb.length() > 0) {
-                sb.append(",");
-            }
-            sb.append("'").append(expectedPropKey).append("'");
-            sb.append("=");
-            sb.append("'").append(expectedProps.get(expectedPropKey)).append("'");
-        }
-        return sb.toString();
-    }
-
-    @Test
-    public void testAlterDBOwner() throws Exception {
-        String dbName = createDatabase();
-        final String owner = "testOwner";
-        String dbId = assertDatabaseIsRegistered(dbName);
-        final String fmtQuery = "alter database %s set OWNER %s %s";
-        String query = String.format(fmtQuery, dbName, "USER", owner);
-
-        runCommand(query);
-
-        assertDatabaseIsRegistered(dbName);
-        Referenceable entity = dgiCLient.getEntity(dbId);
-        Assert.assertEquals(entity.get(HiveDataModelGenerator.OWNER), owner);
-    }
-
-    @Test
-    public void testAlterDBProperties() throws Exception {
-        String dbName = createDatabase();
-        final String fmtQuery = "alter database %s %s DBPROPERTIES (%s)";
-        testAlterProperties(Entity.Type.DATABASE, dbName, fmtQuery);
-    }
-
-    @Test
-    public void testAlterTableProperties() throws Exception {
-        String tableName = createTable();
-        final String fmtQuery = "alter table %s %s TBLPROPERTIES (%s)";
-        testAlterProperties(Entity.Type.TABLE, tableName, fmtQuery);
-    }
-
-    private void testAlterProperties(Entity.Type entityType, String entityName, String fmtQuery) throws Exception {
-        final String SET_OP = "set";
-        final String UNSET_OP = "unset";
-
-        final Map<String, String> expectedProps = new HashMap<String, String>() {{
-            put("testPropKey1", "testPropValue1");
-            put("comment", "test comment");
-        }};
-
-        String query = String.format(fmtQuery, entityName, SET_OP, getSerializedProps(expectedProps));
-        runCommand(query);
-        verifyEntityProperties(entityType, entityName, expectedProps, false);
-
-        expectedProps.put("testPropKey2", "testPropValue2");
-        //Add another property
-        query = String.format(fmtQuery, entityName, SET_OP, getSerializedProps(expectedProps));
-        runCommand(query);
-        verifyEntityProperties(entityType, entityName, expectedProps, false);
-
-        if (entityType != Entity.Type.DATABASE) {
-            //Database unset properties doesnt work strangely - alter database %s unset DBPROPERTIES doesnt work
-            //Unset all the props
-            StringBuilder sb = new StringBuilder("'");
-            query = String.format(fmtQuery, entityName, UNSET_OP, Joiner.on("','").skipNulls().appendTo(sb, expectedProps.keySet()).append('\''));
-            runCommand(query);
-
-            verifyEntityProperties(entityType, entityName, expectedProps, true);
-        }
-    }
-
-    @Test
-    public void testAlterViewProperties() throws Exception {
-        String tableName = createTable();
-        String viewName = tableName();
-        String query = "create view " + viewName + " as select * from " + tableName;
-        runCommand(query);
-
-        final String fmtQuery = "alter view %s %s TBLPROPERTIES (%s)";
-        testAlterProperties(Entity.Type.TABLE, viewName, fmtQuery);
-    }
-
-    private void verifyEntityProperties(Entity.Type type, String entityName, Map<String, String> expectedProps, boolean checkIfNotExists) throws Exception {
-
-        String entityId = null;
-
-        switch(type) {
-        case TABLE:
-            entityId = assertTableIsRegistered(DEFAULT_DB, entityName);
-            break;
-        case DATABASE:
-            entityId = assertDatabaseIsRegistered(entityName);
-            break;
-        }
-
-        Referenceable ref = dgiCLient.getEntity(entityId);
-        verifyProperties(ref, expectedProps, checkIfNotExists);
-    }
-
-    private void verifyTableSdProperties(String tableName, String serdeLib, Map<String, String> expectedProps) throws Exception {
-        String tableId = assertTableIsRegistered(DEFAULT_DB, tableName);
-        Referenceable tableRef = dgiCLient.getEntity(tableId);
-        Referenceable sdRef = (Referenceable) tableRef.get(HiveDataModelGenerator.STORAGE_DESC);
-        Struct serdeInfo = (Struct) sdRef.get("serdeInfo");
-        Assert.assertEquals(serdeInfo.get("serializationLib"), serdeLib);
-        verifyProperties(serdeInfo, expectedProps, false);
-    }
-
-    private void verifyProperties(Struct referenceable, Map<String, String> expectedProps, boolean checkIfNotExists) {
-        Map<String, String> parameters = (Map<String, String>) referenceable.get(HiveDataModelGenerator.PARAMETERS);
-
-        if (checkIfNotExists == false) {
-            //Check if properties exist
-            Assert.assertNotNull(parameters);
-            for (String propKey : expectedProps.keySet()) {
-                Assert.assertEquals(parameters.get(propKey), expectedProps.get(propKey));
-            }
-        } else {
-            //Check if properties dont exist
-            if (expectedProps != null && parameters != null) {
-                for (String propKey : expectedProps.keySet()) {
-                    Assert.assertFalse(parameters.containsKey(propKey));
-                }
-            }
-        }
-    }
-
     private String assertProcessIsRegistered(String queryStr) throws Exception {
         //        String dslQuery = String.format("%s where queryText = \"%s\"", HiveDataTypes.HIVE_PROCESS.getName(),
         //                normalize(queryStr));
@@ -988,18 +390,6 @@ public class HiveHookIT {
         return assertEntityIsRegistered(gremlinQuery);
     }
 
-    private void assertProcessIsNotRegistered(String queryStr) throws Exception {
-        //        String dslQuery = String.format("%s where queryText = \"%s\"", HiveDataTypes.HIVE_PROCESS.getName(),
-        //                normalize(queryStr));
-        //        assertEntityIsRegistered(dslQuery, true);
-        //todo replace with DSL
-        String typeName = HiveDataTypes.HIVE_PROCESS.getName();
-        String gremlinQuery =
-            String.format("g.V.has('__typeName', '%s').has('%s.queryText', \"%s\").toList()", typeName, typeName,
-                normalize(queryStr));
-        assertEntityIsNotRegistered(QUERY_TYPE.GREMLIN, gremlinQuery);
-    }
-
     private String normalize(String str) {
         if (StringUtils.isEmpty(str)) {
             return null;
@@ -1012,7 +402,7 @@ public class HiveHookIT {
         String query = String.format(
                 "%s as t where tableName = '%s', db where name = '%s' and clusterName = '%s'" + " select t",
                 HiveDataTypes.HIVE_TABLE.getName(), tableName.toLowerCase(), dbName.toLowerCase(), CLUSTER_NAME);
-        assertEntityIsNotRegistered(QUERY_TYPE.DSL, query);
+        assertEntityIsNotRegistered(query);
     }
 
     private String assertTableIsRegistered(String dbName, String tableName) throws Exception {
@@ -1038,8 +428,19 @@ public class HiveHookIT {
         return assertEntityIsRegistered(query);
     }
 
+    private String assertPartitionIsRegistered(String dbName, String tableName, String value) throws Exception {
+        String typeName = HiveDataTypes.HIVE_PARTITION.getName();
+
+        LOG.debug("Searching for partition of {}.{} with values {}", dbName, tableName, value);
+        String dslQuery = String.format("%s as p where values = ['%s'], table where tableName = '%s', "
+                        + "db where name = '%s' and clusterName = '%s' select p", typeName, value,
+                tableName.toLowerCase(), dbName.toLowerCase(), CLUSTER_NAME);
+
+        return assertEntityIsRegistered(dslQuery, "p");
+    }
+
     private String assertEntityIsRegistered(final String query, String... arg) throws Exception {
-        waitFor(60000, new Predicate() {
+        waitFor(2000, new Predicate() {
             @Override
             public boolean evaluate() throws Exception {
                 JSONArray results = dgiCLient.search(query);
@@ -1060,16 +461,8 @@ public class HiveHookIT {
         }
     }
 
-    private void assertEntityIsNotRegistered(QUERY_TYPE queryType, String query) throws Exception {
-        JSONArray results = null;
-        switch(queryType) {
-        case DSL :
-            results = dgiCLient.searchByDSL(query);
-            break;
-        case GREMLIN :
-            results = dgiCLient.searchByGremlin(query);
-            break;
-        }
+    private void assertEntityIsNotRegistered(String dslQuery) throws Exception {
+        JSONArray results = dgiCLient.searchByDSL(dslQuery);
         Assert.assertEquals(results.length(), 0);
     }
 