diff --git a/addons/hive-bridge/src/test/java/org/apache/hadoop/metadata/hive/hook/HiveHookIT.java b/addons/hive-bridge/src/test/java/org/apache/hadoop/metadata/hive/hook/HiveHookIT.java
old mode 100755
new mode 100644
index 92186f450..a47815006
--- a/addons/hive-bridge/src/test/java/org/apache/hadoop/metadata/hive/hook/HiveHookIT.java
+++ b/addons/hive-bridge/src/test/java/org/apache/hadoop/metadata/hive/hook/HiveHookIT.java
@@ -20,33 +20,47 @@ package org.apache.hadoop.metadata.hive.hook;
 
 import org.apache.commons.lang.RandomStringUtils;
 import org.apache.hadoop.hive.conf.HiveConf;
+import org.apache.hadoop.hive.ql.CommandNeedRetryException;
 import org.apache.hadoop.hive.ql.Driver;
 import org.apache.hadoop.hive.ql.session.SessionState;
 import org.apache.hadoop.metadata.MetadataServiceClient;
 import org.apache.hadoop.metadata.hive.bridge.HiveMetaStoreBridge;
+import org.apache.hadoop.metadata.hive.model.HiveDataModelGenerator;
 import org.apache.hadoop.metadata.hive.model.HiveDataTypes;
+import org.apache.hadoop.metadata.typesystem.TypesDef;
+import org.apache.hadoop.metadata.typesystem.json.TypesSerialization;
+import org.apache.hadoop.metadata.typesystem.types.TypeSystem;
 import org.codehaus.jettison.json.JSONArray;
 import org.codehaus.jettison.json.JSONObject;
 import org.testng.Assert;
 import org.testng.annotations.BeforeClass;
 import org.testng.annotations.Test;
 
-import java.io.File;
-
 public class HiveHookIT {
     private static final String DGI_URL = "http://localhost:21000/";
-    private static final String CLUSTER_NAME = "test";
     private Driver driver;
     private MetadataServiceClient dgiCLient;
     private SessionState ss;
 
     @BeforeClass
     public void setUp() throws Exception {
+        //Register hive types
+        HiveDataModelGenerator hiveModel = new HiveDataModelGenerator();
+        hiveModel.createDataModel();
+        TypesDef typesDef = hiveModel.getTypesDef();
+        String typesAsJson = TypesSerialization.toJson(typesDef);
+        MetadataServiceClient dgiClient = new MetadataServiceClient(DGI_URL);
+        try {
+            dgiClient.createType(typesAsJson);
+        } catch (Exception e) {
+            //ignore if types are already defined
+        }
+
         //Set-up hive session
         HiveConf conf = getHiveConf();
         driver = new Driver(conf);
-        ss = new SessionState(conf, System.getProperty("user.name"));
-        ss = SessionState.start(ss);
+        ss = new SessionState(conf);
+        ss = ss.start(conf);
         SessionState.setCurrentSessionState(ss);
 
         dgiCLient = new MetadataServiceClient(DGI_URL);
@@ -59,12 +73,7 @@ public class HiveHookIT {
         hiveConf.setBoolVar(HiveConf.ConfVars.HIVE_SUPPORT_CONCURRENCY, false);
         hiveConf.setVar(HiveConf.ConfVars.METASTOREWAREHOUSE, System.getProperty("user.dir") + "/target/metastore");
         hiveConf.set(HiveMetaStoreBridge.DGI_URL_PROPERTY, DGI_URL);
-        hiveConf.set("javax.jdo.option.ConnectionURL", "jdbc:derby:./target/metastore_db;create=true");
-        hiveConf.set("hive.hook.dgi.synchronous", "true");
-        hiveConf.set(HiveMetaStoreBridge.HIVE_CLUSTER_NAME, CLUSTER_NAME);
-        hiveConf.setBoolVar(HiveConf.ConfVars.HIVETESTMODE, true);  //to not use hdfs
-        hiveConf.setVar(HiveConf.ConfVars.HIVETESTMODEPREFIX, "");
-        hiveConf.set("fs.pfile.impl", "org.apache.hadoop.fs.ProxyLocalFileSystem");
+        hiveConf.set("debug", "true");
         return hiveConf;
     }
 
@@ -75,166 +84,40 @@ public class HiveHookIT {
 
     @Test
     public void testCreateDatabase() throws Exception {
-        String dbName = "db" + random();
+        String dbName = "db" + RandomStringUtils.randomAlphanumeric(5).toLowerCase();
         runCommand("create database " + dbName);
-        assertDatabaseIsRegistered(dbName);
 
-        //There should be just one entity per dbname
-        runCommand("drop database " + dbName);
-        runCommand("create database " + dbName);
-        assertDatabaseIsRegistered(dbName);
+        String typeName = HiveDataTypes.HIVE_DB.getName();
+        JSONObject result = dgiCLient.search(typeName, "name", dbName);
+        JSONArray results = (JSONArray) result.get("results");
+        Assert.assertEquals(results.length(), 1);
+        JSONObject resultRow = (JSONObject) results.get(0);
+        Assert.assertEquals(resultRow.get(typeName + ".name"), dbName);
     }
 
-    @Test
+    @Test(enabled = false)
     public void testCreateTable() throws Exception {
-        String dbName = "db" + random();
+        String dbName = "db" + RandomStringUtils.randomAlphanumeric(5).toLowerCase();
         runCommand("create database " + dbName);
 
-        String tableName = "table" + random();
-        runCommand("create table " + dbName + "." + tableName + "(id int, name string)");
-        assertTableIsRegistered(dbName, tableName);
+        String tableName = "table" + RandomStringUtils.randomAlphanumeric(5);
+        String queryStr = String.format("create table %s.%s(id int, name string)", dbName, tableName);
+        runCommand(queryStr);
 
-        tableName = "table" + random();
-        runCommand("create table " + tableName + "(id int, name string) partitioned by(dt string)");
-        assertTableIsRegistered("default", tableName);
+        String defaultTableName = "table" + RandomStringUtils.randomAlphanumeric(5);
+        runCommand("create table " + defaultTableName + "(id int, name string)");
 
-        //Create table where database doesn't exist, will create database instance as well
-        assertDatabaseIsRegistered("default");
-    }
+        runCommand("select * from " + defaultTableName);
 
-    @Test
-    public void testCTAS() throws Exception {
-        String tableName = "table" + random();
-        runCommand("create table " + tableName + "(id int, name string)");
+        runCommand("select * from " + dbName + "." + tableName);
 
-        String ctasTableName = "table" + random();
-        String query = "create table " + ctasTableName + " as select * from " + tableName;
-        runCommand(query);
+        String newTableName = "table" + RandomStringUtils.randomAlphanumeric(5);
 
-        assertTableIsRegistered("default", ctasTableName);
-        assertProcessIsRegistered(query);
-    }
-
-    @Test
-    public void testCreateView() throws Exception {
-        String tableName = "table" + random();
-        runCommand("create table " + tableName + "(id int, name string)");
-
-        String viewName = "table" + random();
-        String query = "create view " + viewName + " as select * from " + tableName;
-        runCommand(query);
-
-        assertTableIsRegistered("default", viewName);
-        assertProcessIsRegistered(query);
-    }
+        runCommand("create table " + newTableName + " as select * from " + defaultTableName);
 
-    @Test
-    public void testLoadData() throws Exception {
-        String tableName = "table" + random();
-        runCommand("create table " + tableName + "(id int, name string)");
-
-        String loadFile = file("load");
-        String query = "load data local inpath 'file://" + loadFile + "' into table " + tableName;
-        runCommand(query);
-
-        assertProcessIsRegistered(query);
-    }
-
-    @Test
-    public void testInsert() throws Exception {
-        String tableName = "table" + random();
-        runCommand("create table " + tableName + "(id int, name string) partitioned by(dt string)");
-
-        String insertTableName = "table" + random();
-        runCommand("create table " + insertTableName + "(name string) partitioned by(dt string)");
-
-        String query = "insert into " + insertTableName + " partition(dt = '2015-01-01') select name from "
-                + tableName + " where dt = '2015-01-01'";
-
-        runCommand(query);
-        assertProcessIsRegistered(query);
-        assertPartitionIsRegistered("default", insertTableName, "2015-01-01");
-    }
-
-    private String random() {
-        return RandomStringUtils.randomAlphanumeric(5).toLowerCase();
-    }
+        runCommand("create table " + dbName + "." + newTableName + " as select * from " + dbName + "." + tableName);
 
-    private String file(String tag) throws Exception {
-        String filename = "./target/" + tag + "-data-" + random();
-        File file = new File(filename);
-        file.createNewFile();
-        return file.getAbsolutePath();
-    }
-
-    private String mkdir(String tag) throws Exception {
-        String filename = "./target/" + tag + "-data-" + random();
-        File file = new File(filename);
-        file.mkdirs();
-        return file.getAbsolutePath();
-    }
-
-    @Test
-    public void testExportImport() throws Exception {
-        String tableName = "table" + random();
-        runCommand("create table " + tableName + "(name string)");
-
-        String filename = "pfile://" + mkdir("export");
-        String query = "export table " + tableName + " to '" + filename + "'";
-        runCommand(query);
-        assertProcessIsRegistered(query);
-
-        tableName = "table" + random();
-        runCommand("create table " + tableName + "(name string)");
-
-        query = "import table " + tableName + " from '" + filename + "'";
-        runCommand(query);
-        assertProcessIsRegistered(query);
-    }
-
-    @Test
-    public void testSelect() throws Exception {
-        String tableName = "table" + random();
-        runCommand("create table " + tableName + "(id int, name string)");
-
-        String query = "select * from " + tableName;
-        runCommand(query);
-        assertProcessIsRegistered(query);
-    }
-
-    private void assertProcessIsRegistered(String queryStr) throws Exception {
-        String dslQuery = String.format("%s where queryText = \"%s\"", HiveDataTypes.HIVE_PROCESS.getName(), queryStr);
-        assertEntityIsRegistered(dslQuery);
-    }
-
-    private void assertTableIsRegistered(String dbName, String tableName) throws Exception {
-        String query = String.format("%s where name = '%s', dbName where name = '%s' and clusterName = '%s'",
-                HiveDataTypes.HIVE_TABLE.getName(), tableName, dbName, CLUSTER_NAME);
-        assertEntityIsRegistered(query);
-    }
-
-    private void assertDatabaseIsRegistered(String dbName) throws Exception {
-        String query = String.format("%s where name = '%s' and clusterName = '%s'", HiveDataTypes.HIVE_DB.getName(),
-                dbName, CLUSTER_NAME);
-        assertEntityIsRegistered(query);
-    }
-
-    private void assertPartitionIsRegistered(String dbName, String tableName, String value) throws Exception {
-        String typeName = HiveDataTypes.HIVE_PARTITION.getName();
-
-        String dbType = HiveDataTypes.HIVE_DB.getName();
-        String tableType = HiveDataTypes.HIVE_TABLE.getName();
-        String gremlinQuery = String.format("g.V.has('__typeName', '%s').has('%s.values', ['%s']).as('p')."
-                        + "out('__%s.tableName').has('%s.name', '%s').out('__%s.dbName').has('%s.name', '%s')"
-                        + ".has('%s.clusterName', '%s').back('p').toList()", typeName, typeName, value, typeName,
-                tableType, tableName, tableType, dbType, dbName, dbType, CLUSTER_NAME);
-        JSONObject response = dgiCLient.searchByGremlin(gremlinQuery);
-        JSONArray results = response.getJSONArray(MetadataServiceClient.RESULTS);
-        Assert.assertEquals(results.length(), 1);
-    }
-
-    private void assertEntityIsRegistered(String dslQuery) throws Exception{
-        JSONArray results = dgiCLient.searchByDSL(dslQuery);
-        Assert.assertEquals(results.length(), 1);
+        newTableName = "table" + RandomStringUtils.randomAlphanumeric(5);
+        runCommand("create table " + newTableName + " as select count(*) from " + defaultTableName);
     }
 }